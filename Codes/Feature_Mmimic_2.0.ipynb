{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0N3ldrt/Thesis/blob/main/Codes/Feature_Mmimic_2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading enviroment and required libraries "
      ],
      "metadata": {
        "id": "cYXBKmqyLiKs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2XvqJSygLSEu"
      },
      "outputs": [],
      "source": [
        "# Importing necesary libraries\n",
        "\n",
        "import math\n",
        "import pickle\n",
        "import os, time\n",
        "import numpy as np\n",
        "import collections\n",
        "import pandas as pd\n",
        "from os.path import exists\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google drive loading as work station for local-usage of the files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount= True)\n",
        "\n",
        "#-----------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "Gm-nssvJLa59",
        "outputId": "688383a6-8f30-40c7-e26e-0f2b57938825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para cambiar los paths rapido.\n",
        "workers = [\"Ronald\", \"Local\"]\n",
        "\n",
        "# Cambiar el numero aqui para cambiar los paths.\n",
        "worker = workers[0]\n",
        "\n",
        "if worker == \"Ronald\":\n",
        "  path= \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset\"\n",
        "else: path = os.getcwd()"
      ],
      "metadata": {
        "id": "NqW-7OpZMfdc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-procesing"
      ],
      "metadata": {
        "id": "dQYBQZ_dMQSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "\n",
        "global distances \n",
        "distances = [80*i for i in range(1,26)]\n",
        "\n",
        "global sc_input, sc_output\n",
        "sc_input = MinMaxScaler()\n",
        "sc_output = MinMaxScaler()"
      ],
      "metadata": {
        "id": "spCmDUR-NFpJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_data(df, train):\n",
        "  # Function that converts the provided data frame into target and explicative variables.\n",
        "  colnames=df.columns[1:25]\n",
        "  X=df.iloc[:,1:25]\n",
        "  Y=df.iloc[:,0].to_numpy().reshape(-1,1)\n",
        "  if train: \n",
        "    X = sc_input.fit_transform(X)\n",
        "    Y = sc_output.fit_transform(Y)\n",
        "  else: \n",
        "    X = sc_input.transform(X)\n",
        "    Y = sc_output.transform(Y)\n",
        "  return X,Y"
      ],
      "metadata": {
        "id": "0-eCCQOqLfcl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_train(X_train,Y_train):\n",
        "  #NN Model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim = 24, activation = 'tanh'))\n",
        "  model.add(Dense(6,activation='tanh'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss ='mean_squared_error',optimizer = 'RMSprop')\n",
        "  \n",
        "  #Generate model\n",
        "  model_ann = KerasRegressor(build_fn=ann,epochs=500,batch_size=32)\n",
        "\n",
        "  #Train model\n",
        "  start_time = time.time()\n",
        "  callback = EarlyStopping(monitor='loss', patience=500)\n",
        "  model_ann.fit(X_train, Y_train, callbacks=[callback])\n",
        "  time_train_ann = time.time() - start_time\n",
        "  return model_ann"
      ],
      "metadata": {
        "id": "8ya8A2w6SZUn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_NNmodel(df_train, df_test, NN_filepath):\n",
        "  X_train, Y_train = modify_data(df_train, True)\n",
        "  X_test, Y_test = modify_data(df_test, False)\n",
        "\n",
        "  \n",
        "  file_exists = exists(NN_filepath)\n",
        "  if file_exists != True:\n",
        "    model_ann = generate_and_train(X_train,Y_train)\n",
        "    pickle.dump(model_ann,open(NN_filepath,\"wb\"))\n",
        "    print('NN models trained and saved succesfully')\n",
        "  else:\n",
        "    print('NN models already saved in provided filepath')\n",
        "  return X_train,Y_train, X_test, Y_test"
      ],
      "metadata": {
        "id": "X3OY2mVrSc9V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_results(model,X_test,Y_test,log = True): \n",
        "  start_time = time.time()\n",
        "  Y_test_pred=model.predict(X_test)\n",
        "  time_eval_ann=time.time()-start_time\n",
        "\n",
        "  real=list(list(zip(*Y_test))[0])\n",
        "\n",
        "  #real=list(map(list, zip(*Y_train)))\n",
        "  pred=list(Y_test_pred)\n",
        "  print(pred)\n",
        "\n",
        "  plt.plot(real,pred,'bo')\n",
        "  x= np.linspace(0,1,100)\n",
        "  plt.plot(x,x,\"-r\")\n",
        "  plt.show()\n",
        "  plt.close\n",
        "\n",
        "  tot_abs, tot_square = 0, 0\n",
        "  for i in range(len(real)):\n",
        "    tot_abs += (real[i] - pred[i])\n",
        "    tot_square += (real[i] - pred[i])**2\n",
        "  if log:\n",
        "    print('MAE:', tot_abs/len(real))\n",
        "    print('MSE:', tot_square/len(real))\n",
        "  return Y_test_pred"
      ],
      "metadata": {
        "id": "s71PmjkXL1wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Opening train/test and modified files\n",
        "df_train=pd.read_csv(path+'/trainingData/training_data.csv')\n",
        "df_test=pd.read_csv(path+'/trainingData/testing_data.csv')\n",
        "df_modified = pd.read_csv(path+'/modifiedData/GD/alpha1.csv')\n",
        "\n",
        "#Filepath of the neural network\n",
        "NN_filepath = path+\"/trainedModel/new_model.pkl\"\n",
        "\n",
        "#Create train test splits and train neural network if necesesary\n",
        "X_train,Y_train, X_test, Y_test = train_test_split_NNmodel(df_train, df_test, NN_filepath)\n"
      ],
      "metadata": {
        "id": "py8BOCL0YmA-",
        "outputId": "2d3c4a35-6ca0-443c-e5da-cc2bbb3c870e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN models already saved in provided filepath\n"
          ]
        }
      ]
    }
  ]
}