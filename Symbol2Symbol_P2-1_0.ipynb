{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIxcPUGKij8eWIZ+y4kQ2r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0N3ldrt/Thesis/blob/main/Symbol2Symbol_P2-1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Symbol_to_Symbol Part 2"
      ],
      "metadata": {
        "id": "S1iYFnpV0e5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Necesary Libraries"
      ],
      "metadata": {
        "id": "jpawY2sz0vLP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfR0V2_D0cYc"
      },
      "outputs": [],
      "source": [
        "# Importing necesary libraries\n",
        "# Libraries for correct code execution \n",
        "\n",
        "import os, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Enviroment"
      ],
      "metadata": {
        "id": "5ReapRgr00wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE PARA USAR DESDE COLAB\n",
        "\n",
        "# Google drive loading as work station for local-usage of the files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount= True)\n",
        "\n",
        "#-----------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "LRJiBU4z09pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para cambiar los paths rapido.\n",
        "workers = [\"Ronald\", \"Local\"]\n",
        "\n",
        "# Cambiar el numero aqui para cambiar los paths.\n",
        "worker = workers[0]\n",
        "\n",
        "if worker == \"Ronald\":\n",
        "  path= \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset\"\n",
        "else: path = os.getcwd()"
      ],
      "metadata": {
        "id": "qa25KuA90_G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Conversion"
      ],
      "metadata": {
        "id": "9mnyo0oe1AsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_data(df, train):\n",
        "  # Function that converts the provided data frame into target and explicative variables.\n",
        "  colnames=df.columns[1:25]\n",
        "  X=df.iloc[:,1:25]\n",
        "  Y=df.iloc[:,0].to_numpy().reshape(-1,1)\n",
        "  if train: \n",
        "    X = sc_input.fit_transform(X)\n",
        "    Y = sc_output.fit_transform(Y)\n",
        "  else: \n",
        "    X = sc_input.transform(X)\n",
        "    Y = sc_output.transform(Y)\n",
        "  return X,Y"
      ],
      "metadata": {
        "id": "fQkaGxj71H5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "-NBDxQZ21Lnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ann():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim = 24, activation = 'tanh'))\n",
        "    model.add(Dense(6,activation='tanh'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss ='mean_squared_error',optimizer = 'RMSprop')\n",
        "    return model"
      ],
      "metadata": {
        "id": "wFao3URm1QGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_train(X_train,Y_train):\n",
        "  model_ann = KerasRegressor(build_fn=ann,epochs=500,batch_size=32)\n",
        "\n",
        "  start_time = time.time()\n",
        "  callback = EarlyStopping(monitor='loss', patience=500)\n",
        "  model_ann.fit(X_train, Y_train, callbacks=[callback])\n",
        "  time_train_ann = time.time() - start_time\n",
        "  return model_ann"
      ],
      "metadata": {
        "id": "tHCJsxiw1UIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results"
      ],
      "metadata": {
        "id": "Kqj_CJaW1RuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_results(model,X_test,Y_test,log = True): \n",
        "  start_time = time.time()\n",
        "  Y_test_pred=model.predict(X_test)\n",
        "  time_eval_ann=time.time()-start_time\n",
        "\n",
        "  real=list(list(zip(*Y_test))[0])\n",
        "\n",
        "  #real=list(map(list, zip(*Y_train)))\n",
        "  pred=list(Y_test_pred)\n",
        "  print(pred)\n",
        "\n",
        "  plt.plot(real,pred,'bo')\n",
        "  x= np.linspace(0,1,100)\n",
        "  plt.plot(x,x,\"-r\")\n",
        "  plt.show()\n",
        "  plt.close\n",
        "\n",
        "  tot_abs, tot_square = 0, 0\n",
        "  for i in range(len(real)):\n",
        "    tot_abs += (real[i] - pred[i])\n",
        "    tot_square += (real[i] - pred[i])**2\n",
        "  if log:\n",
        "    print('MAE:', tot_abs/len(real))\n",
        "    print('MSE:', tot_square/len(real))\n",
        "  return Y_test_pred"
      ],
      "metadata": {
        "id": "P_jWqPCm1jFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "G5hiDacv1qcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global sc_input, sc_output\n",
        "sc_input = MinMaxScaler()\n",
        "sc_output = MinMaxScaler()\n",
        "\n",
        "\n",
        "X_train,Y_train = modify_data(df_train, True)\n",
        "X_test, Y_test = modify_data(df_test, False)"
      ],
      "metadata": {
        "id": "v2FO8VOz1KkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ann = generate_and_train(X_train,Y_train)\n",
        "\n",
        "pickle.dump(model_ann,open(path+\"/trainedModel/new_model.pkl\",\"wb\"))"
      ],
      "metadata": {
        "id": "E9QX4OZ11ZTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent"
      ],
      "metadata": {
        "id": "yq8H1bHw1wtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Old path\n",
        "#path_modified = path+'/modifiedData/GD/alpha1.csv'\n",
        "\n",
        "path_modified = path+'/modifiedData/GD/GD_alpha_1.csv'\n",
        "df_modified = pd.read_csv(path_modified)"
      ],
      "metadata": {
        "id": "vxifai_F1u9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_matrix_alpha_1_GD = []\n",
        "for i in range(24):\n",
        "  interest = 25-(i+1)\n",
        "  idx1 = sum([x for x in range(interest+1,25)])*25\n",
        "  idx2 = idx1 + interest*25\n",
        "  points = df_modified.iloc[idx1:idx2,]\n",
        "  X_mod, Y_mod = modify_data(points, False)\n",
        "  aux = test_results(model_ann,X_mod,Y_mod,log = False)\n",
        "  aux = sc_output.inverse_transform(aux.reshape(1,-1))[0]\n",
        "  tar = sc_output.inverse_transform(Y_mod.reshape(1,-1))[0]\n",
        "  mean_error = [0 for _ in range(interest)]\n",
        "  for j in range(interest):\n",
        "    elements = aux[j*25:j*25+25]\n",
        "    targets = tar[j*25:j*25+25]\n",
        "    err = 0\n",
        "    for k in range(25):\n",
        "      err += np.abs(elements[k]-targets[k])\n",
        "    mean_error[j] = err/25\n",
        "  error_matrix_alpha_1_GD.append(mean_error)"
      ],
      "metadata": {
        "id": "AcrJmAml12UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "og_dist = 1680\n",
        "print(\"RESULTS FOR ORIGINAL DISTANCE:\", og_dist)\n",
        "a = test_results(model_ann,X_mod,Y_mod)"
      ],
      "metadata": {
        "id": "lezUIdyq206-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(error_matrix_alpha_1_GD,open(path+\"/modifiedData/GD/EM_alpha0.5.pkl\",\"wb\"))"
      ],
      "metadata": {
        "id": "dpkqkGL815wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Z Score"
      ],
      "metadata": {
        "id": "ymVhFUeM17aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Old path\n",
        "#path_modified = path+'/modifiedData/Z/alpha1.csv'\n",
        "\n",
        "path_modified = path+'/modifiedData/Z/Z_alpha_1.csv'\n",
        "df_modified = pd.read_csv(path_modified)"
      ],
      "metadata": {
        "id": "iHos-EUo2CZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_matrix_alpha_1_Z = []\n",
        "for i in range(24):\n",
        "  interest = 25-(i+1)\n",
        "  idx1 = sum([x for x in range(interest+1,25)])*25\n",
        "  idx2 = idx1 + interest*25\n",
        "  points = df_modified.iloc[idx1:idx2,]\n",
        "  X_mod, Y_mod = modify_data(points, False)\n",
        "  aux = test_results(model_ann,X_mod,Y_mod,log = False)\n",
        "  aux = sc_output.inverse_transform(aux.reshape(1,-1))[0]\n",
        "  tar = sc_output.inverse_transform(Y_mod.reshape(1,-1))[0]\n",
        "  mean_error = [0 for _ in range(interest)]\n",
        "  for j in range(interest):\n",
        "    elements = aux[j*25:j*25+25]\n",
        "    targets = tar[j*25:j*25+25]\n",
        "    err = 0\n",
        "    for k in range(25):\n",
        "      err += np.abs(elements[k]-targets[k])\n",
        "    mean_error[j] = err/25\n",
        "  error_matrix_alpha_1_Z.append(mean_error)"
      ],
      "metadata": {
        "id": "EX1ZFSwi2D4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "og_dist = 1680\n",
        "print(\"RESULTS FOR ORIGINAL DISTANCE:\", og_dist)\n",
        "a = test_results(model_ann,X_mod,Y_mod)"
      ],
      "metadata": {
        "id": "Dr0GWs9z2m9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(error_matrix_alpha_1_Z,open(path+\"/modifiedData/Z/EM_alpha0.5.pkl\",\"wb\"))"
      ],
      "metadata": {
        "id": "9qAX_urP2IO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis"
      ],
      "metadata": {
        "id": "xc5HO1s32jjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path=path+\"/trainingData\"\n",
        "file_name=\"training_data.csv\"\n",
        "df_train=pd.read_csv(data_path+'/'+file_name)\n",
        "\n",
        "file_name=\"testing_data.csv\"\n",
        "df_test=pd.read_csv(data_path+'/'+file_name)\n",
        "\n",
        "print(\"DF train shape:\",df_train.shape)\n",
        "print(\"DF test shape:\",df_test.shape)\n",
        "\n",
        "global distances \n",
        "distances = [80*i for i in range(1,26)]"
      ],
      "metadata": {
        "id": "oWfVa1wY27l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install shap\n",
        "import shap\n",
        "\n",
        "# print the JS visualization code to the notebook\n",
        "shap.initjs()"
      ],
      "metadata": {
        "id": "UHQgVMOc28_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots"
      ],
      "metadata": {
        "id": "MUUAVAxz3AVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def var_boxplot(df):\n",
        "  total_items = len(df.columns)\n",
        "  items_per_row = 4\n",
        "  total_rows = math.ceil(total_items / items_per_row)\n",
        "\n",
        "\n",
        "  fig = make_subplots(rows=total_rows, cols=items_per_row)\n",
        "\n",
        "  cur_row = 1\n",
        "  cur_col = 1\n",
        "\n",
        "  for index, column in enumerate(df.columns):\n",
        "      fig.add_trace(go.Box(y=df[column], name=column), row=cur_row, col=cur_col)\n",
        "      \n",
        "      if cur_col % items_per_row == 0:\n",
        "          cur_col = 1\n",
        "          cur_row = cur_row + 1\n",
        "      else:\n",
        "          cur_col = cur_col + 1\n",
        "      fig.update_layout(height=1000, width=750,  showlegend=False)\n",
        "  fig.show() "
      ],
      "metadata": {
        "id": "5IJfK0XF2-cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def line_plots_and_params(df,pol_deg,plot = True):\n",
        "  total_items = len(df.columns)\n",
        "  items_per_row = 3\n",
        "  total_rows = math.ceil(total_items / items_per_row)\n",
        "\n",
        "  fig = make_subplots(rows=total_rows, cols=items_per_row, subplot_titles=df.columns)\n",
        "\n",
        "  cur_row = 1\n",
        "  cur_col = 1\n",
        "\n",
        "  parameters = {}\n",
        "\n",
        "  for index, column in enumerate(df.columns):\n",
        "      fig.add_trace(go.Scattergl(y=df[column], \n",
        "                              x=df['dist'], \n",
        "                              mode=\"markers\", \n",
        "                              marker=dict(size=3)), \n",
        "                    row=cur_row, \n",
        "                    col=cur_col)\n",
        "      \n",
        "      fit = np.polyfit(df['dist'], df[column],pol_deg)\n",
        "      poly = np.poly1d(fit)\n",
        "      intercept = poly(np.unique(df_train['dist']))\n",
        "      parameters[column] = poly\n",
        "      \n",
        "      fig.add_trace(go.Scatter(x=np.unique(df[\"dist\"]), \n",
        "                              y=intercept, \n",
        "                              line=dict(color='red', width=1)), \n",
        "                    row=cur_row, \n",
        "                    col=cur_col)\n",
        "      \n",
        "      if cur_col % items_per_row == 0:\n",
        "          cur_col = 1\n",
        "          cur_row = cur_row + 1\n",
        "      else:\n",
        "          cur_col = cur_col + 1\n",
        "      fig.update_layout(height=2500, width=1850, showlegend=False)\n",
        "  if plot: fig.show()\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "GAnIRpDw3DDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = line_plots_and_params(df_train,5,plot=True)"
      ],
      "metadata": {
        "id": "fVyuI27f3FII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Analysis"
      ],
      "metadata": {
        "id": "8RaDNqZ73Pd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "names = df_test.columns[1:]\n",
        "explainer = shap.KernelExplainer(model_ann.model, X_train[:100])\n",
        "shap_values = explainer.shap_values(X_test[:100])\n",
        "shap.summary_plot(shap_values, X_test, plot_type='bar',feature_names=names )"
      ],
      "metadata": {
        "id": "dRzPE3Rm3RNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}