{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOU1D9JCd80bSqJiELHf722",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0N3ldrt/Thesis/blob/main/new_training_CNN_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traininig CNN Spectrum"
      ],
      "metadata": {
        "id": "UT4kgsEJEpyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Necesary Libraries"
      ],
      "metadata": {
        "id": "qsIzw6RGEwWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0YnA2ltpEoSi"
      },
      "outputs": [],
      "source": [
        "# Importing necesary libraries\n",
        "# Libraries for correct code execution \n",
        "\n",
        "import os, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import csv\n",
        "import re\n",
        "import array\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from functools import reduce\n",
        "from random import random, gauss\n",
        "from math import modf, pi, cos, sin, sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.stats.stats import pearsonr\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import os, time, math, csv, joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import os, time, math, csv, joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Enviroment"
      ],
      "metadata": {
        "id": "o99IEHDfE2yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE PARA USAR DESDE COLAB\n",
        "\n",
        "# Google drive loading as work station for local-usage of the files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount= True)\n",
        "\n",
        "#-----------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruXEP78XE7E5",
        "outputId": "face70ce-370e-4338-c611-40e2b114f602"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para cambiar los paths rapido.\n",
        "workers = [\"Ronald\", \"Local\"]\n",
        "\n",
        "# Change the number to change the paths.\n",
        "worker = workers[0]\n",
        "\n",
        "if worker == \"Ronald\":\n",
        "  path = \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset\"\n",
        "else: path = os.getcwd()"
      ],
      "metadata": {
        "id": "1Y2-m9DsE74Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create training/testing df"
      ],
      "metadata": {
        "id": "-vRA8ls1E-rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rand(start, end, num): # get random value function\n",
        "    res = []\n",
        "    for j in range(num):\n",
        "        res.append(np.random.randint(start, end))\n",
        "    return res"
      ],
      "metadata": {
        "id": "JmxzxqJgFyk0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_freq_behavior(working_df, selected_point, multi=False): # Individual freq calculator\n",
        "  extra_data = working_df.iloc[:, 0:6]\n",
        "  freq_selected = working_df.iloc[:, selected_point+6]\n",
        "\n",
        "  freq_data_df = pd.merge(extra_data, freq_selected, left_index=True, right_index=True)\n",
        "  freq_data_df['Distance_km'] = freq_data_df['Distance_km'].astype(int)\n",
        "\n",
        "  headers = list(freq_data_df.columns.values)\n",
        "  selected_val = round(float(headers[-1]), 5)\n",
        "\n",
        "  distances = [x*80 for x in range(1, 26)]\n",
        "  freq_behavior = {}\n",
        "  f_behavior = {}\n",
        "\n",
        "  for dist in distances: # loop all distances available\n",
        "\n",
        "    distance_df = freq_data_df[(freq_data_df['Distance_km'] == dist)] # select all the row with current eval distance\n",
        "    freq_distance_vals = distance_df[str(selected_val)].tolist()\n",
        "\n",
        "    freq_mean = np.mean(freq_distance_vals)\n",
        "    freq_std = np.std(freq_distance_vals)\n",
        "    results = (freq_mean, freq_std)\n",
        "    f_behavior[dist] = results\n",
        "\n",
        "  freq_behavior[selected_val] = f_behavior\n",
        "  return freq_behavior"
      ],
      "metadata": {
        "id": "1772AwU6F1li"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_eval_cols(working_df, eval_cols_param): # retturn index of column to be evaluated\n",
        "  if eval_cols_param[0] == 'even': \n",
        "    break_point = int((working_df.shape[1]-6)/(eval_cols_param[1]+1))\n",
        "    selected_cols = []\n",
        "    for col_idx in range(1, eval_cols_param[1]+1):\n",
        "      selected_cols.append((col_idx*break_point)-1)\n",
        "  else:\n",
        "    selected_cols = rand(1, working_df.shape[1]-6, eval_cols_param[1])\n",
        "    selected_cols = sorted(selected_cols)\n",
        "  return selected_cols"
      ],
      "metadata": {
        "id": "K4iYZAsvLE_s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multi_params = (method, number_freq_to_analyze)\n",
        "def multiple_freq_analyzer(working_df, multi_params): #method = 'rand' or 'even' (multiple freq behavior calculator)\n",
        "  selected_cols = select_eval_cols(working_df, multi_params)\n",
        "\n",
        "  multi_freq_behavior = {}\n",
        "  for selected_point in tqdm(selected_cols):\n",
        "    freq_behavior = calc_freq_behavior(working_df, selected_point)\n",
        "    selected_v = [v for v in freq_behavior.keys()]\n",
        "\n",
        "    selected_d = {}\n",
        "    for data in freq_behavior.values():\n",
        "      for k, v in data.items():\n",
        "        selected_d[k] = v\n",
        "\n",
        "    multi_freq_behavior[selected_v[0]] = selected_d\n",
        "  return multi_freq_behavior"
      ],
      "metadata": {
        "id": "0u77CgndFpMU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def freq_dict_to_df(multi_freq_behavior):\n",
        "  distances = [x*80 for x in range(1, 26)]\n",
        "  freq_mean_data = {'distances':distances}\n",
        "  freq_std_data = {'distances':distances}\n",
        "\n",
        "  for header, distances_dict in multi_freq_behavior.items():\n",
        "    col_data_mean = []\n",
        "    col_data_std = []\n",
        "    for distance, results in distances_dict.items():\n",
        "      col_data_mean.append(results[0])\n",
        "      col_data_std.append(results[1])\n",
        "    freq_mean_data[header] = col_data_mean\n",
        "    freq_std_data[header] = col_data_std\n",
        "\n",
        "  freq_mean_df = pd.DataFrame(freq_mean_data)\n",
        "  freq_std_df = pd.DataFrame(freq_std_data)\n",
        "  \n",
        "  return freq_mean_df, freq_std_df"
      ],
      "metadata": {
        "id": "ujrIKsPLI8ST"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pearson Correletion"
      ],
      "metadata": {
        "id": "-iTYBjVZ3OLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#eval_method = 'avg' or 'min' or 'max'\n",
        "\n",
        "def pearson_matrix(working_df , source_sample_id):\n",
        "  distances = [x*80 for x in range(1, 26)]\n",
        "  result_data = {'source/target': distances}\n",
        "  \n",
        "  for target_dist in tqdm(distances): # loop all distances available\n",
        "    min_result_target = []\n",
        "    avg_result_target = []\n",
        "    max_result_target = []\n",
        "    for source_dist in distances: # loop all distances available\n",
        "      source_df = working_df[(working_df['Distance_km'] == source_dist) & (working_df['PBRS_id'] == source_sample_id)]# select data of source (distance and sample_id) \n",
        "      source_data = source_df.iloc[0, 6:source_df.shape[1]].tolist()\n",
        "      pearson_values = []\n",
        "      for target_sample_id in working_df['PBRS_id'].unique(): # loop all samples id to then exclude the source sample id\n",
        "        if target_sample_id != source_sample_id:\n",
        "          target_df = working_df[(working_df['Distance_km'] == target_dist) & (working_df['PBRS_id'] == target_sample_id)] # select data of target\n",
        "          target_data = target_df.iloc[0, 6:target_df.shape[1]].tolist()\n",
        "          pearson_values.append(round(pearsonr(source_data, target_data)[0], 5)) # pearson correlation\n",
        "      \n",
        "      avg_result_target.append(np.mean(pearson_values))    \n",
        "      max_result_target.append(np.max(pearson_values))\n",
        "      min_result_target.append(np.min(pearson_values))\n",
        "      \n",
        "    result_data['min_'+str(target_dist)] = min_result_target\n",
        "    result_data['avg_'+str(target_dist)] = avg_result_target\n",
        "    result_data['max_'+str(target_dist)] = max_result_target\n",
        "\n",
        "  pearson_matrix_df = pd.DataFrame.from_dict(result_data)\n",
        "  #pearson_matrix_df = pearson_matrix_df.set_index('source/target')\n",
        "\n",
        "  return pearson_matrix_df, result_data"
      ],
      "metadata": {
        "id": "KJkVm8Fs3NeI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean/std analysis"
      ],
      "metadata": {
        "id": "FlVr8zYP40rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_freq_behavior(working_df, selected_point): # Individual freq calculator\n",
        "  extra_data = working_df.iloc[:, 0:6]\n",
        "  freq_selected = working_df.iloc[:, selected_point+6]\n",
        "\n",
        "  freq_data_df = pd.merge(extra_data, freq_selected, left_index=True, right_index=True)\n",
        "  freq_data_df['Distance_km'] = freq_data_df['Distance_km'].astype(int)\n",
        "\n",
        "  headers = list(freq_data_df.columns.values)\n",
        "  selected_val = round(float(headers[-1]), 5)\n",
        "\n",
        "  distances = [x*80 for x in range(1, 26)]\n",
        "  freq_behavior = {}\n",
        "  f_behavior = {}\n",
        "\n",
        "  for dist in distances: # loop all distances available\n",
        "\n",
        "    distance_df = freq_data_df[(freq_data_df['Distance_km'] == dist)] # select all the row with current eval distance\n",
        "    freq_distance_vals = distance_df[str(selected_val)].tolist()\n",
        "\n",
        "    freq_mean = np.mean(freq_distance_vals)\n",
        "    freq_std = np.std(freq_distance_vals)\n",
        "    results = (freq_mean, freq_std)\n",
        "    f_behavior[dist] = results\n",
        "  freq_behavior[selected_val] = f_behavior\n",
        "  return freq_behavior"
      ],
      "metadata": {
        "id": "z1PxUXA_43zG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_freq_behavior_v2(working_df, amt_of_selected_point): # Individual freq calculator\n",
        "  extra_data = working_df.iloc[:, 0:6]\n",
        "\n",
        "  distances = [x*80 for x in range(1, 26)]\n",
        "\n",
        "  std_combined = []\n",
        "  for dist in distances: # loop all distances available\n",
        "    std_all = []\n",
        "    for val_idx in range(0, amt_of_selected_point):\n",
        "\n",
        "      freq_selected = working_df.iloc[:, val_idx+6]\n",
        "      freq_data_df = pd.merge(extra_data, freq_selected, left_index=True, right_index=True)\n",
        "      freq_data_df['Distance_km'] = freq_data_df['Distance_km'].astype(int)\n",
        "\n",
        "      headers = list(freq_data_df.columns.values)\n",
        "      selected_val = round(float(headers[-1]), 5)\n",
        "      \n",
        "      distance_df = freq_data_df[(freq_data_df['Distance_km'] == dist)] # select all the row with current eval distance\n",
        "      freq_distance_vals = distance_df[str(selected_val)].tolist()\n",
        "\n",
        "      freq_std = np.std(freq_distance_vals)\n",
        "      std_all.append(freq_std)\n",
        "      std_avg = round(np.average(std_all), 5)\n",
        "    std_combined.append(std_avg)\n",
        "\n",
        "\n",
        "  data = {'source/target':distances, 'std':std_combined}\n",
        " \n",
        "  # Create DataFrame\n",
        "  std_df = pd.DataFrame(data)\n",
        "  return std_df"
      ],
      "metadata": {
        "id": "4oOLCr9ZmJey"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get features \n",
        "def get_features(eval_freq_data_df, amt_sel_points):\n",
        "  # get pearson values\n",
        "  pearson_matrix_df, result_data = pearson_matrix(eval_freq_data_df, source_sample_id=1)\n",
        "\n",
        "  # get std values\n",
        "  std_df = calc_freq_behavior_v2(eval_freq_data_df, amt_of_selected_point = amt_sel_points)\n",
        "\n",
        "  final_df = pd.merge(pearson_matrix_df, std_df, on = \"source/target\", how = \"inner\")\n",
        "  return final_df"
      ],
      "metadata": {
        "id": "bR0YRqkWl7hY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(working_df, amt_train = 0.8):\n",
        "  print('Creating train/test split:')\n",
        "  num_sample_train = math.ceil((working_df.shape[1]-6)*amt_train)\n",
        "  num_sample_test = (working_df.shape[1]-6) - num_sample_train\n",
        "\n",
        "  multi_params = ('rand', num_sample_train)  # (evenly separate points(other option 'rand'for randomly selected points), mount of points to be selected)\n",
        "  multi_freq_behavior = multiple_freq_analyzer(working_df, multi_params)\n",
        "\n",
        "  eval_points = select_eval_cols(working_df, multi_params) # get indexes of of points to be evaluated\n",
        "  real_eval_idx = [eval_point+6 for eval_point in eval_points]\n",
        "\n",
        "  extra_data = working_df.iloc[:, 0:6]\n",
        "  eval_freq_df = working_df.iloc[:, real_eval_idx]\n",
        "  train_df = pd.merge(extra_data, eval_freq_df, left_index=True, right_index=True) #df we only eval freqs TRAIN\n",
        "\n",
        "  test_df= working_df.copy()\n",
        "  test_df.drop(test_df.columns[real_eval_idx], axis=1, inplace=True) # df without eval freqs TEST\n",
        "  return train_df, test_df"
      ],
      "metadata": {
        "id": "5ZXdVyj7mQZv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run train/test split"
      ],
      "metadata": {
        "id": "1NQbJ_HZP9-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = path + \"/Spectrum/CNN/working_df.csv\"\n",
        "\n",
        "working_df = pd.read_csv(input_path)\n",
        "working_df['Distance_km'] = working_df['Distance_km'].astype(int)\n",
        "\n",
        "train_df, test_df = train_test_split(working_df, amt_train = 0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Buf7Y8-P88B",
        "outputId": "258ce8a3-e44c-4db9-b2cb-685ef14d6e18"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating train/test split:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1654/1654 [00:43<00:00, 38.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('------------------------------')\n",
        "# Get features \n",
        "print('Calculating features for train set:')\n",
        "train_features_df = get_features(train_df, train_df.shape[1]-6)\n",
        "print('------------------------------')\n",
        "print('Calculating features for test set:')\n",
        "test_features_df = get_features(test_df, test_df.shape[1]-6)\n",
        "\n",
        "#final_final_df.to_csv(path+'/Spectrum/CNN/training_data_DNN.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K8RvbegRMk2",
        "outputId": "f9d514cf-c56b-4175-b921-0db576bfa008"
      },
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating train/test split:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1654/1654 [00:28<00:00, 57.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Calculating features for train set:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:22<00:00,  1.11it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Calculating features for test set:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:12<00:00,  2.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_df.to_csv(path+'/Spectrum/CNN/training_data_DNN.csv')"
      ],
      "metadata": {
        "id": "Zb84UW7mLgIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_features_df.to_csv(path+'/Spectrum/CNN/testing_data_DNN.csv')"
      ],
      "metadata": {
        "id": "IIsMASaZLgVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "CGa0J5JcS-BW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ],
      "metadata": {
        "id": "eydWoJNWTEGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_df=pd.read_csv(path+'/Spectrum/CNN/training_data_DNN.csv')"
      ],
      "metadata": {
        "id": "qxSBXWpQV3Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_df=pd.read_csv(path+'/Spectrum/CNN/testing_data_DNN.csv')"
      ],
      "metadata": {
        "id": "TWEnupmBK9jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = training_df.iloc[:, 1].to_numpy().reshape(-1,1)\n",
        "X = training_df.iloc[:, 2:training_df.shape[1]]\n",
        "\n",
        "sc_input = MinMaxScaler()\n",
        "sc_output = MinMaxScaler()\n",
        "X_train = sc_input.fit_transform(X) # convert features to values from 0 to 1\n",
        "Y_train = sc_output.fit_transform(Y) # convert distances to values from 0 to 1"
      ],
      "metadata": {
        "id": "ZEGP4I1lTDZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "pdv_LIJAV6YX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "def ann():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(76, input_dim = 76, activation = 'tanh'))\n",
        "    model.add(Dense(38,activation='tanh'))\n",
        "    model.add(Dense(19,activation='tanh'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss ='mean_squared_error',optimizer = 'RMSprop')\n",
        "    return model\n",
        "\n",
        "\n",
        "model_ann = KerasRegressor(build_fn=ann,epochs=5000,batch_size=32)\n",
        "\n",
        "start_time = time.time()\n",
        "callback = EarlyStopping(monitor='loss', patience=500)\n",
        "model_ann.fit(X_train, Y_train, callbacks=[callback])\n",
        "time_train_ann = time.time() - start_time"
      ],
      "metadata": {
        "id": "E3baz5KzV4mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model"
      ],
      "metadata": {
        "id": "_CRKziCqWmH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_df=pd.read_csv(path+'/Spectrum/CNN/testing_data_DNN.csv')\n",
        "\n",
        "Y = testing_df.iloc[:, 1].to_numpy().reshape(-1,1)\n",
        "X = testing_df.iloc[:, 2:testing_df.shape[1]]\n",
        "\n",
        "\n",
        "sc_input = MinMaxScaler()\n",
        "sc_output = MinMaxScaler()\n",
        "X_test = sc_input.fit_transform(X) # convert features to values from 0 to 1\n",
        "Y_test = sc_output.fit_transform(Y) # convert distances to values from 0 to 1"
      ],
      "metadata": {
        "id": "m_BQ4VC63NeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = sc_input.transform(X)  #convert features two values between 0 and 1\n",
        "Y_test = sc_output.transform(Y) #convert distances two values between 0 and 1\n",
        "\n",
        "start_time = time.time()\n",
        "Y_test_pred=model_ann.predict(X_test)\n",
        "\n",
        "time_eval_ann=time.time()-start_time\n",
        "\n",
        "real=list(list(zip(*Y_test))[0])\n",
        "\n",
        "#real=list(map(list, zip(*Y_train)))\n",
        "pred=list(Y_test_pred)\n",
        "print(pred)\n",
        "\n",
        "\n",
        "dist_min=sc_output.data_min_[0] # 80\n",
        "dist_max=sc_output.data_max_[0] # 2000\n",
        "\n",
        "#np.add = add values in a array\n",
        "#np.multiply multiple values in a array\n",
        "print(real)\n",
        "real_abs=np.add(dist_min,np.multiply((dist_max-dist_min),real)) # convert back to distances values from scalar\n",
        "real_abs=[int(np.round(i)) for i in real_abs]\n",
        "#print(real_abs)\n",
        "pred_abs=np.add(dist_min,np.multiply((dist_max-dist_min),pred)) # convert back to distances values from scalar\n",
        "#print(pred_abs)\n",
        "\n",
        "#np.divide = divide values in a array\n",
        "error=np.divide(np.abs(np.subtract(np.array(real_abs),np.array(pred_abs))),np.array(real_abs))\n",
        "\n",
        "res=pd.DataFrame({\"dist\":real_abs,\"pred\":pred_abs,\"error\":error})\n",
        "display(res)\n",
        "res.to_csv(\"results_pme_supervisedFeatures.csv\", header=True, index=False)\n",
        "plt.plot(real_abs,error,'bo')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kxG4WaGnWkXj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}