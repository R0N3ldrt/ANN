{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPr2IWKS2MyZLZffLeZdIkn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0N3ldrt/Thesis/blob/main/Feature_Mimic_2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading enviroment and required libraries "
      ],
      "metadata": {
        "id": "cYXBKmqyLiKs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XvqJSygLSEu"
      },
      "outputs": [],
      "source": [
        "# Importing necesary libraries\n",
        "\n",
        "import math\n",
        "import pickle\n",
        "import os, time\n",
        "import numpy as np\n",
        "import collections\n",
        "import pandas as pd\n",
        "from os.path import exists\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google drive loading as work station for local-usage of the files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount= True)\n",
        "\n",
        "#-----------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "Gm-nssvJLa59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para cambiar los paths rapido.\n",
        "workers = [\"Ronald\", \"Local\"]\n",
        "\n",
        "# Cambiar el numero aqui para cambiar los paths.\n",
        "worker = workers[0]\n",
        "\n",
        "if worker == \"Ronald\":\n",
        "  path= \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset\"\n",
        "else: path = os.getcwd()"
      ],
      "metadata": {
        "id": "NqW-7OpZMfdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-procesing"
      ],
      "metadata": {
        "id": "dQYBQZ_dMQSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global distances \n",
        "distances = [80*i for i in range(1,26)]\n",
        "\n",
        "global sc_input, sc_output\n",
        "sc_input = MinMaxScaler()\n",
        "sc_output = MinMaxScaler()"
      ],
      "metadata": {
        "id": "spCmDUR-NFpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating train and test files\n",
        "df_train=pd.read_csv(path+'trainingData/training_data.csv')\n",
        "df_test=pd.read_csv(path+'trainingData/testing_data.csv')\n",
        "\n",
        "def modify_data(df, train):\n",
        "  # Function that converts the provided data frame into target and explicative variables.\n",
        "  colnames=df.columns[1:25]\n",
        "  X=df.iloc[:,1:25]\n",
        "  Y=df.iloc[:,0].to_numpy().reshape(-1,1)\n",
        "  if train: \n",
        "    X = sc_input.fit_transform(X)\n",
        "    Y = sc_output.fit_transform(Y)\n",
        "  else: \n",
        "    X = sc_input.transform(X)\n",
        "    Y = sc_output.transform(Y)\n",
        "  return X,Y\n",
        "\n",
        "X_train,Y_train = modify_data(df_train, True)\n",
        "X_test, Y_test = modify_data(df_test, False)"
      ],
      "metadata": {
        "id": "0-eCCQOqLfcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_train(X_train,Y_train):\n",
        "  #NN Model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim = 24, activation = 'tanh'))\n",
        "  model.add(Dense(6,activation='tanh'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss ='mean_squared_error',optimizer = 'RMSprop')\n",
        "  \n",
        "  #Generate model\n",
        "  model_ann = KerasRegressor(build_fn=ann,epochs=500,batch_size=32)\n",
        "\n",
        "  #Train model\n",
        "  start_time = time.time()\n",
        "  callback = EarlyStopping(monitor='loss', patience=500)\n",
        "  model_ann.fit(X_train, Y_train, callbacks=[callback])\n",
        "  time_train_ann = time.time() - start_time\n",
        "  return model_ann"
      ],
      "metadata": {
        "id": "8ya8A2w6SZUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_NNmodel()\n",
        "  file_exists = exists(path_to_file)"
      ],
      "metadata": {
        "id": "X3OY2mVrSc9V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}