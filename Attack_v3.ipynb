{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxLjXQqdvZXhHrV6j4Uzfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0N3ldrt/Thesis/blob/main/Attack_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack"
      ],
      "metadata": {
        "id": "eDgG4ygA9GDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "xsbnWao69DFZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hAWCVcJ_8_zo"
      },
      "outputs": [],
      "source": [
        "# Importing necesary libraries\n",
        "# Libraries for correct code execution \n",
        "\n",
        "import os, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import csv\n",
        "import re\n",
        "import array\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from functools import reduce\n",
        "from random import random, gauss\n",
        "from math import modf, pi, cos, sin, sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.stats.stats import pearsonr\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import os, time, math, csv, joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import os, time, math, csv, joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Enviroment"
      ],
      "metadata": {
        "id": "CJ_c-LNY9Kft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE PARA USAR DESDE COLAB\n",
        "\n",
        "# Google drive loading as work station for local-usage of the files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount= True)\n",
        "\n",
        "#-----------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt_uvFYn9L8g",
        "outputId": "94c3a697-6979-42ef-960c-a5074badda7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para cambiar los paths rapido.\n",
        "workers = [\"Ronald\", \"Local\"]\n",
        "\n",
        "# Change the number to change the paths.\n",
        "worker = workers[0]\n",
        "\n",
        "if worker == \"Ronald\":\n",
        "  path = \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset\"\n",
        "else: path = os.getcwd()"
      ],
      "metadata": {
        "id": "31nM5w3n9Oy-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-procesing"
      ],
      "metadata": {
        "id": "T54BySkf9PSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = path + \"/Spectrum/CNN/new_working_df.csv\"\n",
        "\n",
        "working_df = pd.read_csv(input_path)\n",
        "working_df['Distance_km'] = working_df['Distance_km'].astype(int)"
      ],
      "metadata": {
        "id": "qjLmjjay9olo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "ZK6vWbBE-t_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Train/Test data"
      ],
      "metadata": {
        "id": "plX57BW7-vjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(input_data_path, distances, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  X=None\n",
        "  Y=[]\n",
        "  colnames=['i'+str(i) for i in range(nsymbols)]\n",
        "\n",
        "  for d in distances:\n",
        "    dist=d*span_length\n",
        "    if dist<min_dist or dist>max_dist: continue\n",
        "    filename='consts_'+str(d)+'span.csv'\n",
        "    df_aux=pd.read_csv(input_data_path+'/'+filename, sep=\",\", header=None)\n",
        "    df_aux = df_aux.T\n",
        "    df_aux.columns=colnames\n",
        "    Y=Y+[dist]*df_aux.shape[0]\n",
        "    if X is None: X=df_aux\n",
        "    else: X=X.append(df_aux)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "LkM3LI3c-yY5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df_v2(working_df, distances, nsymbols = 2048, span_length=80, min_dist = 0, max_dist = 3000):\n",
        "  X=None\n",
        "  Y=np.array([])\n",
        "\n",
        "  for d in distances:\n",
        "    distance_working_df = working_df.loc[working_df['Distance_km'] == d]\n",
        "    \n",
        "    d_df = distance_working_df.iloc[:, 3].to_numpy()\n",
        "    data_df = distance_working_df.iloc[:, 6:distance_working_df.shape[1]]\n",
        "    Y = np.append(Y, d_df)\n",
        "\n",
        "    if X is None: X=data_df\n",
        "    else: X=X.append(data_df)\n",
        "  Y = Y.astype('int').tolist()\n",
        "\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "nkwW-mY1A3Rh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input_data_path=path+\"/rawData\"\n",
        "#distances=[i for i in range(1,26)]\n",
        "distances = [x*80 for x in range(1, 26)]\n",
        "X, Y = create_df_v2(working_df, distances, nsymbols = 2048, span_length=80,  min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "4bPWvrM1AVZt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_path=path+\"/rawData\"\n",
        "distances=[i for i in range(1,26)]\n",
        "\n",
        "X, Y = create_df(input_data_path, distances, nsymbols = 2048, span_length=80,  min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "h9aC3hQmokGc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v2():\n",
        "  train_idxs2 = []\n",
        "  test_idxs2 = []\n",
        "  for i in range(25):\n",
        "      for j in range(25):\n",
        "          test_idxs2.append(50*(i+1)-1-j)\n",
        "\n",
        "  for i in range(25):\n",
        "    for j in range(2):\n",
        "      train_idxs2.append(50*i + j)\n",
        "  return train_idxs2, test_idxs2"
      ],
      "metadata": {
        "id": "YE70OaQlsvw6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_idx_train_test_split(working_df, distances, trainingProp = 0.8):\n",
        "\n",
        "  rows_training = np.array([])\n",
        "  rows_testing = np.array([])\n",
        "  for d in distances:  \n",
        "    distance_working_df = working_df.loc[working_df['Distance_km'] == d]\n",
        "\n",
        "    rows_mixed=np.random.permutation(distance_working_df.shape[0])\n",
        "\n",
        "    training_amt = math.ceil(distance_working_df.shape[0]*trainingProp)\n",
        "    testing_amt = distance_working_df.shape[0] - training_amt\n",
        "\n",
        "    rows_training = np.append(rows_training, rows_mixed[:training_amt])\n",
        "    rows_testing = np.append(rows_testing, rows_mixed[-testing_amt:])\n",
        "  \n",
        "  rows_training = rows_training.astype('int').tolist()\n",
        "  rows_testing = rows_testing.astype('int').tolist()\n",
        "\n",
        "  return rows_training, rows_testing"
      ],
      "metadata": {
        "id": "T1OxCIhstvBf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows_training, rows_testing = get_idx_train_test_split(working_df, distances, trainingProp = 0.8)"
      ],
      "metadata": {
        "id": "bnO-ov2iuCmR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GD"
      ],
      "metadata": {
        "id": "wC9AhJ8TrZb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent Function"
      ],
      "metadata": {
        "id": "AgTh4Vk3--dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_b (M,m_og,m_tg,b,beta):\n",
        "  return 2*beta*(M @ m_og + b - m_tg)"
      ],
      "metadata": {
        "id": "q8woGUzl-9hs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_M(M,cov_og,cov_tg,alpha):\n",
        "    error = M @ cov_og @ np.transpose(M) - cov_tg  \n",
        "\n",
        "    m1 = (2*error[0][0] * (2*cov_og[0][0]*M[0][0] + 2*cov_og[0][1]*M[0][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[1][0] + cov_og[0][1]*M[1][1]))\n",
        "    \n",
        "    m2 = (2*error[0][0] * (2*cov_og[1][1]*M[0][1] + 2*cov_og[0][1]*M[0][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[1][0] + cov_og[1][1]*M[1][1]))\n",
        "    \n",
        "    m3 = (2*error[1][1] * (2*cov_og[0][0]*M[1][0] + 2*cov_og[0][1]*M[1][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[0][0] + cov_og[0][1]*M[0][1]))\n",
        "\n",
        "    m4 = (2*error[1][1] * (2*cov_og[0][0]*M[1][1] + 2*cov_og[0][1]*M[1][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[0][0] + cov_og[1][1]*M[0][1]))\n",
        "    \n",
        "    return alpha*np.array([[m1, m2], [m3, m4]])"
      ],
      "metadata": {
        "id": "M9QYjER9_BBJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(alpha,beta,m_tg,m_og,cov_tg,cov_og,nu,log):\n",
        "  Ms = []\n",
        "  bs = []\n",
        "  M = np.random.rand(2,2)\n",
        "  #M = np.array([[1, 0], [0, 1]])\n",
        "  b = np.random.rand(2,1)\n",
        "  #b = np.array([[0], [0]])\n",
        "  #for i in range(100000):\n",
        "  i = 0\n",
        "  while True:\n",
        "    # print('From:', M @ cov_source @ np.transpose(M))\n",
        "    # print('To:', cov_target)\n",
        "    L = loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b) \n",
        "    if  L < 1e-20:\n",
        "        Ms.append(M)\n",
        "        bs.append(b)\n",
        "        break\n",
        "    b = b - nu*grad_b(M,m_og,m_tg,b,beta)\n",
        "    M = M - nu*grad_M(M,cov_og,cov_tg,alpha)\n",
        "    i+= 1\n",
        "    if (i>= 5000 and i <= 5025) or (i>= 5975 and i <= 6000):\n",
        "      Ms.append(M)\n",
        "      bs.append(b)\n",
        "    if not i%5000 and log: print(L)\n",
        "  if log: print(\"-\"*25)\n",
        "  return Ms,bs"
      ],
      "metadata": {
        "id": "EQwVHNaR_DRW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute parameters and mean/covariance"
      ],
      "metadata": {
        "id": "wJSQYPCd_GlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mean_and_cov(data):\n",
        "  aux_x = [] # Reales\n",
        "  aux_y = [] # Imag\n",
        "  for obs in data:\n",
        "    aux_x.append(obs[0])\n",
        "    aux_y.append(obs[1])\n",
        "  return np.array([[np.mean(aux_x)],[np.mean(aux_y)]]), np.cov(aux_x,aux_y)\n",
        "\n",
        "\n",
        "def total_loss(m_mod,m_tg,cov_mod,cov_tg):\n",
        "  return (sum(sum(np.power(cov_mod-cov_tg,2))) + sum(np.power(m_mod - m_tg,2)))[0]\n",
        "\n",
        "\n",
        "def loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b):\n",
        "  first = alpha*sum(sum(np.power(M @ cov_og @ np.transpose(M) - cov_tg, 2)))\n",
        "  second = beta*sum(np.power(M @ m_og + b - m_tg, 2))\n",
        "  a = first+second\n",
        "  return a"
      ],
      "metadata": {
        "id": "bg5fXgvY_HCh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_parameters (const,method,source,target, params = None, log = False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  q_target = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "\n",
        "    q_source += [[x.real,x.imag] for x in source.values.tolist()[i] if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "    q_target += [[x.real,x.imag] for x in target.values.tolist()[i]if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "\n",
        "  unbiased = (len(q_source)/(len(q_source)-1) * 125/126)\n",
        "\n",
        "  mean_source,cov_source = compute_mean_and_cov(q_source)\n",
        "  mean_target, cov_target= compute_mean_and_cov(q_target)\n",
        "\n",
        "  cov_source *= unbiased\n",
        "  cov_target *= unbiased\n",
        "\n",
        "  if method == \"GD\":\n",
        "    if (params is None):\n",
        "      alpha = 3/4\n",
        "      beta = 1/4\n",
        "    else:\n",
        "      alpha = params[\"alpha\"] if params[\"alpha\"]>0 and params[\"alpha\"]<=1 and params[\"alpha\"]>params[\"beta\"]  else 3/4\n",
        "      beta = params[\"beta\"] if params[\"beta\"]>=0 and params[\"beta\"]<1 and params[\"beta\"]<params[\"alpha\"]  else 1/4\n",
        "\n",
        "    M, b = gradient_descent(alpha,beta,mean_target,mean_source,cov_target,cov_source, 0.5,log)\n",
        "    return M,b\n",
        "\n",
        "  elif method == \"Z\":\n",
        "    return mean_source,cov_source,mean_target,cov_target"
      ],
      "metadata": {
        "id": "c3ZMthBM_KB6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify GD/Z"
      ],
      "metadata": {
        "id": "TqpqU4M0_ODy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_GD(const,source,M,b, target = None, return_plots=False):\n",
        "\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "      \n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  for mult in mults:\n",
        "    res = (M @ mult + b).tolist()\n",
        "\n",
        "    # --------- Old line ---------\n",
        "    #new_points.append([res[0][0],res[1][0]])\n",
        "    nested_check = any(isinstance(i, list) for i in res[0])\n",
        "    if nested_check:\n",
        "      new_points.append([res[0][0][0],res[0][1][0]])\n",
        "    else:\n",
        "      new_points.append([res[0][0],res[1][0]])\n",
        "\n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      return new_points, q_target\n",
        "\n",
        "  return new_points, indexes"
      ],
      "metadata": {
        "id": "E0uaG8YN_OPO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_Z(const,source,mean_source,cov_source,mean_target,cov_target,target = None, return_plots=False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "\n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  w, v = np.linalg.eig(cov_source)\n",
        "  S1 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "  w, v = np.linalg.eig(cov_target)\n",
        "  S2 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "\n",
        "  for mult in mults:\n",
        "    normalized = np.linalg.inv(S1) @ (mult - mean_source)\n",
        "    denormalized = S2 @ normalized + mean_target\n",
        "\n",
        "    new_points.append([denormalized[0][0], denormalized[1][0]])\n",
        "\n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      \n",
        "\n",
        "  return new_points, indexes"
      ],
      "metadata": {
        "id": "J-bim6du_Rzh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L2dist(a,b):\n",
        "    return math.sqrt(math.pow(a[0]-b[0],2)+math.pow(a[1]-b[1],2))"
      ],
      "metadata": {
        "id": "29pAANvx_Xkc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "corK2647_dol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symbol2symbol_main(method, quadrants, input_data_path, distances, output_path, params = None, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  \n",
        "  if (params is None):\n",
        "    output_features = \"/{}_alpha_75_beta_25_features.csv\".format(str(method))\n",
        "  else:\n",
        "    decimal_alpha = modf(params['alpha'])\n",
        "    decimal_alpha  = round(decimal_alpha[0], 2)\n",
        "    decimal_alpha = re.findall('..(.*)', str(decimal_alpha))[0]\n",
        "\n",
        "    decimal_beta = modf(params['beta'])\n",
        "    decimal_beta  = round(decimal_beta[0], 2)\n",
        "    decimal_beta = re.findall('..(.*)', str(decimal_beta))[0]\n",
        "\n",
        "    output_features = \"/{}_alpha_{}_beta{}_features.csv\".format(str(method), str(decimal_alpha), str(decimal_beta))\n",
        "\n",
        "  # Get input data\n",
        "  X, Y = create_df(input_data_path, distances, nsymbols, min_dist, max_dist)\n",
        "\n",
        "  X = X.applymap(strToTuple)\n",
        "\n",
        " \n",
        "  train_idxs2, test_idxs2 = test_train_indexes_v2()\n",
        "\n",
        "  X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "  X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\") \n",
        "\n",
        "  data_new = {}\n",
        "\n",
        "  for i in range(0,25):\n",
        "    data_new[str(80*(i+1))] = {\"Train\":X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}  \n",
        "\n",
        "  first = True\n",
        "  modify_all_data_df = pd.DataFrame()\n",
        "  for i in tqdm(range(25)):\n",
        "      print('\\n')\n",
        "      print(\"i = \",i)\n",
        "      modify_data_df = pd.DataFrame()\n",
        "      for j in range(i+1,25):\n",
        "          print(\" j = \",j)\n",
        "          source = data_new[str(distances[i]*80)]['Train']\n",
        "          target = data_new[str(distances[j]*80)]['Train']\n",
        "          source_test = data_new[str(distances[i]*80)]['Test']\n",
        "\n",
        "          source_test2 = source_test.copy()\n",
        "\n",
        "          for quadrant in quadrants:\n",
        "              print(\"   quadrant = \", quadrant)\n",
        "              if method == \"GD\":\n",
        "                M, b = compute_parameters(quadrant, 'GD', source, target, params=params)\n",
        "                new_points, indexes = modify_const_GD(quadrant, source_test, M, b)\n",
        "              elif method == \"Z\":\n",
        "                mean_source,cov_source,mean_target,cov_target = compute_parameters(quadrant, 'Z', source, target, params=None)\n",
        "                new_points, indexes = modify_const_Z(quadrant,source_test,mean_source,cov_source,mean_target,cov_target)\n",
        "\n",
        "              for k in range(len(indexes)):\n",
        "                  source_test2.iloc[indexes[k][0],indexes[k][1]] = complex(new_points[k][0], new_points[k][1])\n",
        "\n",
        "          F=[]\n",
        "          for k in range(source_test2.shape[0]):\n",
        "              data2=list(source_test2.iloc[k,:])\n",
        "              data2=[[float(d.real), float(d.imag)] for d in data2]\n",
        "              gmm = GaussianMixture(n_components=16, random_state=0, means_init=my_centers).fit(data2)\n",
        "              mus=gmm.means_\n",
        "              sigmas=gmm.covariances_\n",
        "\n",
        "              features=[distances[i]*80, distances[j]*80]\n",
        "\n",
        "              for z in selCP_pos:\n",
        "                  mindist=None\n",
        "                  k_inc=None\n",
        "                  for w in range(16):\n",
        "                      d=L2dist(mus[w],z)\n",
        "                      if mindist is None or mindist>d:\n",
        "                          mindist=d\n",
        "                          k_inc=w\n",
        "\n",
        "                  covmat=np.concatenate(list(sigmas[k_inc])).ravel().tolist()\n",
        "                  features = [*features, *mus[k_inc], *covmat]\n",
        "              F.append(features)\n",
        "          \n",
        "          header=['original_dist', 'target_dist']\n",
        "          \n",
        "          for j in selCP:\n",
        "              header=[*header,*['mu_r_'+str(j),'mu_i_'+str(j),'sigma_rr_'+str(j),'sigma_ri_'+str(j),'sigma_ir_'+str(j),'sigma_ii_'+str(j)]]\n",
        "   \n",
        "          with open(output_path + output_features, 'a', encoding='UTF8', newline='') as f:\n",
        "              writer = csv.writer(f)\n",
        "              # write the header\n",
        "              if first:\n",
        "                writer.writerow(header)\n",
        "                first = False\n",
        "              # write multiple rows\n",
        "              writer.writerows(F)   "
      ],
      "metadata": {
        "id": "KMd12eb7_dtN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strToTuple(s):\n",
        "    s_aux=s.split(\"i\")\n",
        "    s=s_aux[0]+\"j\"\n",
        "    return complex(s)\n",
        "\n",
        "def strToTuple_v2(s):\n",
        "    return complex(s)"
      ],
      "metadata": {
        "id": "zjSFyIF-Cyt7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v2():\n",
        "  train_idxs2 = []\n",
        "  test_idxs2 = []\n",
        "  for i in range(25):\n",
        "      for j in range(25):\n",
        "          test_idxs2.append(50*(i+1)-1-j)\n",
        "\n",
        "  for i in range(25):\n",
        "    for j in range(2):\n",
        "      train_idxs2.append(50*i + j)\n",
        "  return train_idxs2, test_idxs2"
      ],
      "metadata": {
        "id": "3fRiKPkhC1KR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE SELCET THE METHOD AND QUADRANTS THAT ARE DESIRED TO BE TESTED\n",
        "method = \"GD\" # or method = \"GD\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "\n",
        "#Output mod files\n",
        "output_path = path + '/modifiedData/'+ method\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))"
      ],
      "metadata": {
        "id": "afVIB3d9Cn2G",
        "outputId": "b46a2503-925b-424b-fd97-5983e78bbc70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath selected: /content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset/rawData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "\n",
        "distances=[i for i in range(1,26)]\n",
        "nsamples=50\n",
        "span_length=80\n",
        "nsymbols=2048\n",
        "\n",
        "######\n",
        "min_dist=0\n",
        "max_dist=3000\n",
        "selCP=[1,7,10,15]\n",
        "selCP_pos=[(-3,3),(1,1),(-1,-1),(1,-3)]\n",
        "my_centers=[[-3,3],[-1,3],[1,3],[3,3],[-3,1],[-1,1],[1,1],[3,1],[-3,-1],[-1,-1],[1,-1],[3,-1], [-3,-3],[-1,-3],[1,-3],[3,-3]]\n",
        "######"
      ],
      "metadata": {
        "id": "hCjqDq9YDoyL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol2symbol_main(method, quadrants, input_data_path, distances, output_path, params = None, nsymbols = 2048, min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "D39gQHCwCQjz",
        "outputId": "d65e2930-5314-45be-d111-17ef4ca607a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "i =  0\n",
            " j =  1\n",
            "   quadrant =  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-15e761c9ae11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msymbol2symbol_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadrants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsymbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-22cf5d82856b>\u001b[0m in \u001b[0;36msymbol2symbol_main\u001b[0;34m(method, quadrants, input_data_path, distances, output_path, params, nsymbols, min_dist, max_dist)\u001b[0m\n\u001b[1;32m     47\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   quadrant = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadrant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GD\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquadrant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mnew_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodify_const_GD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquadrant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m               \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Z\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-becd57eb7e3f>\u001b[0m in \u001b[0;36mcompute_parameters\u001b[0;34m(const, method, source, target, params, log)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-51b0d8a7148a>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(alpha, beta, m_tg, m_og, cov_tg, cov_og, nu, log)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_og\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_tg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_M\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_og\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_tg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0;36m5000\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m5025\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0;36m5975\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m6000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-189ca4b24a22>\u001b[0m in \u001b[0;36mgrad_M\u001b[0;34m(M, cov_og, cov_tg, alpha)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mcov_og\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcov_tg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     m1 = (2*error[0][0] * (2*cov_og[0][0]*M[0][0] + 2*cov_og[0][1]*M[0][1]) +\n\u001b[0m\u001b[1;32m      5\u001b[0m           2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[1][0] + cov_og[0][1]*M[1][1]))\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main v2"
      ],
      "metadata": {
        "id": "OOQABumrw5ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data_path = path + \"/Spectrum/CNN/new_working_df.csv\"\n",
        "def symbol2symbol_main_v2(method, quadrants, input_data_path, distances, output_path, params = None, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  \n",
        "  if (params is None):\n",
        "    output_features = \"/{}_alpha_75_beta_25_features.csv\".format(str(method))\n",
        "  else:\n",
        "    decimal_alpha = modf(params['alpha'])\n",
        "    decimal_alpha  = round(decimal_alpha[0], 2)\n",
        "    decimal_alpha = re.findall('..(.*)', str(decimal_alpha))[0]\n",
        "\n",
        "    decimal_beta = modf(params['beta'])\n",
        "    decimal_beta  = round(decimal_beta[0], 2)\n",
        "    decimal_beta = re.findall('..(.*)', str(decimal_beta))[0]\n",
        "\n",
        "    output_features = \"/{}_alpha_{}_beta{}_features.csv\".format(str(method), str(decimal_alpha), str(decimal_beta))\n",
        "  \n",
        "  # Get input data\n",
        "  working_df = pd.read_csv(input_data_path)\n",
        "  working_df['Distance_km'] = working_df['Distance_km'].astype(int)\n",
        "\n",
        "  #Get train/test split\n",
        "  train_idxs2, test_idxs2 = get_idx_train_test_split(working_df, distances, trainingProp = 0.8)\n",
        "\n",
        "  # Get labels and data\n",
        "  distances = [x*80 for x in range(1, 26)]\n",
        "  X, Y = create_df_v2(working_df, distances, nsymbols = 2048, span_length=80,  min_dist = 0, max_dist = 3000)\n",
        "  X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "  X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\")\n",
        "\n",
        "  '''\n",
        "  data_new = {}\n",
        "\n",
        "  for i in range(0,25):\n",
        "    data_new[str(80*(i+1))] = {\"Train\":X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}  \n",
        "\n",
        "  first = True\n",
        "  modify_all_data_df = pd.DataFrame()\n",
        "  for i in tqdm(range(25)):\n",
        "      print('\\n')\n",
        "      print(\"i = \",i)\n",
        "      modify_data_df = pd.DataFrame()\n",
        "      for j in range(i+1,25):\n",
        "          print(\" j = \",j)\n",
        "          source = data_new[str(distances[i]*80)]['Train']\n",
        "          target = data_new[str(distances[j]*80)]['Train']\n",
        "          source_test = data_new[str(distances[i]*80)]['Test']\n",
        "\n",
        "          source_test2 = source_test.copy()\n",
        "\n",
        "          for quadrant in quadrants:\n",
        "              print(\"   quadrant = \", quadrant)\n",
        "              if method == \"GD\":\n",
        "                M, b = compute_parameters(quadrant, 'GD', source, target, params=params)\n",
        "                new_points, indexes = modify_const_GD(quadrant, source_test, M, b)\n",
        "              elif method == \"Z\":\n",
        "                mean_source,cov_source,mean_target,cov_target = compute_parameters(quadrant, 'Z', source, target, params=None)\n",
        "                new_points, indexes = modify_const_Z(quadrant,source_test,mean_source,cov_source,mean_target,cov_target)\n",
        "\n",
        "              for k in range(len(indexes)):\n",
        "                  source_test2.iloc[indexes[k][0],indexes[k][1]] = complex(new_points[k][0], new_points[k][1])\n",
        "\n",
        "          F=[]\n",
        "          for k in range(source_test2.shape[0]):\n",
        "              data2=list(source_test2.iloc[k,:])\n",
        "              data2=[[float(d.real), float(d.imag)] for d in data2]\n",
        "              gmm = GaussianMixture(n_components=16, random_state=0, means_init=my_centers).fit(data2)\n",
        "              mus=gmm.means_\n",
        "              sigmas=gmm.covariances_\n",
        "\n",
        "              features=[distances[i]*80, distances[j]*80]\n",
        "\n",
        "              for z in selCP_pos:\n",
        "                  mindist=None\n",
        "                  k_inc=None\n",
        "                  for w in range(16):\n",
        "                      d=L2dist(mus[w],z)\n",
        "                      if mindist is None or mindist>d:\n",
        "                          mindist=d\n",
        "                          k_inc=w\n",
        "\n",
        "                  covmat=np.concatenate(list(sigmas[k_inc])).ravel().tolist()\n",
        "                  features = [*features, *mus[k_inc], *covmat]\n",
        "              F.append(features)\n",
        "          \n",
        "          header=['original_dist', 'target_dist']\n",
        "          \n",
        "          for j in selCP:\n",
        "              header=[*header,*['mu_r_'+str(j),'mu_i_'+str(j),'sigma_rr_'+str(j),'sigma_ri_'+str(j),'sigma_ir_'+str(j),'sigma_ii_'+str(j)]]\n",
        "   \n",
        "          with open(output_path + output_features, 'a', encoding='UTF8', newline='') as f:\n",
        "              writer = csv.writer(f)\n",
        "              # write the header\n",
        "              if first:\n",
        "                writer.writerow(header)\n",
        "                first = False\n",
        "              # write multiple rows\n",
        "              writer.writerows(F)   \n",
        "    '''"
      ],
      "metadata": {
        "id": "wD-7qi5yw1yF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "UG958x4cAHiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE SELCET THE METHOD AND QUADRANTS THAT ARE DESIRED TO BE TESTED\n",
        "method = \"GD\" # or method = \"Z\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "distances = [x*80 for x in range(1, 26)]\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path = path + \"/Spectrum/CNN/new_working_df.csv\"\n",
        "\n",
        "#input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))\n",
        "\n",
        "#Output mod files\n",
        "output_path = path + '/modifiedData/'+ method\n",
        "\n",
        "# Params for gradient descent alpha and beta\n",
        "a = 0.7\n",
        "b = 0.2\n",
        "params = {\"alpha\": float(a), \"beta\": float(b)}"
      ],
      "metadata": {
        "id": "pMiahsERAI2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d60b9c6-1a3b-49b0-8c74-f75dce459897"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath selected: /content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset/Spectrum/CNN/new_working_df.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbol2symbol_main_v2(method, quadrants, input_data_path, distances, output_path, params = None, nsymbols = 2048, min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "nyjOhORG8HEv"
      },
      "execution_count": 62,
      "outputs": []
    }
  ]
}