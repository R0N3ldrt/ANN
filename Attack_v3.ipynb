{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmlw1v6F4bxBoHdqPaVMRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0N3ldrt/Thesis/blob/main/Attack_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attack"
      ],
      "metadata": {
        "id": "eDgG4ygA9GDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "xsbnWao69DFZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hAWCVcJ_8_zo"
      },
      "outputs": [],
      "source": [
        "# Importing necesary libraries\n",
        "# Libraries for correct code execution \n",
        "\n",
        "import os, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import csv\n",
        "import re\n",
        "import array\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from functools import reduce\n",
        "from random import random, gauss\n",
        "from math import modf, pi, cos, sin, sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from plotly.subplots import make_subplots\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.stats.stats import pearsonr\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import os, time, math, csv, joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import os, time, math, csv, joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Enviroment"
      ],
      "metadata": {
        "id": "CJ_c-LNY9Kft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE PARA USAR DESDE COLAB\n",
        "\n",
        "# Google drive loading as work station for local-usage of the files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount= True)\n",
        "\n",
        "#-----------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt_uvFYn9L8g",
        "outputId": "25f05906-9c8b-494e-e667-68aa74eac3f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para cambiar los paths rapido.\n",
        "workers = [\"Ronald\", \"Local\"]\n",
        "\n",
        "# Change the number to change the paths.\n",
        "worker = workers[0]\n",
        "\n",
        "if worker == \"Ronald\":\n",
        "  path = \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset\"\n",
        "else: path = os.getcwd()"
      ],
      "metadata": {
        "id": "31nM5w3n9Oy-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-procesing"
      ],
      "metadata": {
        "id": "T54BySkf9PSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = path + \"/Spectrum/NN/new_data_working_df.csv\"\n",
        "\n",
        "working_df = pd.read_csv(input_path)\n",
        "working_df['Distance_km'] = working_df['Distance_km'].astype(int)"
      ],
      "metadata": {
        "id": "qjLmjjay9olo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "ZK6vWbBE-t_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Train/Test data"
      ],
      "metadata": {
        "id": "plX57BW7-vjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(input_data_path, distances, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  X=None\n",
        "  Y=[]\n",
        "  colnames=['i'+str(i) for i in range(nsymbols)]\n",
        "\n",
        "  for d in distances:\n",
        "    dist=d*span_length\n",
        "    if dist<min_dist or dist>max_dist: continue\n",
        "    filename='consts_'+str(d)+'span.csv'\n",
        "    df_aux=pd.read_csv(input_data_path+'/'+filename, sep=\",\", header=None)\n",
        "    df_aux = df_aux.T\n",
        "    df_aux.columns=colnames\n",
        "    Y=Y+[dist]*df_aux.shape[0]\n",
        "    if X is None: X=df_aux\n",
        "    else: X=X.append(df_aux)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "LkM3LI3c-yY5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df_v2(working_df, distances, nsymbols = 2048, span_length=80, min_dist = 0, max_dist = 3000):\n",
        "  X=None\n",
        "  Y=np.array([])\n",
        "\n",
        "  for d in distances:\n",
        "    distance_working_df = working_df.loc[working_df['Distance_km'] == d]\n",
        "    \n",
        "    d_df = distance_working_df.iloc[:, 3].to_numpy()\n",
        "    data_df = distance_working_df.iloc[:, 6:distance_working_df.shape[1]]\n",
        "    Y = np.append(Y, d_df)\n",
        "\n",
        "    if X is None: X=data_df\n",
        "    else: X=X.append(data_df)\n",
        "  Y = Y.astype('int').tolist()\n",
        "\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "nkwW-mY1A3Rh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input_data_path=path+\"/rawData\"\n",
        "#distances=[i for i in range(1,26)]\n",
        "distances = [x*80 for x in range(1, 26)]\n",
        "X, Y = create_df_v2(working_df, distances, nsymbols = 2048, span_length=80,  min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "4bPWvrM1AVZt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get indexes for train/test split"
      ],
      "metadata": {
        "id": "i9nThXISFt7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_idx_train_test_split(working_df, distances, trainingProp = 0.8):\n",
        "\n",
        "  rows_training = np.array([])\n",
        "  rows_testing = np.array([])\n",
        "  for d in distances:  \n",
        "    distance_working_df = working_df.loc[working_df['Distance_km'] == d]\n",
        "\n",
        "    rows_mixed=np.random.permutation(distance_working_df.shape[0])\n",
        "\n",
        "    training_amt = math.ceil(distance_working_df.shape[0]*trainingProp)\n",
        "    testing_amt = distance_working_df.shape[0] - training_amt\n",
        "\n",
        "    rows_training = np.append(rows_training, rows_mixed[:training_amt])\n",
        "    rows_testing = np.append(rows_testing, rows_mixed[-testing_amt:])\n",
        "  \n",
        "  rows_training = rows_training.astype('int').tolist()\n",
        "  rows_testing = rows_testing.astype('int').tolist()\n",
        "\n",
        "  return rows_training, rows_testing"
      ],
      "metadata": {
        "id": "T1OxCIhstvBf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows_training, rows_testing = get_idx_train_test_split(working_df, distances, trainingProp = 0.8)"
      ],
      "metadata": {
        "id": "bnO-ov2iuCmR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v2():\n",
        "  train_idxs2 = []\n",
        "  test_idxs2 = []\n",
        "  for i in range(25):\n",
        "      for j in range(25):\n",
        "          test_idxs2.append(50*(i+1)-1-j)\n",
        "\n",
        "  for i in range(25):\n",
        "    for j in range(2):\n",
        "      train_idxs2.append(50*i + j)\n",
        "  return train_idxs2, test_idxs2"
      ],
      "metadata": {
        "id": "YE70OaQlsvw6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GD"
      ],
      "metadata": {
        "id": "wC9AhJ8TrZb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent Function"
      ],
      "metadata": {
        "id": "AgTh4Vk3--dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_b (M,m_og,m_tg,b,beta):\n",
        "  return 2*beta*(M @ m_og + b - m_tg)"
      ],
      "metadata": {
        "id": "q8woGUzl-9hs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_M(M,cov_og,cov_tg,alpha):\n",
        "    error = M @ cov_og @ np.transpose(M) - cov_tg  \n",
        "\n",
        "    m1 = (2*error[0][0] * (2*cov_og[0][0]*M[0][0] + 2*cov_og[0][1]*M[0][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[1][0] + cov_og[0][1]*M[1][1]))\n",
        "    \n",
        "    m2 = (2*error[0][0] * (2*cov_og[1][1]*M[0][1] + 2*cov_og[0][1]*M[0][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[1][0] + cov_og[1][1]*M[1][1]))\n",
        "    \n",
        "    m3 = (2*error[1][1] * (2*cov_og[0][0]*M[1][0] + 2*cov_og[0][1]*M[1][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[0][0] + cov_og[0][1]*M[0][1]))\n",
        "\n",
        "    m4 = (2*error[1][1] * (2*cov_og[0][0]*M[1][1] + 2*cov_og[0][1]*M[1][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[0][0] + cov_og[1][1]*M[0][1]))\n",
        "    \n",
        "    return alpha*np.array([[m1, m2], [m3, m4]])"
      ],
      "metadata": {
        "id": "M9QYjER9_BBJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(alpha,beta,m_tg,m_og,cov_tg,cov_og,nu,log):\n",
        "  Ms = []\n",
        "  bs = []\n",
        "  M = np.random.rand(2,2)\n",
        "  #M = np.array([[1, 0], [0, 1]])\n",
        "  b = np.random.rand(2,1)\n",
        "  #b = np.array([[0], [0]])\n",
        "  #for i in range(100000):\n",
        "  i = 0\n",
        "  while True:\n",
        "    # print('From:', M @ cov_source @ np.transpose(M))\n",
        "    # print('To:', cov_target)\n",
        "    L = loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b) \n",
        "    if  L < 1e-20:\n",
        "        Ms.append(M)\n",
        "        bs.append(b)\n",
        "        break\n",
        "    b = b - nu*grad_b(M,m_og,m_tg,b,beta)\n",
        "    M = M - nu*grad_M(M,cov_og,cov_tg,alpha)\n",
        "    i+= 1\n",
        "    if (i>= 5000 and i <= 5025) or (i>= 5975 and i <= 6000):\n",
        "      Ms.append(M)\n",
        "      bs.append(b)\n",
        "    if not i%5000 and log: print(L)\n",
        "  if log: print(\"-\"*25)\n",
        "  return Ms,bs"
      ],
      "metadata": {
        "id": "EQwVHNaR_DRW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute parameters and mean/covariance"
      ],
      "metadata": {
        "id": "wJSQYPCd_GlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mean_and_cov(data):\n",
        "  aux_x = [] # Reales\n",
        "  aux_y = [] # Imag\n",
        "  for obs in data:\n",
        "    aux_x.append(obs[0])\n",
        "    aux_y.append(obs[1])\n",
        "  return np.array([[np.mean(aux_x)],[np.mean(aux_y)]]), np.cov(aux_x,aux_y)\n",
        "\n",
        "\n",
        "def total_loss(m_mod,m_tg,cov_mod,cov_tg):\n",
        "  return (sum(sum(np.power(cov_mod-cov_tg,2))) + sum(np.power(m_mod - m_tg,2)))[0]\n",
        "\n",
        "\n",
        "def loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b):\n",
        "  first = alpha*sum(sum(np.power(M @ cov_og @ np.transpose(M) - cov_tg, 2)))\n",
        "  second = beta*sum(np.power(M @ m_og + b - m_tg, 2))\n",
        "  a = first+second\n",
        "  return a"
      ],
      "metadata": {
        "id": "bg5fXgvY_HCh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_parameters (const,method,source,target, params = None, log = False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  q_target = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "\n",
        "    q_source += [[x.real,x.imag] for x in source.values.tolist()[i] if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "    q_target += [[x.real,x.imag] for x in target.values.tolist()[i]if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "\n",
        "  unbiased = (len(q_source)/(len(q_source)-1) * 125/126)\n",
        "\n",
        "  mean_source,cov_source = compute_mean_and_cov(q_source)\n",
        "  mean_target, cov_target= compute_mean_and_cov(q_target)\n",
        "\n",
        "  cov_source *= unbiased\n",
        "  cov_target *= unbiased\n",
        "\n",
        "  if method == \"GD\":\n",
        "    if (params is None):\n",
        "      alpha = 3/4\n",
        "      beta = 1/4\n",
        "    else:\n",
        "      alpha = params[\"alpha\"] if params[\"alpha\"]>0 and params[\"alpha\"]<=1 and params[\"alpha\"]>params[\"beta\"]  else 3/4\n",
        "      beta = params[\"beta\"] if params[\"beta\"]>=0 and params[\"beta\"]<1 and params[\"beta\"]<params[\"alpha\"]  else 1/4\n",
        "\n",
        "    M, b = gradient_descent(alpha,beta,mean_target,mean_source,cov_target,cov_source, 0.5,log)\n",
        "    return M,b\n",
        "\n",
        "  elif method == \"Z\":\n",
        "    return mean_source,cov_source,mean_target,cov_target"
      ],
      "metadata": {
        "id": "c3ZMthBM_KB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify GD/Z"
      ],
      "metadata": {
        "id": "TqpqU4M0_ODy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_GD(const,source,M,b, target = None, return_plots=False):\n",
        "\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "      \n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  for mult in mults:\n",
        "    res = (M @ mult + b).tolist()\n",
        "\n",
        "    # --------- Old line ---------\n",
        "    #new_points.append([res[0][0],res[1][0]])\n",
        "    nested_check = any(isinstance(i, list) for i in res[0])\n",
        "    if nested_check:\n",
        "      new_points.append([res[0][0][0],res[0][1][0]])\n",
        "    else:\n",
        "      new_points.append([res[0][0],res[1][0]])\n",
        "\n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      return new_points, q_target\n",
        "\n",
        "  return new_points, indexes"
      ],
      "metadata": {
        "id": "E0uaG8YN_OPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_Z(const,source,mean_source,cov_source,mean_target,cov_target,target = None, return_plots=False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "\n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  w, v = np.linalg.eig(cov_source)\n",
        "  S1 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "  w, v = np.linalg.eig(cov_target)\n",
        "  S2 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "\n",
        "  for mult in mults:\n",
        "    normalized = np.linalg.inv(S1) @ (mult - mean_source)\n",
        "    denormalized = S2 @ normalized + mean_target\n",
        "\n",
        "    new_points.append([denormalized[0][0], denormalized[1][0]])\n",
        "\n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      \n",
        "\n",
        "  return new_points, indexes"
      ],
      "metadata": {
        "id": "J-bim6du_Rzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L2dist(a,b):\n",
        "    return math.sqrt(math.pow(a[0]-b[0],2)+math.pow(a[1]-b[1],2))"
      ],
      "metadata": {
        "id": "29pAANvx_Xkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "corK2647_dol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symbol2symbol_main(method, quadrants, input_data_path, distances, output_path, params = None, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  \n",
        "  if (params is None):\n",
        "    output_features = \"/{}_alpha_75_beta_25_features.csv\".format(str(method))\n",
        "  else:\n",
        "    decimal_alpha = modf(params['alpha'])\n",
        "    decimal_alpha  = round(decimal_alpha[0], 2)\n",
        "    decimal_alpha = re.findall('..(.*)', str(decimal_alpha))[0]\n",
        "\n",
        "    decimal_beta = modf(params['beta'])\n",
        "    decimal_beta  = round(decimal_beta[0], 2)\n",
        "    decimal_beta = re.findall('..(.*)', str(decimal_beta))[0]\n",
        "\n",
        "    output_features = \"/{}_alpha_{}_beta{}_features.csv\".format(str(method), str(decimal_alpha), str(decimal_beta))\n",
        "\n",
        "  # Get input data\n",
        "  X, Y = create_df(input_data_path, distances, nsymbols, min_dist, max_dist)\n",
        "\n",
        "  X = X.applymap(strToTuple)\n",
        "\n",
        " \n",
        "  train_idxs2, test_idxs2 = test_train_indexes_v2()\n",
        "\n",
        "  X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "  X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\") \n",
        "\n",
        "  data_new = {}\n",
        "\n",
        "  for i in range(0,25):\n",
        "    data_new[str(80*(i+1))] = {\"Train\":X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}  \n",
        "  display(data_new)\n",
        "  \n",
        "  first = True\n",
        "  modify_all_data_df = pd.DataFrame()\n",
        "  for i in tqdm(range(25)):\n",
        "      print('\\n')\n",
        "      print(\"i = \",i)\n",
        "      modify_data_df = pd.DataFrame()\n",
        "      for j in range(i+1,25):\n",
        "          print(\" j = \",j)\n",
        "          source = data_new[str(distances[i]*80)]['Train']\n",
        "          target = data_new[str(distances[j]*80)]['Train']\n",
        "          source_test = data_new[str(distances[i]*80)]['Test']\n",
        "\n",
        "          source_test2 = source_test.copy()\n",
        "\n",
        "          for quadrant in quadrants:\n",
        "              print(\"   quadrant = \", quadrant)\n",
        "              if method == \"GD\":\n",
        "                M, b = compute_parameters(quadrant, 'GD', source, target, params=params)\n",
        "                new_points, indexes = modify_const_GD(quadrant, source_test, M, b)\n",
        "              elif method == \"Z\":\n",
        "                mean_source,cov_source,mean_target,cov_target = compute_parameters(quadrant, 'Z', source, target, params=None)\n",
        "                new_points, indexes = modify_const_Z(quadrant,source_test,mean_source,cov_source,mean_target,cov_target)\n",
        "\n",
        "              for k in range(len(indexes)):\n",
        "                  source_test2.iloc[indexes[k][0],indexes[k][1]] = complex(new_points[k][0], new_points[k][1])\n",
        "\n",
        "          F=[]\n",
        "          for k in range(source_test2.shape[0]):\n",
        "              data2=list(source_test2.iloc[k,:])\n",
        "              data2=[[float(d.real), float(d.imag)] for d in data2]\n",
        "              gmm = GaussianMixture(n_components=16, random_state=0, means_init=my_centers).fit(data2)\n",
        "              mus=gmm.means_\n",
        "              sigmas=gmm.covariances_\n",
        "\n",
        "              features=[distances[i]*80, distances[j]*80]\n",
        "\n",
        "              for z in selCP_pos:\n",
        "                  mindist=None\n",
        "                  k_inc=None\n",
        "                  for w in range(16):\n",
        "                      d=L2dist(mus[w],z)\n",
        "                      if mindist is None or mindist>d:\n",
        "                          mindist=d\n",
        "                          k_inc=w\n",
        "\n",
        "                  covmat=np.concatenate(list(sigmas[k_inc])).ravel().tolist()\n",
        "                  features = [*features, *mus[k_inc], *covmat]\n",
        "              F.append(features)\n",
        "          \n",
        "          header=['original_dist', 'target_dist']\n",
        "          \n",
        "          for j in selCP:\n",
        "              header=[*header,*['mu_r_'+str(j),'mu_i_'+str(j),'sigma_rr_'+str(j),'sigma_ri_'+str(j),'sigma_ir_'+str(j),'sigma_ii_'+str(j)]]\n",
        "   \n",
        "          with open(output_path + output_features, 'a', encoding='UTF8', newline='') as f:\n",
        "              writer = csv.writer(f)\n",
        "              # write the header\n",
        "              if first:\n",
        "                writer.writerow(header)\n",
        "                first = False\n",
        "              # write multiple rows\n",
        "              writer.writerows(F)   "
      ],
      "metadata": {
        "id": "KMd12eb7_dtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uitls Main"
      ],
      "metadata": {
        "id": "503noWGtHTQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strToTuple(s):\n",
        "    s_aux=s.split(\"i\")\n",
        "    s=s_aux[0]+\"j\"\n",
        "    return complex(s)\n",
        "\n",
        "def strToTuple_v2(s):\n",
        "    return complex(s)"
      ],
      "metadata": {
        "id": "zjSFyIF-Cyt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v2():\n",
        "  train_idxs2 = []\n",
        "  test_idxs2 = []\n",
        "  for i in range(25):\n",
        "      for j in range(25):\n",
        "          test_idxs2.append(50*(i+1)-1-j)\n",
        "\n",
        "  for i in range(25):\n",
        "    for j in range(2):\n",
        "      train_idxs2.append(50*i + j)\n",
        "  return train_idxs2, test_idxs2"
      ],
      "metadata": {
        "id": "3fRiKPkhC1KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE SELCET THE METHOD AND QUADRANTS THAT ARE DESIRED TO BE TESTED\n",
        "method = \"GD\" # or method = \"GD\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "\n",
        "#Output mod files\n",
        "output_path = path + '/modifiedData/'+ method\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afVIB3d9Cn2G",
        "outputId": "b46a2503-925b-424b-fd97-5983e78bbc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath selected: /content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset/rawData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "\n",
        "distances=[i for i in range(1,26)]\n",
        "nsamples=50\n",
        "span_length=80\n",
        "nsymbols=2048\n",
        "\n",
        "######\n",
        "min_dist=0\n",
        "max_dist=3000\n",
        "selCP=[1,7,10,15]\n",
        "selCP_pos=[(-3,3),(1,1),(-1,-1),(1,-3)]\n",
        "my_centers=[[-3,3],[-1,3],[1,3],[3,3],[-3,1],[-1,1],[1,1],[3,1],[-3,-1],[-1,-1],[1,-1],[3,-1], [-3,-3],[-1,-3],[1,-3],[3,-3]]\n",
        "######"
      ],
      "metadata": {
        "id": "hCjqDq9YDoyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run main"
      ],
      "metadata": {
        "id": "9FAksiYMHXkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main v2"
      ],
      "metadata": {
        "id": "OOQABumrw5ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data_path = path + \"/Spectrum/CNN/new_working_df.csv\"\n",
        "def symbol2symbol_main_v2(method, quadrants, input_data_path, distances, output_path, params = None, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  \n",
        "  if (params is None):\n",
        "    output_features = \"/{}_alpha_75_beta_25_features.csv\".format(str(method))\n",
        "  else:\n",
        "    decimal_alpha = modf(params['alpha'])\n",
        "    decimal_alpha  = round(decimal_alpha[0], 2)\n",
        "    decimal_alpha = re.findall('..(.*)', str(decimal_alpha))[0]\n",
        "\n",
        "    decimal_beta = modf(params['beta'])\n",
        "    decimal_beta  = round(decimal_beta[0], 2)\n",
        "    decimal_beta = re.findall('..(.*)', str(decimal_beta))[0]\n",
        "\n",
        "    output_features = \"/{}_alpha_{}_beta{}_features.csv\".format(str(method), str(decimal_alpha), str(decimal_beta))\n",
        "  \n",
        "  # Get input data\n",
        "  working_df = pd.read_csv(input_data_path)\n",
        "  working_df['Distance_km'] = working_df['Distance_km'].astype(int)\n",
        "\n",
        "  #Get train/test split\n",
        "  train_idxs2, test_idxs2 = get_idx_train_test_split(working_df, distances, trainingProp = 0.8)\n",
        "\n",
        "  # Get labels and data\n",
        "  distances = [x*80 for x in range(1, 26)]\n",
        "  X, Y = create_df_v2(working_df, distances, nsymbols = 2048, span_length=80,  min_dist = 0, max_dist = 3000)\n",
        "  X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "  X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\")\n",
        "\n",
        "  '''\n",
        "  data_new = {}\n",
        "\n",
        "  for i in range(0,25):\n",
        "    data_new[str(80*(i+1))] = {\"Train\":X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}  \n",
        "\n",
        "  first = True\n",
        "  modify_all_data_df = pd.DataFrame()\n",
        "  for i in tqdm(range(25)):\n",
        "      print('\\n')\n",
        "      print(\"i = \",i)\n",
        "      modify_data_df = pd.DataFrame()\n",
        "      for j in range(i+1,25):\n",
        "          print(\" j = \",j)\n",
        "          source = data_new[str(distances[i]*80)]['Train']\n",
        "          target = data_new[str(distances[j]*80)]['Train']\n",
        "          source_test = data_new[str(distances[i]*80)]['Test']\n",
        "\n",
        "          source_test2 = source_test.copy()\n",
        "\n",
        "          for quadrant in quadrants:\n",
        "              print(\"   quadrant = \", quadrant)\n",
        "              if method == \"GD\":\n",
        "                M, b = compute_parameters(quadrant, 'GD', source, target, params=params)\n",
        "                new_points, indexes = modify_const_GD(quadrant, source_test, M, b)\n",
        "              elif method == \"Z\":\n",
        "                mean_source,cov_source,mean_target,cov_target = compute_parameters(quadrant, 'Z', source, target, params=None)\n",
        "                new_points, indexes = modify_const_Z(quadrant,source_test,mean_source,cov_source,mean_target,cov_target)\n",
        "\n",
        "              for k in range(len(indexes)):\n",
        "                  source_test2.iloc[indexes[k][0],indexes[k][1]] = complex(new_points[k][0], new_points[k][1])\n",
        "\n",
        "          F=[]\n",
        "          for k in range(source_test2.shape[0]):\n",
        "              data2=list(source_test2.iloc[k,:])\n",
        "              data2=[[float(d.real), float(d.imag)] for d in data2]\n",
        "              gmm = GaussianMixture(n_components=16, random_state=0, means_init=my_centers).fit(data2)\n",
        "              mus=gmm.means_\n",
        "              sigmas=gmm.covariances_\n",
        "\n",
        "              features=[distances[i]*80, distances[j]*80]\n",
        "\n",
        "              for z in selCP_pos:\n",
        "                  mindist=None\n",
        "                  k_inc=None\n",
        "                  for w in range(16):\n",
        "                      d=L2dist(mus[w],z)\n",
        "                      if mindist is None or mindist>d:\n",
        "                          mindist=d\n",
        "                          k_inc=w\n",
        "\n",
        "                  covmat=np.concatenate(list(sigmas[k_inc])).ravel().tolist()\n",
        "                  features = [*features, *mus[k_inc], *covmat]\n",
        "              F.append(features)\n",
        "          \n",
        "          header=['original_dist', 'target_dist']\n",
        "          \n",
        "          for j in selCP:\n",
        "              header=[*header,*['mu_r_'+str(j),'mu_i_'+str(j),'sigma_rr_'+str(j),'sigma_ri_'+str(j),'sigma_ir_'+str(j),'sigma_ii_'+str(j)]]\n",
        "   \n",
        "          with open(output_path + output_features, 'a', encoding='UTF8', newline='') as f:\n",
        "              writer = csv.writer(f)\n",
        "              # write the header\n",
        "              if first:\n",
        "                writer.writerow(header)\n",
        "                first = False\n",
        "              # write multiple rows\n",
        "              writer.writerows(F)   \n",
        "    '''"
      ],
      "metadata": {
        "id": "wD-7qi5yw1yF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "UG958x4cAHiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE SELCET THE METHOD AND QUADRANTS THAT ARE DESIRED TO BE TESTED\n",
        "method = \"GD\" # or method = \"Z\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "distances = [x*80 for x in range(1, 26)]\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path = path + \"/Spectrum/NN/new_data_working_df.csv\"\n",
        "\n",
        "#input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))\n",
        "\n",
        "#Output mod files\n",
        "output_path = path + '/modifiedData/'+ method\n",
        "\n",
        "# Params for gradient descent alpha and beta\n",
        "a = 0.7\n",
        "b = 0.2\n",
        "params = {\"alpha\": float(a), \"beta\": float(b)}"
      ],
      "metadata": {
        "id": "pMiahsERAI2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37738cc5-e261-4f71-dff3-99547d4618c3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath selected: /content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset/Spectrum/NN/new_data_working_df.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbol2symbol_main_v2(method, quadrants, input_data_path, distances, output_path, params = None, nsymbols = 2048, min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "nyjOhORG8HEv",
        "outputId": "95e752d2-7b42-44ad-e926-083484e19362",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     -39.90625    -39.875  -39.84375   -39.8125  -39.78125     -39.75  \\\n",
            "0   -57.249552 -57.624664 -58.071283 -60.040833 -54.626309 -65.738997   \n",
            "1   -63.880076 -54.838930 -50.731974 -52.124606 -55.442314 -59.147945   \n",
            "2   -57.122957 -53.956785 -53.896963 -56.500870 -61.729861 -67.854404   \n",
            "3   -70.696618 -65.303756 -60.683876 -57.875370 -54.574001 -53.748213   \n",
            "4   -51.348821 -60.813456 -65.890334 -66.461066 -66.788831 -59.574001   \n",
            "..         ...        ...        ...        ...        ...        ...   \n",
            "495 -55.993777 -60.940842 -63.454978 -65.541745 -64.175338 -55.326790   \n",
            "496 -56.829372 -55.905008 -56.196466 -58.846688 -57.930540 -57.942953   \n",
            "497 -54.902319 -57.469566 -58.650167 -58.256577 -57.120871 -54.832446   \n",
            "498 -55.869261 -59.209400 -59.939595 -57.487492 -56.982003 -53.641354   \n",
            "499 -56.988001 -59.388396 -60.397553 -59.809899 -56.239314 -56.703642   \n",
            "\n",
            "     -39.71875   -39.6875  -39.65625    -39.625  ...    34.6875   34.71875  \\\n",
            "0   -69.004208 -66.973126 -58.935310 -64.124615  ... -65.148055 -55.207276   \n",
            "1   -59.568813 -58.219893 -58.387052 -58.921913  ... -65.900533 -65.732200   \n",
            "2   -61.820875 -56.871482 -54.302286 -54.325404  ... -58.617249 -55.757177   \n",
            "3   -58.920613 -65.129243 -69.102172 -62.891362  ... -55.859031 -57.273496   \n",
            "4   -60.943313 -61.990758 -63.800189 -61.095272  ... -55.073790 -59.555017   \n",
            "..         ...        ...        ...        ...  ...        ...        ...   \n",
            "495 -57.396206 -59.477690 -60.613260 -59.877609  ... -53.686475 -54.229128   \n",
            "496 -55.750507 -57.103698 -57.183412 -59.556502  ... -59.704004 -57.092386   \n",
            "497 -56.585764 -58.167556 -57.408129 -56.009250  ... -57.627135 -64.548644   \n",
            "498 -57.368125 -58.920757 -60.774134 -63.652007  ... -59.914772 -63.300435   \n",
            "499 -59.680567 -61.770316 -56.972968 -60.665724  ... -64.945289 -66.063654   \n",
            "\n",
            "         34.75   34.78125    34.8125   34.84375     34.875   34.90625  \\\n",
            "0   -53.139839 -57.653619 -61.911491 -60.008590 -56.232757 -59.879697   \n",
            "1   -58.647372 -60.150832 -59.855774 -60.492674 -56.816631 -54.299492   \n",
            "2   -55.076319 -56.508889 -60.612223 -60.346532 -59.529758 -54.010239   \n",
            "3   -54.406578 -61.030509 -61.955984 -62.319736 -55.400181 -55.312056   \n",
            "4   -60.716108 -70.481726 -71.552571 -68.530300 -56.585097 -56.093043   \n",
            "..         ...        ...        ...        ...        ...        ...   \n",
            "495 -57.307983 -59.585934 -58.990885 -60.129763 -61.487025 -67.653904   \n",
            "496 -58.509062 -60.798891 -58.902880 -60.033926 -60.556063 -56.309629   \n",
            "497 -65.637002 -63.156643 -58.177577 -59.985663 -58.031358 -60.922607   \n",
            "498 -64.683215 -62.780883 -54.035113 -56.448371 -56.009822 -56.070181   \n",
            "499 -61.491647 -57.673396 -56.665346 -55.336343 -59.736032 -61.509437   \n",
            "\n",
            "       34.9375   34.96875  \n",
            "0   -61.741188 -63.534636  \n",
            "1   -54.394218 -56.479767  \n",
            "2   -56.703044 -64.572308  \n",
            "3   -59.259579 -66.898471  \n",
            "4   -54.729800 -54.293514  \n",
            "..         ...        ...  \n",
            "495 -68.317301 -65.823757  \n",
            "496 -55.304066 -54.996690  \n",
            "497 -59.679082 -56.034034  \n",
            "498 -58.934685 -64.073571  \n",
            "499 -60.290227 -56.251555  \n",
            "\n",
            "[500 rows x 2397 columns]\n"
          ]
        }
      ]
    }
  ]
}