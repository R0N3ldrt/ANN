{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMppEhe4SsgAzWjFH0v/e6z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0N3ldrt/Thesis/blob/main/Symbol-to-Symbol_Attack_Clean-Synthetic_Final_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbol-to_Symbol Attack"
      ],
      "metadata": {
        "id": "m0Bi4sm804DM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Necesary Libraries"
      ],
      "metadata": {
        "id": "Wqnrp_jX0-IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necesary libraries\n",
        "# Libraries for correct code execution \n",
        "\n",
        "import os, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import csv\n",
        "import re\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "from tqdm import tqdm\n",
        "from math import modf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from plotly.subplots import make_subplots\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "W4KNWD010_XY"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Train/Test data"
      ],
      "metadata": {
        "id": "iSiPMiQE1D-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(input_data_path, distances, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  X=None\n",
        "  Y=[]\n",
        "  colnames=['i'+str(i) for i in range(nsymbols)]\n",
        "\n",
        "  for d in distances:\n",
        "    dist=d*span_length\n",
        "    if dist<min_dist or dist>max_dist: continue\n",
        "    filename='consts_'+str(d)+'span.csv'\n",
        "    df_aux=pd.read_csv(input_data_path+'/'+filename, sep=\",\", header=None)\n",
        "    df_aux = df_aux.T\n",
        "    df_aux.columns=colnames\n",
        "    Y=Y+[dist]*df_aux.shape[0]\n",
        "    if X is None: X=df_aux\n",
        "    else: X=X.append(df_aux)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "IUbBYpr71R0R"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strToTuple(s):\n",
        "    s_aux=s.split(\"i\")\n",
        "    s=s_aux[0]+\"j\"\n",
        "    return complex(s)\n",
        "\n",
        "def strToTuple_v2(s):\n",
        "    return complex(s)"
      ],
      "metadata": {
        "id": "1okA-BcY1UIC"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v1():\n",
        "  train_idxs = []\n",
        "  test_idxs = []\n",
        "  for i in range(25):\n",
        "      for j in range(25):\n",
        "          train_idxs.append(50*i + j)\n",
        "          test_idxs.append(50*(i+1)-1-j)\n",
        "  return train_idxs, test_idxs"
      ],
      "metadata": {
        "id": "eQA0MFsb1VmC"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v2(num_files=25):\n",
        "  train_idxs2 = []\n",
        "  test_idxs2 = []\n",
        "  for i in range(num_files):\n",
        "      for j in range(num_files):\n",
        "          test_idxs2.append(50*(i+1)-1-j)\n",
        "\n",
        "  for i in range(num_files):\n",
        "    for j in range(2):\n",
        "      train_idxs2.append(50*i + j)\n",
        "  return train_idxs2, test_idxs2"
      ],
      "metadata": {
        "id": "Ggyeg8kj1W_9"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "D7t_OQ2X1iMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent Function"
      ],
      "metadata": {
        "id": "463uTmP01ner"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_b (M,m_og,m_tg,b,beta):\n",
        "  return 2*beta*(M @ m_og + b - m_tg)"
      ],
      "metadata": {
        "id": "G4S0fONp1tgI"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_M(M,cov_og,cov_tg,alpha):\n",
        "    error = M @ cov_og @ np.transpose(M) - cov_tg  \n",
        "\n",
        "    m1 = (2*error[0][0] * (2*cov_og[0][0]*M[0][0] + 2*cov_og[0][1]*M[0][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[1][0] + cov_og[0][1]*M[1][1]))\n",
        "    \n",
        "    m2 = (2*error[0][0] * (2*cov_og[1][1]*M[0][1] + 2*cov_og[0][1]*M[0][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[1][0] + cov_og[1][1]*M[1][1]))\n",
        "    \n",
        "    m3 = (2*error[1][1] * (2*cov_og[0][0]*M[1][0] + 2*cov_og[0][1]*M[1][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[0][0] + cov_og[0][1]*M[0][1]))\n",
        "\n",
        "    m4 = (2*error[1][1] * (2*cov_og[0][0]*M[1][1] + 2*cov_og[0][1]*M[1][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[0][0] + cov_og[1][1]*M[0][1]))\n",
        "    \n",
        "    return alpha*np.array([[m1, m2], [m3, m4]])"
      ],
      "metadata": {
        "id": "Jwj71thl1vpu"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(alpha,beta,m_tg,m_og,cov_tg,cov_og,nu,log):\n",
        "  Ms = []\n",
        "  bs = []\n",
        "  M = np.random.rand(2,2)\n",
        "  #M = np.array([[1, 0], [0, 1]])\n",
        "  b = np.random.rand(2,1)\n",
        "  #b = np.array([[0], [0]])\n",
        "  #for i in range(100000):\n",
        "  i = 0\n",
        "  while True:\n",
        "    # print('From:', M @ cov_source @ np.transpose(M))\n",
        "    # print('To:', cov_target)\n",
        "    L = loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b) \n",
        "    if  L < 1e-20:\n",
        "        Ms.append(M)\n",
        "        bs.append(b)\n",
        "        break\n",
        "    b = b - nu*grad_b(M,m_og,m_tg,b,beta)\n",
        "    M = M - nu*grad_M(M,cov_og,cov_tg,alpha)\n",
        "    i+= 1\n",
        "    if (i>= 5000 and i <= 5025) or (i>= 5975 and i <= 6000):\n",
        "      Ms.append(M)\n",
        "      bs.append(b)\n",
        "    if not i%5000 and log: print(L)\n",
        "  if log: print(\"-\"*25)\n",
        "  return Ms,bs"
      ],
      "metadata": {
        "id": "bS620BBC1xQw"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute parameters and mean/covariance"
      ],
      "metadata": {
        "id": "3f_zKFpi10iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mean_and_cov(data):\n",
        "  aux_x = [] # Reales\n",
        "  aux_y = [] # Imag\n",
        "  for obs in data:\n",
        "    aux_x.append(obs[0])\n",
        "    aux_y.append(obs[1])\n",
        "  return np.array([[np.mean(aux_x)],[np.mean(aux_y)]]), np.cov(aux_x,aux_y)\n",
        "\n",
        "\n",
        "def total_loss(m_mod,m_tg,cov_mod,cov_tg):\n",
        "  return (sum(sum(np.power(cov_mod-cov_tg,2))) + sum(np.power(m_mod - m_tg,2)))[0]\n",
        "\n",
        "\n",
        "def loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b):\n",
        "  first = alpha*sum(sum(np.power(M @ cov_og @ np.transpose(M) - cov_tg, 2)))\n",
        "  second = beta*sum(np.power(M @ m_og + b - m_tg, 2))\n",
        "  a = first+second\n",
        "  return a"
      ],
      "metadata": {
        "id": "aEey3Em513gb"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_parameters (const,method,source,target, params = None, log = False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  q_target = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "\n",
        "    q_source += [[x.real,x.imag] for x in source.values.tolist()[i] if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "    q_target += [[x.real,x.imag] for x in target.values.tolist()[i]if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "\n",
        "  unbiased = (len(q_source)/(len(q_source)-1) * 125/126)\n",
        "\n",
        "  mean_source,cov_source = compute_mean_and_cov(q_source)\n",
        "  mean_target, cov_target= compute_mean_and_cov(q_target)\n",
        "\n",
        "  cov_source *= unbiased\n",
        "  cov_target *= unbiased\n",
        "\n",
        "  if method == \"GD\":\n",
        "    if (params is None):\n",
        "      alpha = 3/4\n",
        "      beta = 1/4\n",
        "    else:\n",
        "      alpha = params[\"alpha\"] if params[\"alpha\"]>0 and params[\"alpha\"]<=1 and params[\"alpha\"]>params[\"beta\"]  else 3/4\n",
        "      beta = params[\"beta\"] if params[\"beta\"]>=0 and params[\"beta\"]<1 and params[\"beta\"]<params[\"alpha\"]  else 1/4\n",
        "\n",
        "    M, b = gradient_descent(alpha,beta,mean_target,mean_source,cov_target,cov_source, 0.5,log)\n",
        "    return M,b\n",
        "\n",
        "  elif method == \"Z\":\n",
        "    return mean_source,cov_source,mean_target,cov_target"
      ],
      "metadata": {
        "id": "EsLrPZeS15_a"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify GD/Z"
      ],
      "metadata": {
        "id": "uA2cDNyE17Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_GD(const,source,M,b, target = None, return_plots=False):\n",
        "\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "      \n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  for mult in mults:\n",
        "    res = (M @ mult + b).tolist()\n",
        "\n",
        "    # --------- Old line ---------\n",
        "    #new_points.append([res[0][0],res[1][0]])\n",
        "    nested_check = any(isinstance(i, list) for i in res[0])\n",
        "    if nested_check:\n",
        "      new_points.append([res[0][0][0],res[0][1][0]])\n",
        "    else:\n",
        "      new_points.append([res[0][0],res[1][0]])\n",
        "\n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      return new_points, q_target\n",
        "\n",
        "  return new_points, indexes"
      ],
      "metadata": {
        "id": "z-7kfNDv2Bfo"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_Z(const,source,mean_source,cov_source,mean_target,cov_target,target = None, return_plots=False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "\n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  w, v = np.linalg.eig(cov_source)\n",
        "  S1 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "  w, v = np.linalg.eig(cov_target)\n",
        "  S2 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "\n",
        "  for mult in mults:\n",
        "    if np.linalg.det(S1)==0:\n",
        "      print('Error Singular Matrix')\n",
        "    else:\n",
        "      normalized = np.linalg.inv(S1) @ (mult - mean_source)\n",
        "      denormalized = S2 @ normalized + mean_target\n",
        "\n",
        "      new_points.append([denormalized[0][0], denormalized[1][0]])\n",
        "\n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      \n",
        "\n",
        "  return new_points, indexes"
      ],
      "metadata": {
        "id": "TLrAx2KP2DXH"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare plots"
      ],
      "metadata": {
        "id": "EtBxMfUB2JrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_comparison_plot(mod_points,ptarget, return_plots=False):\n",
        "  x1 = [x[0] for  x in mod_points]\n",
        "  y1 = [x[1] for  x in mod_points]\n",
        "  x2 = [x[0] for  x in ptarget]\n",
        "  y2 = [x[1] for  x in ptarget]\n",
        "\n",
        "  if return_plots:\n",
        "      return go.Scatter(x = x1, y = y1, mode='markers'), go.Scatter(x = x2, y = y2,mode='markers') \n",
        "\n",
        "  fig = make_subplots(rows=1, cols=2)\n",
        "  fig.add_trace(\n",
        "    go.Scatter(x = x1, y = y1,mode='markers'),\n",
        "    \n",
        "    row=1, col=1\n",
        "  )\n",
        "  fig.add_trace(\n",
        "    go.Scatter(x = x2, y = y2,mode='markers'),\n",
        "    row=1, col=2\n",
        "  )\n",
        "  fig.update_layout(height=500, width=1000, title_text=\"Point comparison\",autosize = False)\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "irTwDoUA2L9A"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distance Calc"
      ],
      "metadata": {
        "id": "1KBVQKZg2jvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L2dist(a,b):\n",
        "    return math.sqrt(math.pow(a[0]-b[0],2)+math.pow(a[1]-b[1],2))"
      ],
      "metadata": {
        "id": "IYbhKHJu2mlD"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mod files generator"
      ],
      "metadata": {
        "id": "WU6cQzM9_OT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mod_df_generator(df, output_filepath, raw_data = True, mod_i = None, method = None):\n",
        "  sample_arr = []\n",
        "  symbol_arr = []\n",
        "  real_arr = []\n",
        "  imag_arr = []\n",
        "\n",
        "  # For alraeady modify data\n",
        "  if raw_data != True:\n",
        "\n",
        "    source_arr = []\n",
        "    target_arr = []\n",
        "\n",
        "    vals_df = df.iloc[:, 2:df.shape[1]]\n",
        "    vals_df = vals_df.applymap(strToTuple_v2)\n",
        "\n",
        "    distances_df = df.iloc[:, [0, 1]]\n",
        "\n",
        "    sample_cnt = 1\n",
        "    for i in range(len(vals_df)):\n",
        "      symbol_cnt = 1\n",
        "      for x in vals_df.values.tolist()[i]:\n",
        "\n",
        "        real_arr.append(x.real)\n",
        "        imag_arr.append(x.imag)\n",
        "\n",
        "        sample_arr.append(sample_cnt)\n",
        "        symbol_arr.append(symbol_cnt)    \n",
        "        symbol_cnt += 1\n",
        "\n",
        "        source_arr.append(distances_df['source_distance'].loc[distances_df.index[i]])\n",
        "        target_arr.append(distances_df['target_distance'].loc[distances_df.index[i]])\n",
        "        \n",
        "      sample_cnt += 1\n",
        "\n",
        "    data = {'Source_Distance':source_arr, 'Target_Distance':target_arr, 'Sample_Id':sample_arr, 'Symbol_Id':symbol_arr, 'Real':real_arr, 'Imag':imag_arr}  \n",
        "    \n",
        "    mod_df = pd.DataFrame(data)\n",
        "\n",
        "    if method == 'GD':\n",
        "      filename = ('/{}_mod/consts_modified_source_distance_{}_alpha_0.75_beta_0.25.csv'.format(str(method), str(mod_i)))\n",
        "    else:\n",
        "      filename = ('/{}_mod/consts_modified_source_distance_{}.csv'.format(str(method), str(mod_i)))\n",
        "\n",
        "    mod_df.to_csv(str(output_filepath)+filename, index=False, encoding='utf-8-sig')\n",
        "    \n",
        "  else:\n",
        "    vals_df = df\n",
        "\n",
        "    sample_cnt = 1\n",
        "    file_cnt = 1\n",
        "    for i in range(len(vals_df)):\n",
        "      symbol_cnt = 1\n",
        "      for x in vals_df.values.tolist()[i]:\n",
        "        real_arr.append(x.real)\n",
        "        imag_arr.append(x.imag)\n",
        "\n",
        "        sample_arr.append(sample_cnt)\n",
        "        symbol_arr.append(symbol_cnt)\n",
        "        symbol_cnt += 1\n",
        "\n",
        "      sample_cnt += 1\n",
        "      if (i+1) % 50 == 0:\n",
        "        data = {'Sample_Id':sample_arr, 'Symbol_Id':symbol_arr, 'Real':real_arr, 'Imag':imag_arr}  \n",
        "        \n",
        "        mod_df = pd.DataFrame(data)\n",
        "        \n",
        "        filename = ('/rawData_mod/consts_{}span_mod.csv'.format(file_cnt))\n",
        "\n",
        "        file_cnt += 1\n",
        "        mod_df.to_csv(str(output_filepath)+filename, index=False, encoding='utf-8-sig') \n",
        "        \n",
        "        # Reset values\n",
        "        sample_cnt = 1\n",
        "        sample_arr = []\n",
        "        symbol_arr = []\n",
        "        real_arr = []\n",
        "        imag_arr = [] "
      ],
      "metadata": {
        "id": "LPbiawX9_SC_"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mod_df_generator_v2(df, output_filepath, radius, funct, raw_data = True, mod_i = None, method = None):\n",
        "  sample_arr = []\n",
        "  symbol_arr = []\n",
        "  real_arr = []\n",
        "  imag_arr = []\n",
        "\n",
        "  # For alraeady modify data\n",
        "  if raw_data != True:\n",
        "\n",
        "    source_arr = []\n",
        "    target_arr = []\n",
        "\n",
        "    vals_df = df.iloc[:, 2:df.shape[1]]\n",
        "    vals_df = vals_df.applymap(strToTuple_v2)\n",
        "\n",
        "    distances_df = df.iloc[:, [0, 1]]\n",
        "\n",
        "    sample_cnt = 1\n",
        "    for i in range(len(vals_df)):\n",
        "      symbol_cnt = 1\n",
        "      for x in vals_df.values.tolist()[i]:\n",
        "\n",
        "        real_arr.append(x.real)\n",
        "        imag_arr.append(x.imag)\n",
        "\n",
        "        sample_arr.append(sample_cnt)\n",
        "        symbol_arr.append(symbol_cnt)    \n",
        "        symbol_cnt += 1\n",
        "\n",
        "        source_arr.append(distances_df['source_distance'].loc[distances_df.index[i]])\n",
        "        target_arr.append(distances_df['target_distance'].loc[distances_df.index[i]])\n",
        "        \n",
        "      sample_cnt += 1\n",
        "\n",
        "    data = {'Source_Distance':source_arr, 'Target_Distance':target_arr, 'Sample_Id':sample_arr, 'Symbol_Id':symbol_arr, 'Real':real_arr, 'Imag':imag_arr}  \n",
        "    \n",
        "    mod_df = pd.DataFrame(data)\n",
        "\n",
        "    if method == 'GD':\n",
        "      filename = ('/{}_mod/consts_modified_source_distance_{}_radius_{}_funct_{}_alpha_0.75_beta_0.25.csv'.format(str(method), str(mod_i)))     \n",
        "    else:\n",
        "      filename = ('/{}_mod/consts_modified_source_distance_{}_radius_{}_funct_{}.csv'.format(str(method), str(mod_i), str(radius), str(funct)))\n",
        "    mod_df.to_csv(str(output_filepath)+filename, index=False, encoding='utf-8-sig')\n",
        "    \n",
        "  else:\n",
        "    vals_df = df\n",
        "\n",
        "    sample_cnt = 1\n",
        "    file_cnt = 1\n",
        "    for i in range(len(vals_df)):\n",
        "      symbol_cnt = 1\n",
        "      for x in vals_df.values.tolist()[i]:\n",
        "        real_arr.append(x.real)\n",
        "        imag_arr.append(x.imag)\n",
        "\n",
        "        sample_arr.append(sample_cnt)\n",
        "        symbol_arr.append(symbol_cnt)\n",
        "        symbol_cnt += 1\n",
        "\n",
        "      sample_cnt += 1\n",
        "      if (i+1) % 50 == 0:\n",
        "        data = {'Sample_Id':sample_arr, 'Symbol_Id':symbol_arr, 'Real':real_arr, 'Imag':imag_arr}  \n",
        "        \n",
        "        mod_df = pd.DataFrame(data)\n",
        "        \n",
        "        filename = ('/synthetic_mod/consts_radius_{}_funct_{}_mod.csv'.format(str(radius), str(funct)))\n",
        "\n",
        "        file_cnt += 1\n",
        "        mod_df.to_csv(str(output_filepath)+filename, index=False, encoding='utf-8-sig') \n",
        "        \n",
        "        # Reset values\n",
        "        sample_cnt = 1\n",
        "        sample_arr = []\n",
        "        symbol_arr = []\n",
        "        real_arr = []\n",
        "        imag_arr = [] "
      ],
      "metadata": {
        "id": "zAWom4u-1XHC"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove duplicates"
      ],
      "metadata": {
        "id": "3_u0_QGcfS2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dups_remover(filepath):\n",
        "  df = pd.read_csv(filepath)\n",
        "  no_dups_df = df.drop_duplicates()\n",
        "  no_dups_df.to_csv(filepath, index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "GVqUnMJGfWvC"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "D0mIXvtv2xAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main v1"
      ],
      "metadata": {
        "id": "BsuaWLMj1Z01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symbol2symbol_main(method, quadrants, input_data_path, distances, output_path, params = None, mod_csv = False, mod_original = False, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  \n",
        "  if params is None and method == 'GD':\n",
        "    output_features = \"/{}_alpha_0.75_beta_0.25_features.csv\".format(str(method))\n",
        "  elif method == 'Z':\n",
        "    output_features = \"/{}_features.csv\".format(str(method))\n",
        "  elif params is not None and method == 'GD':\n",
        "    decimal_alpha = modf(params['alpha'])\n",
        "    decimal_beta = modf(params['beta'])\n",
        "\n",
        "    output_features = \"/{}_alpha_p{}_beta_p{}_features.csv\".format(str(method), str(decimal_alpha), str(decimal_beta))\n",
        "\n",
        "  # Get input data\n",
        "  X, Y = create_df(input_data_path, distances, nsymbols, min_dist, max_dist)\n",
        "  X = X.applymap(strToTuple)\n",
        "\n",
        "  # Generate mod of the original file\n",
        "  if mod_original == True:\n",
        "    print('Generating the modified file for the original data')\n",
        "    mod_df_generator(X, input_data_path)\n",
        "  \n",
        "  train_idxs2, test_idxs2 = test_train_indexes_v2()\n",
        "\n",
        "  X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "  X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\") \n",
        "\n",
        "  data_new = {}\n",
        "\n",
        "  for i in range(0,25):\n",
        "    data_new[str(80*(i+1))] = {\"Train\":X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}  \n",
        "\n",
        "  first = True\n",
        "  modify_all_data_df = pd.DataFrame()\n",
        "  for i in tqdm(range(25)):\n",
        "      print('\\n')\n",
        "      print(\"i = \",i)\n",
        "      if mod_csv == True:\n",
        "        modify_data_df = pd.DataFrame()\n",
        "      for j in range(i+1,25):\n",
        "          print(\" j = \",j)\n",
        "          source = data_new[str(distances[i]*80)]['Train']\n",
        "          target = data_new[str(distances[j]*80)]['Train']\n",
        "          source_test = data_new[str(distances[i]*80)]['Test']\n",
        "\n",
        "          source_test2 = source_test.copy()\n",
        "\n",
        "          for quadrant in quadrants:\n",
        "              print(\"   quadrant = \", quadrant)\n",
        "              if method == \"GD\":\n",
        "                M, b = compute_parameters(quadrant, 'GD', source, target, params=params)\n",
        "                new_points, indexes = modify_const_GD(quadrant, source_test, M, b)\n",
        "              elif method == \"Z\":\n",
        "                mean_source,cov_source,mean_target,cov_target = compute_parameters(quadrant, 'Z', source, target, params=None)\n",
        "                new_points, indexes = modify_const_Z(quadrant,source_test,mean_source,cov_source,mean_target,cov_target)\n",
        "\n",
        "              for k in range(len(indexes)):\n",
        "                  source_test2.iloc[indexes[k][0],indexes[k][1]] = complex(new_points[k][0], new_points[k][1])\n",
        "\n",
        "          if mod_csv == True:\n",
        "            old_df = source_test2.copy()\n",
        "            old_df.insert(loc = 0,column = 'source_distance',value = str(distances[i]*80))\n",
        "            old_df.insert(loc = 1,column = 'target_distance',value = str(distances[j]*80))\n",
        "\n",
        "            modify_data_df  = pd.concat([modify_data_df, old_df], ignore_index=True)\n",
        "       \n",
        "          F=[]\n",
        "          for k in range(source_test2.shape[0]):\n",
        "              data2=list(source_test2.iloc[k,:])\n",
        "              data2=[[float(d.real), float(d.imag)] for d in data2]\n",
        "              gmm = GaussianMixture(n_components=16, random_state=0, means_init=my_centers).fit(data2)\n",
        "              mus=gmm.means_\n",
        "              sigmas=gmm.covariances_\n",
        "\n",
        "              features=[distances[i]*80, distances[j]*80]\n",
        "\n",
        "              for z in selCP_pos:\n",
        "                  mindist=None\n",
        "                  k_inc=None\n",
        "                  for w in range(16):\n",
        "                      d=L2dist(mus[w],z)\n",
        "                      if mindist is None or mindist>d:\n",
        "                          mindist=d\n",
        "                          k_inc=w\n",
        "\n",
        "                  covmat=np.concatenate(list(sigmas[k_inc])).ravel().tolist()\n",
        "                  features = [*features, *mus[k_inc], *covmat]\n",
        "              F.append(features)\n",
        "          \n",
        "          header=['source_distance', 'target_distance']\n",
        "          \n",
        "          for j in selCP:\n",
        "              header=[*header,*['mu_r_'+str(j),'mu_i_'+str(j),'sigma_rr_'+str(j),'sigma_ri_'+str(j),'sigma_ir_'+str(j),'sigma_ii_'+str(j)]]\n",
        "   \n",
        "          with open(output_path + output_features, 'a', encoding='UTF8', newline='') as f:\n",
        "              writer = csv.writer(f)\n",
        "              # write the header\n",
        "              if first:\n",
        "                writer.writerow(header)\n",
        "                first = False\n",
        "              # write multiple rows\n",
        "              writer.writerows(F)  \n",
        "\n",
        "      if mod_csv == True and i<24:\n",
        "        # Generate mod for modified file\n",
        "        print('Generating the modified file for the modified data')\n",
        "        mod_df_generator(modify_data_df, output_path, raw_data = False, mod_i = str(distances[i]*80), method = method)\n",
        "\n",
        "        # Get modified data points\n",
        "        modify_all_data_df  = pd.concat([modify_all_data_df, modify_data_df], ignore_index=True)\n",
        "\n",
        "  if mod_csv == True:\n",
        "    # Save the modified data\n",
        "    print('Saving the modified data')\n",
        "    filename = ('/{}_consts_modified_data.csv'.format(str(method)))\n",
        "    # Removing parenthesis of complex numbers\n",
        "    headers_names = list(modify_all_data_df.columns)\n",
        "    for h in headers_names:\n",
        "      if h != 'source_distance' or h != 'target_distance':\n",
        "        modify_all_data_df[h] = modify_all_data_df[h].apply(str).str.replace('\\(|\\)','')\n",
        "    modify_all_data_df.to_csv(str(output_path)+filename, index=False, encoding='utf-8-sig')        "
      ],
      "metadata": {
        "id": "v0EbouGD82YI"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main v2"
      ],
      "metadata": {
        "id": "svRXwZlV1cHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symbol2symbol_main_v2(method, quadrants, input_data_path, distances, output_path, source_params=None, params = None, mod_csv = False, mod_original = False, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  \n",
        "  if params is None and method == 'GD':\n",
        "    output_features = \"/{}_alpha_0.75_beta_0.25_radius_{}_funct_{}_features.csv\".format(str(method), str(source_params[1]), str(source_params[2]))\n",
        "  elif method == 'Z':\n",
        "    output_features = \"/{}_radius_{}_funct_{}_features.csv\".format(str(method), str(source_params[1]), str(source_params[2]))\n",
        "  elif params is not None and method == 'GD':\n",
        "    decimal_alpha = modf(params['alpha'])\n",
        "    decimal_beta = modf(params['beta'])\n",
        "\n",
        "    output_features = \"/{}_alpha_p{}_beta_p{}_radius_{}_funct_{}_features.csv\".format(str(method), str(decimal_alpha), str(decimal_beta), str(source_params[1]), str(source_params[2]))\n",
        " \n",
        "  # Get input data\n",
        "  X, Y = create_df(input_data_path, distances, nsymbols, min_dist, max_dist)\n",
        "  X = X.applymap(strToTuple)\n",
        "  \n",
        "  input_source = source_params[0]\n",
        "  source_df = read_synthetic_data_v2(input_path=input_source, radius=source_params[1], function=source_params[2])\n",
        "  source_df = source_df.applymap(strToTuple_v2)\n",
        "\n",
        "  # Generate mod of the original file\n",
        "  if mod_original == True:\n",
        "    print('Generating the modified file for the original data')\n",
        "    mod_df_generator(X, input_data_path)\n",
        "  \n",
        "  train_idxs2, test_idxs2 = test_train_indexes_v2()\n",
        "  X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "  X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\") \n",
        "\n",
        "  source_train_idxs2, source_test_idxs2 = test_train_indexes_v2(num_files=1)\n",
        "  source_X_train2 = source_df.iloc[source_train_idxs2].reset_index(drop = \"True\")\n",
        "  source_X_test2 = source_df.iloc[source_test_idxs2].reset_index(drop = \"True\") \n",
        "\n",
        "  data_new = {}\n",
        "\n",
        "  for i in range(0,25):\n",
        "    if i == 0:\n",
        "      data_new[str(80*(i))] = {\"Train\":source_X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":source_X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}\n",
        "      data_new[str(80*(i+1))] = {\"Train\":X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}  \n",
        "    else:\n",
        "      data_new[str(80*(i+1))] = {\"Train\":X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}  \n",
        "  \n",
        "  first = True\n",
        "  modify_all_data_df = pd.DataFrame()\n",
        "\n",
        "  # modifying algorithm to only calculate for one source distance\n",
        "  i_loop = 25\n",
        "  if source_params is not None:\n",
        "    i_loop = 1\n",
        "\n",
        "  for i in range(i_loop):\n",
        "      #print('\\n')\n",
        "      #print(\"i = \",i)\n",
        "\n",
        "      if mod_csv == True:\n",
        "        modify_data_df = pd.DataFrame()\n",
        "\n",
        "      for j in tqdm(range(i,25)):\n",
        "          #print(\" j = \",j)        \n",
        "          source = data_new[str(0)]['Train']\n",
        "          target = data_new[str(distances[j]*80)]['Train']\n",
        "\n",
        "          source_test = data_new[str(0)]['Test']\n",
        "          source_test2 = source_test.copy()\n",
        "\n",
        "          for quadrant in quadrants:\n",
        "              #print(\"   quadrant = \", quadrant)\n",
        "              if method == \"GD\":\n",
        "                M, b = compute_parameters(quadrant, 'GD', source, target, params=params)\n",
        "                new_points, indexes = modify_const_GD(quadrant, source_test, M, b)\n",
        "              elif method == \"Z\":\n",
        "                mean_source,cov_source,mean_target,cov_target = compute_parameters(quadrant, 'Z', source, target, params=None)\n",
        "                new_points, indexes = modify_const_Z(quadrant,source_test,mean_source,cov_source,mean_target,cov_target)\n",
        "\n",
        "              for k in range(len(indexes)):\n",
        "                  source_test2.iloc[indexes[k][0],indexes[k][1]] = complex(new_points[k][0], new_points[k][1])\n",
        "\n",
        "          if mod_csv == True:\n",
        "            old_df = source_test2.copy()\n",
        "            old_df.insert(loc = 0,column = 'source_distance',value = str(0))\n",
        "            old_df.insert(loc = 1,column = 'target_distance',value = str(distances[j]*80))\n",
        "\n",
        "            modify_data_df  = pd.concat([modify_data_df, old_df], ignore_index=True)\n",
        "\n",
        "          F=[]\n",
        "          for k in range(source_test2.shape[0]):\n",
        "              data2=list(source_test2.iloc[k,:])\n",
        "              data2=[[float(d.real), float(d.imag)] for d in data2]\n",
        "              gmm = GaussianMixture(n_components=16, random_state=0, means_init=my_centers).fit(data2)\n",
        "              mus=gmm.means_\n",
        "              sigmas=gmm.covariances_\n",
        "              \n",
        "              # Adding original distance and target distance columns\n",
        "              features=[str(0), distances[j]*80]\n",
        "\n",
        "              for z in selCP_pos:\n",
        "                  mindist=None\n",
        "                  k_inc=None\n",
        "                  for w in range(16):\n",
        "                      d=L2dist(mus[w],z)\n",
        "                      if mindist is None or mindist>d:\n",
        "                          mindist=d\n",
        "                          k_inc=w\n",
        "\n",
        "                  covmat=np.concatenate(list(sigmas[k_inc])).ravel().tolist()\n",
        "                  features = [*features, *mus[k_inc], *covmat]\n",
        "              F.append(features)\n",
        "          \n",
        "          header=['source_distance', 'target_distance']\n",
        "          \n",
        "          for j in selCP:\n",
        "              header=[*header,*['mu_r_'+str(j),'mu_i_'+str(j),'sigma_rr_'+str(j),'sigma_ri_'+str(j),'sigma_ir_'+str(j),'sigma_ii_'+str(j)]]\n",
        "          \n",
        "          with open(output_path + output_features, 'a', encoding='UTF8', newline='') as f:\n",
        "              writer = csv.writer(f)\n",
        "              # write the header\n",
        "              if first:\n",
        "                writer.writerow(header)\n",
        "                first = False\n",
        "              # write multiple rows\n",
        "              writer.writerows(F)  \n",
        "\n",
        "      if mod_csv == True and i<24:\n",
        "        # Generate mod for modified file\n",
        "        #print('Generating the modified file for the modified data')\n",
        "        if source_params is not None:\n",
        "          mod_df_generator_v2(modify_data_df, output_path, radius=source_params[1], funct=source_params[2], raw_data = False, mod_i = str(0), method = method)\n",
        "        else:\n",
        "          mod_df_generator(modify_data_df, output_path, raw_data = False, mod_i = str(0), method = method)\n",
        "\n",
        "        # Get modified data points\n",
        "        modify_all_data_df  = pd.concat([modify_all_data_df, modify_data_df], ignore_index=True)\n",
        "\n",
        "  if mod_csv == True:\n",
        "    # Save the modified data\n",
        "    print('Saving the modified data')\n",
        "    filename = ('/{}_consts_modified_data_radius_{}_funct_{}.csv'.format(str(method), str(source_params[1]), str(source_params[2])))\n",
        "    # Removing parenthesis of complex numbers\n",
        "    headers_names = list(modify_all_data_df.columns)\n",
        "    for h in headers_names:\n",
        "      if h != 'source_distance' or h != 'target_distance':\n",
        "        modify_all_data_df[h] = modify_all_data_df[h].apply(str).str.replace('\\(|\\)','')\n",
        "    \n",
        "    modify_all_data_df = modify_all_data_df.drop_duplicates()\n",
        "    modify_all_data_df.to_csv(str(output_path)+filename, index=False, encoding='utf-8-sig')   \n",
        "\n",
        "  # Remove duplicates in output files of features\n",
        "  #dups_remover(output_path + output_features)     "
      ],
      "metadata": {
        "id": "T8RXepPEX3Bv"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Main "
      ],
      "metadata": {
        "id": "TOT-h2MA_ZgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Enviroment"
      ],
      "metadata": {
        "id": "I4LGRwMj_nPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE PARA USAR DESDE COLAB\n",
        "\n",
        "# Google drive loading as work station for local-usage of the files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount= True)\n",
        "\n",
        "#-----------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHgmPMH9_jM4",
        "outputId": "0aac2861-7ee4-4d70-83af-bafc39fe7779"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para cambiar los paths rapido.\n",
        "workers = [\"Ronald\", \"Local\"]\n",
        "\n",
        "# Change the number to change the paths.\n",
        "worker = workers[0]\n",
        "\n",
        "if worker == \"Ronald\":\n",
        "  path= \"/content/gdrive/MyDrive/Symbol_to_Symbol/ANN_dataset\"\n",
        "  synthetic_path= \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset/synthetic_constellations\"\n",
        "  out_path = \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset\"\n",
        "else: path = os.getcwd()"
      ],
      "metadata": {
        "id": "wEXfbKQn_li-"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Synthetic data"
      ],
      "metadata": {
        "id": "eh_IslCt-aj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_synthetic_data_v2(input_path, radius, function):\n",
        "  syn_path = input_path + '/synthetic_cosntelation_radius_{}_funct_{}.csv'.format(str(radius), str(function))\n",
        "  df = pd.read_csv(syn_path)  \n",
        "  df = df.iloc[:, 2:df.shape[1]]\n",
        "  return df"
      ],
      "metadata": {
        "id": "Wb3LxaZJybkt"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Variables"
      ],
      "metadata": {
        "id": "wNtoRKInAzGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "\n",
        "distances=[i for i in range(1,26)]\n",
        "nsamples=50\n",
        "span_length=80\n",
        "nsymbols=2048\n",
        "\n",
        "######\n",
        "min_dist=0\n",
        "max_dist=3000\n",
        "selCP=[1,7,10,15]\n",
        "selCP_pos=[(-3,3),(1,1),(-1,-1),(1,-3)]\n",
        "my_centers=[[-3,3],[-1,3],[1,3],[3,3],[-3,1],[-1,1],[1,1],[3,1],[-3,-1],[-1,-1],[1,-1],[3,-1], [-3,-3],[-1,-3],[1,-3],[3,-3]]\n",
        "######"
      ],
      "metadata": {
        "id": "zf6EB5DE_1Ln"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Mod original file synthetic"
      ],
      "metadata": {
        "id": "FXOv0HWT6iqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_path = \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset/synthetic_constellations\"\n",
        "fun = ['uniform', 'non_uniform', 'gaussian']\n",
        "rad = [0.04, 0.05, 0.06]\n",
        "#rad = [0.00000001, 0.01, 0.02, 0.03]\n",
        "\n",
        "for f in fun:\n",
        "  for rd in rad:\n",
        "    print('---------------')\n",
        "    print('Evaluating {} function with a dispersion radius of {}'.format(f, rd))\n",
        "    source_params = [synthetic_path, rd, f]\n",
        "    source_df = read_synthetic_data_v2(input_path=source_params[0], radius=source_params[1], function=source_params[2])\n",
        "    source_df = source_df.applymap(strToTuple_v2)\n",
        "    mod_df_generator_v2(source_df, synthetic_path, radius=rd, funct=f, raw_data = True, mod_i = None, method = None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLOegHNK6mdx",
        "outputId": "42af778d-0898-4c7a-dc36-3d24b2e62d72"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------\n",
            "Evaluating uniform function with a dispersion radius of 0.04.\n",
            "---------------\n",
            "Evaluating uniform function with a dispersion radius of 0.05.\n",
            "---------------\n",
            "Evaluating uniform function with a dispersion radius of 0.06.\n",
            "---------------\n",
            "Evaluating non_uniform function with a dispersion radius of 0.04.\n",
            "---------------\n",
            "Evaluating non_uniform function with a dispersion radius of 0.05.\n",
            "---------------\n",
            "Evaluating non_uniform function with a dispersion radius of 0.06.\n",
            "---------------\n",
            "Evaluating gaussian function with a dispersion radius of 0.04.\n",
            "---------------\n",
            "Evaluating gaussian function with a dispersion radius of 0.05.\n",
            "---------------\n",
            "Evaluating gaussian function with a dispersion radius of 0.06.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution Z Score"
      ],
      "metadata": {
        "id": "5rpJNtY-AOrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lauch"
      ],
      "metadata": {
        "id": "qXP72mvG_ucs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard run"
      ],
      "metadata": {
        "id": "RMfqWMTI-me3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE SELCET THE METHOD AND QUADRANTS THAT ARE DESIRED TO BE TESTED\n",
        "method = \"Z\" # or method = \"GD\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "\n",
        "#Output mod files\n",
        "output_path = path + '/modifiedData/'+ method\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgsmrggO_e7Y",
        "outputId": "5ee24408-7cfc-42dc-c4b2-35e7d7b6c1c8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath selected: /content/gdrive/MyDrive/Symbol_to_Symbol/ANN_dataset/rawData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbol2symbol_main(method, quadrants, input_data_path, distances, output_path, params = None, mod_csv = True, mod_original = True, nsymbols = 2048, min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "uBDnCGBx_wMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic Run"
      ],
      "metadata": {
        "id": "WCzNMtDo-uQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic Run Params\n",
        "\n",
        "method = \"Z\" # or method = \"GD\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))\n",
        "\n",
        "output_path = out_path + '/modifiedData/synthetic_data/'+ method\n",
        "\n",
        "#source_params = [source_path, source_radius, source_function]"
      ],
      "metadata": {
        "id": "8RzXmH1g-3oL",
        "outputId": "873d74b2-302c-4d8a-dc8a-8fc94f5a2d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath selected: /content/gdrive/MyDrive/Symbol_to_Symbol/ANN_dataset/rawData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fun = ['uniform', 'non_uniform', 'gaussian']\n",
        "#rad = [0.00000001, 0.01, 0.02, 0.03]\n",
        "rad = [0.04, 0.05, 0.06]\n",
        "synthetic_path= \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset/synthetic_constellations\"\n",
        "\n",
        "for f in fun:\n",
        "  for rd in rad:\n",
        "    print('---------------')\n",
        "    print('Evaluating {} function with a dispersion radius of {}.'.format(f, rd))\n",
        "\n",
        "    source_params = [synthetic_path, rd, f]\n",
        "    symbol2symbol_main_v2(method, quadrants, input_data_path, distances, output_path, source_params=source_params, params = None, mod_csv = True, mod_original = False, nsymbols = 2048, min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "w1QIujEP-wgn",
        "outputId": "46320ced-67df-4493-f55a-ddca9926cd95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------\n",
            "Evaluating uniform function with a dispersion radius of 0.04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:06<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data\n",
            "---------------\n",
            "Evaluating uniform function with a dispersion radius of 0.05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:05<00:00,  4.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data\n",
            "---------------\n",
            "Evaluating uniform function with a dispersion radius of 0.06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:05<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data\n",
            "---------------\n",
            "Evaluating non_uniform function with a dispersion radius of 0.04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:05<00:00,  4.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data\n",
            "---------------\n",
            "Evaluating non_uniform function with a dispersion radius of 0.05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:06<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data\n",
            "---------------\n",
            "Evaluating non_uniform function with a dispersion radius of 0.06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:06<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data\n",
            "---------------\n",
            "Evaluating gaussian function with a dispersion radius of 0.04.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:05<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data\n",
            "---------------\n",
            "Evaluating gaussian function with a dispersion radius of 0.05.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:05<00:00,  4.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data\n",
            "---------------\n",
            "Evaluating gaussian function with a dispersion radius of 0.06.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:05<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution Gradient Descent"
      ],
      "metadata": {
        "id": "z6vVPAoUAeaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lauch"
      ],
      "metadata": {
        "id": "ytfIUkboArYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standard Run"
      ],
      "metadata": {
        "id": "zmBL9fb_AOOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE SELCET THE METHOD AND QUADRANTS THAT ARE DESIRED TO BE TESTED\n",
        "method = \"GD\" # or method = \"Z\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))\n",
        "\n",
        "#Output mod files\n",
        "output_path = out_path + '/modifiedData/'+ method\n",
        "\n",
        "# Params for gradient descent alpha and beta\n",
        "a = 0.7\n",
        "b = 0.2\n",
        "params = {\"alpha\": float(a), \"beta\": float(b)}"
      ],
      "metadata": {
        "id": "_iP0wMjyArEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol2symbol_main(method, quadrants, input_data_path, distances, output_path, mod_csv = True, mod_original = False,  params = None, nsymbols = 2048, min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "priZkLvqAHRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic Run"
      ],
      "metadata": {
        "id": "DiVHIvbNAS__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic Run Params\n",
        "\n",
        "method = \"GD\" # or method = \"Z\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))\n",
        "\n",
        "output_path = out_path + '/modifiedData/synthetic_data/'+ method\n",
        "\n",
        "#source_params = [source_path, source_radius, source_function]"
      ],
      "metadata": {
        "id": "maJry8ynAU2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf53217-a737-4468-a20b-6fad82feed75"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath selected: /content/gdrive/MyDrive/Symbol_to_Symbol/ANN_dataset/rawData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fun = ['uniform', 'non_uniform', 'gaussian']\n",
        "rad = [0.00000001, 0.01, 0.02, 0.03]\n",
        "synthetic_path= \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset/synthetic_constellations\"\n",
        "\n",
        "for f in fun:\n",
        "  for rd in rad:\n",
        "    print('---------------')\n",
        "    print('Evaluating {} function with a dispersion radius of {}.'.format(f, rd))\n",
        "    \n",
        "    source_params = [synthetic_path, rd, f]\n",
        "    symbol2symbol_main_v2(method, quadrants, input_data_path, distances, output_path, source_params=source_params, params = None, mod_csv = True, mod_original = False, nsymbols = 2048, min_dist = 0, max_dist = 3000)    "
      ],
      "metadata": {
        "id": "WFLCrLXmAa0i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "b0ca0071-2a9c-49d6-f48b-45fc589c2276"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------\n",
            "Evaluating uniform function with a dispersion radius of 1e-08.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "i =  0\n",
            " j =  1\n",
            "   quadrant =  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [41:42<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-ccbd1e87663e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msource_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msynthetic_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msymbol2symbol_main_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadrants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsymbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-7c2360dfad92>\u001b[0m in \u001b[0;36msymbol2symbol_main_v2\u001b[0;34m(method, quadrants, input_data_path, distances, output_path, source_params, params, mod_csv, mod_original, nsymbols, min_dist, max_dist)\u001b[0m\n\u001b[1;32m     71\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   quadrant = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadrant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GD\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquadrant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0mnew_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodify_const_GD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquadrant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m               \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Z\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-becd57eb7e3f>\u001b[0m in \u001b[0;36mcompute_parameters\u001b[0;34m(const, method, source, target, params, log)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beta\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-51b0d8a7148a>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(alpha, beta, m_tg, m_og, cov_tg, cov_og, nu, log)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# print('From:', M @ cov_source @ np.transpose(M))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# print('To:', cov_target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_tg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_og\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_tg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_og\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m  \u001b[0mL\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mMs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-14f886bc4246>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(alpha, beta, m_tg, m_og, cov_tg, cov_og, M, b)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_tg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_og\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_tg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_og\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mcov_og\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcov_tg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0msecond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mm_og\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm_tg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msecond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
