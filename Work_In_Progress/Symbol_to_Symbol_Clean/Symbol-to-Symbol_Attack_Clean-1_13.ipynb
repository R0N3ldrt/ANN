{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3ZKGJ0a1bjSdf712g+AMx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0N3ldrt/Thesis/blob/main/Symbol-to-Symbol_Attack_Clean-1_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbol-to_Symbol Attack"
      ],
      "metadata": {
        "id": "m0Bi4sm804DM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Necesary Libraries"
      ],
      "metadata": {
        "id": "Wqnrp_jX0-IO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necesary libraries\n",
        "# Libraries for correct code execution \n",
        "\n",
        "import os, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import csv\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "from math import modf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "W4KNWD010_XY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Train/Test data"
      ],
      "metadata": {
        "id": "iSiPMiQE1D-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(input_data_path, distances, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  X=None\n",
        "  Y=[]\n",
        "  colnames=['i'+str(i) for i in range(nsymbols)]\n",
        "\n",
        "  for d in distances:\n",
        "    dist=d*span_length\n",
        "    if dist<min_dist or dist>max_dist: continue\n",
        "    filename='consts_'+str(d)+'span.csv'\n",
        "    df_aux=pd.read_csv(input_data_path+'/'+filename, sep=\",\", header=None)\n",
        "    df_aux = df_aux.T\n",
        "    df_aux.columns=colnames\n",
        "    Y=Y+[dist]*df_aux.shape[0]\n",
        "    if X is None: X=df_aux\n",
        "    else: X=X.append(df_aux)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "IUbBYpr71R0R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strToTuple(s):\n",
        "    s_aux=s.split(\"i\")\n",
        "    s=s_aux[0]+\"j\"\n",
        "    return complex(s)\n",
        "\n",
        "def strToTuple_v2(s):\n",
        "    return complex(s)"
      ],
      "metadata": {
        "id": "1okA-BcY1UIC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v1():\n",
        "  train_idxs = []\n",
        "  test_idxs = []\n",
        "  for i in range(25):\n",
        "      for j in range(25):\n",
        "          train_idxs.append(50*i + j)\n",
        "          test_idxs.append(50*(i+1)-1-j)\n",
        "  return train_idxs, test_idxs"
      ],
      "metadata": {
        "id": "eQA0MFsb1VmC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v2():\n",
        "  train_idxs2 = []\n",
        "  test_idxs2 = []\n",
        "  for i in range(25):\n",
        "      for j in range(25):\n",
        "          test_idxs2.append(50*(i+1)-1-j)\n",
        "\n",
        "  for i in range(25):\n",
        "    for j in range(2):\n",
        "      train_idxs2.append(50*i + j)\n",
        "  return train_idxs2, test_idxs2"
      ],
      "metadata": {
        "id": "Ggyeg8kj1W_9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "D7t_OQ2X1iMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent Function"
      ],
      "metadata": {
        "id": "463uTmP01ner"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_b (M,m_og,m_tg,b,beta):\n",
        "  return 2*beta*(M @ m_og + b - m_tg)"
      ],
      "metadata": {
        "id": "G4S0fONp1tgI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_M(M,cov_og,cov_tg,alpha):\n",
        "    error = M @ cov_og @ np.transpose(M) - cov_tg  \n",
        "\n",
        "    m1 = (2*error[0][0] * (2*cov_og[0][0]*M[0][0] + 2*cov_og[0][1]*M[0][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[1][0] + cov_og[0][1]*M[1][1]))\n",
        "    \n",
        "    m2 = (2*error[0][0] * (2*cov_og[1][1]*M[0][1] + 2*cov_og[0][1]*M[0][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[1][0] + cov_og[1][1]*M[1][1]))\n",
        "    \n",
        "    m3 = (2*error[1][1] * (2*cov_og[0][0]*M[1][0] + 2*cov_og[0][1]*M[1][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[0][0] + cov_og[0][1]*M[0][1]))\n",
        "\n",
        "    m4 = (2*error[1][1] * (2*cov_og[0][0]*M[1][1] + 2*cov_og[0][1]*M[1][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[0][0] + cov_og[1][1]*M[0][1]))\n",
        "    \n",
        "    return alpha*np.array([[m1, m2], [m3, m4]])"
      ],
      "metadata": {
        "id": "Jwj71thl1vpu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(alpha,beta,m_tg,m_og,cov_tg,cov_og,nu,log):\n",
        "  Ms = []\n",
        "  bs = []\n",
        "  M = np.random.rand(2,2)\n",
        "  #M = np.array([[1, 0], [0, 1]])\n",
        "  b = np.random.rand(2,1)\n",
        "  #b = np.array([[0], [0]])\n",
        "  #for i in range(100000):\n",
        "  i = 0\n",
        "  while True:\n",
        "    # print('From:', M @ cov_source @ np.transpose(M))\n",
        "    # print('To:', cov_target)\n",
        "    L = loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b) \n",
        "    if  L < 1e-20:\n",
        "        Ms.append(M)\n",
        "        bs.append(b)\n",
        "        break\n",
        "    b = b - nu*grad_b(M,m_og,m_tg,b,beta)\n",
        "    M = M - nu*grad_M(M,cov_og,cov_tg,alpha)\n",
        "    i+= 1\n",
        "    if (i>= 5000 and i <= 5025) or (i>= 5975 and i <= 6000):\n",
        "      Ms.append(M)\n",
        "      bs.append(b)\n",
        "    if not i%5000 and log: print(L)\n",
        "  if log: print(\"-\"*25)\n",
        "  return Ms,bs"
      ],
      "metadata": {
        "id": "bS620BBC1xQw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute parameters and mean/covariance"
      ],
      "metadata": {
        "id": "3f_zKFpi10iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mean_and_cov(data):\n",
        "  aux_x = [] # Reales\n",
        "  aux_y = [] # Imag\n",
        "  for obs in data:\n",
        "    aux_x.append(obs[0])\n",
        "    aux_y.append(obs[1])\n",
        "  return np.array([[np.mean(aux_x)],[np.mean(aux_y)]]), np.cov(aux_x,aux_y)\n",
        "\n",
        "\n",
        "def total_loss(m_mod,m_tg,cov_mod,cov_tg):\n",
        "  return (sum(sum(np.power(cov_mod-cov_tg,2))) + sum(np.power(m_mod - m_tg,2)))[0]\n",
        "\n",
        "\n",
        "def loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b):\n",
        "  first = alpha*sum(sum(np.power(M @ cov_og @ np.transpose(M) - cov_tg, 2)))\n",
        "  second = beta*sum(np.power(M @ m_og + b - m_tg, 2))\n",
        "  a = first+second\n",
        "  return a"
      ],
      "metadata": {
        "id": "aEey3Em513gb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_parameters (const,method,source,target, params = None, log = False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  q_target = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "\n",
        "    q_source += [[x.real,x.imag] for x in source.values.tolist()[i] if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "    q_target += [[x.real,x.imag] for x in target.values.tolist()[i]if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "\n",
        "  unbiased = (len(q_source)/(len(q_source)-1) * 125/126)\n",
        "\n",
        "  mean_source,cov_source = compute_mean_and_cov(q_source)\n",
        "  mean_target, cov_target= compute_mean_and_cov(q_target)\n",
        "\n",
        "  cov_source *= unbiased\n",
        "  cov_target *= unbiased\n",
        "\n",
        "  if method == \"GD\":\n",
        "  \n",
        "    alpha = params[\"alpha\"] if params[\"alpha\"] is not None and params[\"alpha\"]>0 and params[\"alpha\"]<=1 and params[\"alpha\"]>params[\"beta\"]  else 3/4\n",
        "    beta = params[\"beta\"] if params[\"beta\"] is not None and params[\"beta\"]>=0 and params[\"beta\"]<1 and params[\"beta\"]<params[\"alpha\"]  else 1/4\n",
        "\n",
        "    M, b = gradient_descent(alpha,beta,mean_target,mean_source,cov_target,cov_source, 0.5,log)\n",
        "    return M,b\n",
        "\n",
        "  elif method == \"Z\":\n",
        "    return mean_source,cov_source,mean_target,cov_target"
      ],
      "metadata": {
        "id": "EsLrPZeS15_a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modify GD/Z"
      ],
      "metadata": {
        "id": "uA2cDNyE17Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_GD(const,source,M,b, target = None, return_plots=False):\n",
        "\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "      \n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  for mult in mults:\n",
        "    res = (M @ mult + b).tolist()\n",
        "\n",
        "    # --------- Old line ---------\n",
        "    #new_points.append([res[0][0],res[1][0]])\n",
        "    nested_check = any(isinstance(i, list) for i in res[0])\n",
        "    if nested_check:\n",
        "      new_points.append([res[0][0][0],res[0][1][0]])\n",
        "    else:\n",
        "      new_points.append([res[0][0],res[1][0]])\n",
        "\n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      return new_points, q_target\n",
        "\n",
        "  return new_points, indexes"
      ],
      "metadata": {
        "id": "z-7kfNDv2Bfo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_Z(const,source,mean_source,cov_source,mean_target,cov_target,target = None, return_plots=False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "\n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  w, v = np.linalg.eig(cov_source)\n",
        "  S1 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "  w, v = np.linalg.eig(cov_target)\n",
        "  S2 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "\n",
        "  for mult in mults:\n",
        "    normalized = np.linalg.inv(S1) @ (mult - mean_source)\n",
        "    denormalized = S2 @ normalized + mean_target\n",
        "\n",
        "    new_points.append([denormalized[0][0], denormalized[1][0]])\n",
        "\n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      \n",
        "\n",
        "  return new_points, indexes"
      ],
      "metadata": {
        "id": "TLrAx2KP2DXH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare plots"
      ],
      "metadata": {
        "id": "EtBxMfUB2JrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_comparison_plot(mod_points,ptarget, return_plots=False):\n",
        "  x1 = [x[0] for  x in mod_points]\n",
        "  y1 = [x[1] for  x in mod_points]\n",
        "  x2 = [x[0] for  x in ptarget]\n",
        "  y2 = [x[1] for  x in ptarget]\n",
        "\n",
        "  if return_plots:\n",
        "      return go.Scatter(x = x1, y = y1, mode='markers'), go.Scatter(x = x2, y = y2,mode='markers') \n",
        "\n",
        "  fig = make_subplots(rows=1, cols=2)\n",
        "  fig.add_trace(\n",
        "    go.Scatter(x = x1, y = y1,mode='markers'),\n",
        "    \n",
        "    row=1, col=1\n",
        "  )\n",
        "  fig.add_trace(\n",
        "    go.Scatter(x = x2, y = y2,mode='markers'),\n",
        "    row=1, col=2\n",
        "  )\n",
        "  fig.update_layout(height=500, width=1000, title_text=\"Point comparison\",autosize = False)\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "irTwDoUA2L9A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distance Calc"
      ],
      "metadata": {
        "id": "1KBVQKZg2jvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def L2dist(a,b):\n",
        "    return math.sqrt(math.pow(a[0]-b[0],2)+math.pow(a[1]-b[1],2))"
      ],
      "metadata": {
        "id": "IYbhKHJu2mlD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mod files generator"
      ],
      "metadata": {
        "id": "WU6cQzM9_OT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mod_df_generator(df, output_filepath, raw_data = True, mod_i = None, method = None):\n",
        "  sample_arr = []\n",
        "  symbol_arr = []\n",
        "  real_arr = []\n",
        "  imag_arr = []\n",
        "\n",
        "  # For alraeady modify data\n",
        "  if raw_data != True:\n",
        "\n",
        "    source_arr = []\n",
        "    target_arr = []\n",
        "\n",
        "    vals_df = df.iloc[:, 2:df.shape[1]]\n",
        "    vals_df = vals_df.applymap(strToTuple_v2)\n",
        " \n",
        "    distances_df = df.iloc[:, [0, 1]]\n",
        "\n",
        "    sample_cnt = 1\n",
        "    for i in range(len(vals_df)):\n",
        "      symbol_cnt = 1\n",
        "      for x in vals_df.values.tolist()[i]:\n",
        "\n",
        "        real_arr.append(x.real)\n",
        "        imag_arr.append(x.imag)\n",
        "\n",
        "        sample_arr.append(sample_cnt)\n",
        "        symbol_arr.append(symbol_cnt)    \n",
        "        symbol_cnt += 1\n",
        "\n",
        "        source_arr.append(distances_df['source_distance'].loc[distances_df.index[i]])\n",
        "        target_arr.append(distances_df['target_distance'].loc[distances_df.index[i]])\n",
        "        \n",
        "      sample_cnt += 1\n",
        "\n",
        "    data = {'Source_Distance':source_arr, 'Target_Distance':target_arr, 'Sample_Id':sample_arr, 'Symbol_Id':symbol_arr, 'Real':real_arr, 'Imag':imag_arr}  \n",
        "    \n",
        "    mod_df = pd.DataFrame(data)\n",
        "\n",
        "    filename = ('/{}_mod/consts_modified_i{}_span_mod.csv'.format(str(method), str(mod_i)))\n",
        "\n",
        "    mod_df.to_csv(str(output_filepath)+filename, index=False, encoding='utf-8-sig')\n",
        "    \n",
        "  else:\n",
        "    vals_df = df\n",
        "\n",
        "    sample_cnt = 1\n",
        "    file_cnt = 1\n",
        "    for i in range(len(vals_df)):\n",
        "      symbol_cnt = 1\n",
        "      for x in vals_df.values.tolist()[i]:\n",
        "        real_arr.append(x.real)\n",
        "        imag_arr.append(x.imag)\n",
        "\n",
        "        sample_arr.append(sample_cnt)\n",
        "        symbol_arr.append(symbol_cnt)\n",
        "        symbol_cnt += 1\n",
        "\n",
        "      sample_cnt += 1\n",
        "      if (i+1) % 50 == 0:\n",
        "        data = {'Sample_Id':sample_arr, 'Symbol_Id':symbol_arr, 'Real':real_arr, 'Imag':imag_arr}  \n",
        "        \n",
        "        mod_df = pd.DataFrame(data)\n",
        "        \n",
        "        filename = ('/rawData_mod/consts_{}span_mod.csv'.format(file_cnt))\n",
        "\n",
        "        file_cnt += 1\n",
        "        mod_df.to_csv(str(output_filepath)+filename, index=False, encoding='utf-8-sig') \n",
        "        \n",
        "        # Reset values\n",
        "        sample_cnt = 1\n",
        "        sample_arr = []\n",
        "        symbol_arr = []\n",
        "        real_arr = []\n",
        "        imag_arr = [] "
      ],
      "metadata": {
        "id": "LPbiawX9_SC_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "D0mIXvtv2xAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symbol2symbol_main(method, quadrants, input_data_path, distances, output_path, params = None, mod_csv = False, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  \n",
        "  if params == None:\n",
        "    output_features = \"/{}_Features_alpha_75_beta_25.csv\".format(str(method))\n",
        "  else:\n",
        "    decimal_alpha = modf(params['alpha'])\n",
        "    decimal_alpha  = round(decimal_alpha[0], 2)\n",
        "    decimal_alpha = re.findall('..(.*)', str(decimal_alpha))[0]\n",
        "\n",
        "    decimal_beta = modf(params['beta'])\n",
        "    decimal_beta  = round(decimal_beta[0], 2)\n",
        "    decimal_beta = re.findall('..(.*)', str(decimal_beta))[0]\n",
        "\n",
        "    output_features = \"/{}_Features_alpha_{}_beta{}.csv\".format(str(method), str(decimal_alpha), str(decimal_beta))\n",
        "\n",
        "  # Get input data\n",
        "  X, Y = create_df(input_data_path, distances, nsymbols, min_dist, max_dist)\n",
        "  X = X.applymap(strToTuple)\n",
        "\n",
        "  # Generate mod of the original file\n",
        "  if mod_csv == True:\n",
        "    print('Generating the modified file for the original data.')\n",
        "    #mod_df_generator(X, input_data_path)\n",
        "  \n",
        "  train_idxs2, test_idxs2 = test_train_indexes_v2()\n",
        "\n",
        "  X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "  X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\") \n",
        "\n",
        "  data_new = {}\n",
        "\n",
        "  for i in range(0,25):\n",
        "    data_new[str(80*(i+1))] = {\"Train\":X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}  \n",
        "\n",
        "  first = True\n",
        "  modify_all_data_df = pd.DataFrame()\n",
        "  for i in tqdm(range(25)):\n",
        "      #i = 24\n",
        "      print('\\n')\n",
        "      print(\"i = \",i)\n",
        "      modify_data_df = pd.DataFrame()\n",
        "      for j in range(i+1,25):\n",
        "          print(\" j = \",j)\n",
        "          source = data_new[str(distances[i]*80)]['Train']\n",
        "          target = data_new[str(distances[j]*80)]['Train']\n",
        "          source_test = data_new[str(distances[i]*80)]['Test']\n",
        "\n",
        "          source_test2 = source_test.copy()\n",
        "\n",
        "          for quadrant in quadrants:\n",
        "              print(\"   quadrant = \", quadrant)\n",
        "              if method == \"GD\":\n",
        "                M, b = compute_parameters(quadrant, 'GD', source, target, params=params)\n",
        "                new_points, indexes = modify_const_GD(quadrant, source_test, M, b)\n",
        "              elif method == \"Z\":\n",
        "                mean_source,cov_source,mean_target,cov_target = compute_parameters(quadrant, 'Z', source, target, params=None)\n",
        "                new_points, indexes = modify_const_Z(quadrant,source_test,mean_source,cov_source,mean_target,cov_target)\n",
        "\n",
        "              for k in range(len(indexes)):\n",
        "                  source_test2.iloc[indexes[k][0],indexes[k][1]] = complex(new_points[k][0], new_points[k][1])\n",
        "\n",
        "          if mod_csv == True:\n",
        "            old_df = source_test2.copy()\n",
        "            old_df.insert(loc = 0,column = 'source_distance',value = str(distances[i]*80))\n",
        "            old_df.insert(loc = 1,column = 'target_distance',value = str(distances[j]*80))\n",
        "\n",
        "            modify_data_df  = pd.concat([modify_data_df, old_df], ignore_index=True)\n",
        "            break\n",
        "          F=[]\n",
        "          for k in range(source_test2.shape[0]):\n",
        "              data2=list(source_test2.iloc[k,:])\n",
        "              data2=[[float(d.real), float(d.imag)] for d in data2]\n",
        "              gmm = GaussianMixture(n_components=16, random_state=0, means_init=my_centers).fit(data2)\n",
        "              mus=gmm.means_\n",
        "              sigmas=gmm.covariances_\n",
        "\n",
        "              features=[distances[i]*80, distances[j]*80]\n",
        "\n",
        "              for z in selCP_pos:\n",
        "                  mindist=None\n",
        "                  k_inc=None\n",
        "                  for w in range(16):\n",
        "                      d=L2dist(mus[w],z)\n",
        "                      if mindist is None or mindist>d:\n",
        "                          mindist=d\n",
        "                          k_inc=w\n",
        "                  covmat=np.concatenate(list(sigmas[k_inc])).ravel().tolist()\n",
        "                  features = [*features, *mus[k_inc], *covmat]\n",
        "              F.append(features)\n",
        "          \n",
        "          header=['original_dist', 'target_dist']\n",
        "          \n",
        "          for j in selCP:\n",
        "              header=[*header,*['mu_r_'+str(j),'mu_i_'+str(j),'sigma_rr_'+str(j),'sigma_ri_'+str(j),'sigma_ir_'+str(j),'sigma_ii_'+str(j)]]\n",
        "\n",
        "          \n",
        "          with open(output_path + output_features, 'a', encoding='UTF8', newline='') as f:\n",
        "              writer = csv.writer(f)\n",
        "              # write the header\n",
        "              if first:\n",
        "                writer.writerow(header)\n",
        "                first = False\n",
        "              # write multiple rows\n",
        "              writer.writerows(F)  \n",
        "\n",
        "                   \n",
        "      if mod_csv == True:\n",
        "        # Generate mod for modified file\n",
        "        print('Generating the modified file for the modified data.')\n",
        "        mod_df_generator(modify_data_df, output_path, raw_data = False, mod_i = i, method = method)\n",
        "\n",
        "        # Get modified data points\n",
        "        modify_all_data_df  = pd.concat([modify_all_data_df, modify_data_df], ignore_index=True)\n",
        "\n",
        "        break\n",
        "  if mod_csv == True:\n",
        "    # Save the modified data\n",
        "    print('Saving the modified data.')\n",
        "    filename = ('/{}_consts_modified_data.csv'.format(str(method)))\n",
        "    \n",
        "    # Removing parenthesis of complex numbers\n",
        "    headers_names = list(modify_all_data_df.columns)\n",
        "    for h in headers_names:\n",
        "      if h != 'source_distance' or h != 'source_distance':\n",
        "        modify_all_data_df[h] = modify_all_data_df[h].apply(str).str.replace('\\(|\\)','')\n",
        "\n",
        "    modify_all_data_df.to_csv(str(output_path)+filename, index=False)        "
      ],
      "metadata": {
        "id": "v0EbouGD82YI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Main "
      ],
      "metadata": {
        "id": "TOT-h2MA_ZgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Enviroment"
      ],
      "metadata": {
        "id": "I4LGRwMj_nPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOQUE PARA USAR DESDE COLAB\n",
        "\n",
        "# Google drive loading as work station for local-usage of the files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount= True)\n",
        "\n",
        "#-----------------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHgmPMH9_jM4",
        "outputId": "6b3e80b0-d35b-4abe-be0f-17e821cb037b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para cambiar los paths rapido.\n",
        "workers = [\"Ronald\", \"Local\"]\n",
        "\n",
        "# Change the number to change the paths.\n",
        "worker = workers[0]\n",
        "\n",
        "if worker == \"Ronald\":\n",
        "  path= \"/content/gdrive/MyDrive/Symbol_to_Symbol/ANN_dataset\"\n",
        "else: path = os.getcwd()"
      ],
      "metadata": {
        "id": "wEXfbKQn_li-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Variables"
      ],
      "metadata": {
        "id": "wNtoRKInAzGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "\n",
        "distances=[i for i in range(1,26)]\n",
        "nsamples=50\n",
        "span_length=80\n",
        "nsymbols=2048\n",
        "\n",
        "######\n",
        "min_dist=0\n",
        "max_dist=3000\n",
        "selCP=[1,7,10,15]\n",
        "selCP_pos=[(-3,3),(1,1),(-1,-1),(1,-3)]\n",
        "my_centers=[[-3,3],[-1,3],[1,3],[3,3],[-3,1],[-1,1],[1,1],[3,1],[-3,-1],[-1,-1],[1,-1],[3,-1], [-3,-3],[-1,-3],[1,-3],[3,-3]]\n",
        "######"
      ],
      "metadata": {
        "id": "zf6EB5DE_1Ln"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution Z Score"
      ],
      "metadata": {
        "id": "5rpJNtY-AOrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User inputs"
      ],
      "metadata": {
        "id": "WorVp1N9_sAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE SELCET THE METHOD AND QUADRANTS THAT ARE DESIRED TO BE TESTED\n",
        "method = \"Z\" # or method = \"GD\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "\n",
        "#Output mod files\n",
        "output_path = path + '/modifiedData/'+ method\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgsmrggO_e7Y",
        "outputId": "2a059b05-76a3-455b-a52e-a9a92a6a8c04"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepath selected: /content/gdrive/MyDrive/Symbol_to_Symbol/ANN_dataset/rawData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lauch"
      ],
      "metadata": {
        "id": "qXP72mvG_ucs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symbol2symbol_main(method, quadrants, input_data_path, distances, output_path, params = None, mod_csv = True, nsymbols = 2048, min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBDnCGBx_wMZ",
        "outputId": "1310316a-5552-4d2a-8db4-cebd1812734d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating the modified file for the original data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "i =  0\n",
            " j =  1\n",
            "   quadrant =  1\n",
            "   quadrant =  7\n",
            "   quadrant =  10\n",
            "   quadrant =  15\n",
            "Generating the modified file for the modified data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/25 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the modified data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution Gradient Descent"
      ],
      "metadata": {
        "id": "z6vVPAoUAeaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User Inputs"
      ],
      "metadata": {
        "id": "Tfs_gFR3AoYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE SELCET THE METHOD AND QUADRANTS THAT ARE DESIRED TO BE TESTED\n",
        "method = \"GD\" # or method = \"Z\"\n",
        "quadrants = [1, 7, 10, 15]\n",
        "\n",
        "# PLEASE review that the path below is correct\n",
        "input_data_path=path+\"/rawData\"\n",
        "print('filepath selected: {}'.format(input_data_path))\n",
        "\n",
        "#Output mod files\n",
        "output_path = path + '/modifiedData/'+ method\n",
        "\n",
        "# Params for gradient descent alpha and beta\n",
        "a = 0.7\n",
        "b = 0.2\n",
        "# params = {\"alpha\": float(a), \"beta\": float(b)}"
      ],
      "metadata": {
        "id": "_iP0wMjyArEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lauch"
      ],
      "metadata": {
        "id": "ytfIUkboArYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symbol2symbol_main(method, quadrants, input_data_path, distances, output_path, mod_csv = True,  params = params, nsymbols = 2048, min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "priZkLvqAHRz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
