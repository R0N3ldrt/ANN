{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSwyjbDoiwhxyEcnZStjjL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R0N3ldrt/Thesis/blob/main/Symbol_to_Symbol-1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbol-to_Symbol Attack"
      ],
      "metadata": {
        "id": "5DHOkVKJcpRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Drive and folders"
      ],
      "metadata": {
        "id": "jdouNqrRcxsT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3PKUBorcmzu",
        "outputId": "00b3351d-ab0d-4ed5-fb8b-a038e944879f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# BLOQUE PARA USAR DESDE COLAB\n",
        "\n",
        "# Google drive loading as work station for local-usage of the files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount= True)\n",
        "\n",
        "#-----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para cambiar los paths rapido.\n",
        "workers = [\"Ronald\", \"Local\"]\n",
        "\n",
        "# Cambiar el numero aqui para cambiar los paths.\n",
        "worker = workers[0]\n",
        "\n",
        "if worker == \"Ronald\":\n",
        "  path= \"/content/gdrive/MyDrive/Thesis_Workstation/ANN_dataset\"\n",
        "else: path = os.getcwd()"
      ],
      "metadata": {
        "id": "24eFk1m1con6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Necesary Libraries"
      ],
      "metadata": {
        "id": "r-MsZTyAc4KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necesary libraries\n",
        "# Libraries for correct code execution \n",
        "\n",
        "import os, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pickle\n",
        "import random\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D, Flatten\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "g96FIp6Lc5MM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Train/Test data"
      ],
      "metadata": {
        "id": "zUlyFUMEdLdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Old input data"
      ],
      "metadata": {
        "id": "kzN1B7ZqBMP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_path=path+\"/rawData\"\n",
        "\n",
        "distances=[i for i in range(1,26)]\n",
        "nsamples=50\n",
        "span_length=80\n",
        "nsymbols=2048\n",
        "\n",
        "######\n",
        "min_dist=0\n",
        "max_dist=3000\n",
        "selCP=[1,7,10,15]\n",
        "selCP_pos=[(-3,3),(1,1),(-1,-1),(1,-3)]\n",
        "my_centers=[[-3,3],[-1,3],[1,3],[3,3],[-3,1],[-1,1],[1,1],[3,1],[-3,-1],[-1,-1],[1,-1],[3,-1], [-3,-3],[-1,-3],[1,-3],[3,-3]]\n",
        "######"
      ],
      "metadata": {
        "id": "bCkGqVsudPAj"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(input_data_path, distances, nsymbols = 2048, min_dist = 0, max_dist = 3000):\n",
        "  X=None\n",
        "  Y=[]\n",
        "  colnames=['i'+str(i) for i in range(nsymbols)]\n",
        "\n",
        "  for d in distances:\n",
        "    dist=d*span_length\n",
        "    if dist<min_dist or dist>max_dist: continue\n",
        "    filename='consts_'+str(d)+'span.csv'\n",
        "    df_aux=pd.read_csv(input_data_path+'/'+filename, sep=\",\", header=None)\n",
        "    df_aux = df_aux.T\n",
        "    df_aux.columns=colnames\n",
        "    Y=Y+[dist]*df_aux.shape[0]\n",
        "    if X is None: X=df_aux\n",
        "    else: X=X.append(df_aux)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "Ob3N2yoWdRMK"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strToTuple(s):\n",
        "    s_aux=s.split(\"i\")\n",
        "    s=s_aux[0]+\"j\"\n",
        "    return complex(s)"
      ],
      "metadata": {
        "id": "ez6fFASYMHqS"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v1():\n",
        "  train_idxs = []\n",
        "  test_idxs = []\n",
        "  for i in range(25):\n",
        "      for j in range(25):\n",
        "          train_idxs.append(50*i + j)\n",
        "          test_idxs.append(50*(i+1)-1-j)\n",
        "  return train_idxs, test_idxs"
      ],
      "metadata": {
        "id": "3stgNC0RdV0y"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_train_indexes_v2():\n",
        "  train_idxs2 = []\n",
        "  test_idxs2 = []\n",
        "  for i in range(25):\n",
        "      for j in range(25):\n",
        "          test_idxs2.append(50*(i+1)-1-j)\n",
        "\n",
        "  for i in range(25):\n",
        "    for j in range(2):\n",
        "      train_idxs2.append(50*i + j)\n",
        "  return train_idxs2, test_idxs2"
      ],
      "metadata": {
        "id": "Pade_gfQdYQu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Old"
      ],
      "metadata": {
        "id": "1I6c2gPZNa_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain df for each distance (X) and  distance*nsymbols (Y)\n",
        "X, Y = create_df(input_data_path, distances, nsymbols = 2048, min_dist = 0, max_dist = 3000)"
      ],
      "metadata": {
        "id": "9A4DSaynda_r"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.applymap(strToTuple)"
      ],
      "metadata": {
        "id": "oqc5q1p93bN4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_idxs, test_idxs = test_train_indexes_v1()\n",
        "train_idxs2, test_idxs2 = test_train_indexes_v2()\n",
        "\n",
        "X_train = X.iloc[train_idxs].reset_index(drop = \"True\")\n",
        "X_test = X.iloc[test_idxs].reset_index(drop = \"True\")\n",
        "X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\")"
      ],
      "metadata": {
        "id": "Zq5BflAWNV6e"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {}\n",
        "\n",
        "for i in range(0,25):\n",
        "  data[str(80*(i+1))] = {\"Train\":X_train.iloc[i*25:(i*25+25)].reset_index(drop = \"True\"),\"Test\":X_test.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}\n",
        "\n",
        "data_new = {}\n",
        "\n",
        "for i in range(0,25):\n",
        "  data_new[str(80*(i+1))] = {\"Train\":X_train2.iloc[i*2:(i*2+2)].reset_index(drop = \"True\"),\"Test\":X_test2.iloc[i*25:(i*25+25)].reset_index(drop = \"True\")}"
      ],
      "metadata": {
        "id": "CAJSSIhGAx4O"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New input data"
      ],
      "metadata": {
        "id": "KtEqnCePBIJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_df(input_data_path):\n",
        "  return pd.read_excel(input_data_path, sheet_name = \"Sheet1\")\n",
        "\n",
        "def strToTuple(s):\n",
        "    s_aux=s.split(\"i\")\n",
        "    s=s_aux[0]+\"j\"\n",
        "    return complex(s)\n",
        "\n",
        "def test_train_indexes_v1(df, distances):\n",
        "  train_idxs = []\n",
        "  test_idxs = []\n",
        "\n",
        "  amt_of_distances = len(distances)\n",
        "  total_of_samples = df.shape[0]\n",
        "\n",
        "  amt_of_sample_per_distance = int(total_of_samples/amt_of_distances)\n",
        "  half_of_sample_per_distance = int(amt_of_sample_per_distance/2)\n",
        "\n",
        "  indx_cnt = 0\n",
        "  for dist in distances:\n",
        "\n",
        "    for row_index in range(amt_of_sample_per_distance):\n",
        "      # Select the first 5 samples as train\n",
        "      if row_index < half_of_sample_per_distance:\n",
        "        train_idxs.append(indx_cnt)\n",
        "        indx_cnt += 1\n",
        "      else:\n",
        "        test_idxs.append(indx_cnt)\n",
        "        indx_cnt += 1\n",
        "\n",
        "  return train_idxs, test_idxs\n",
        "\n",
        "def test_train_indexes_v2(df, distances):\n",
        "  train_idxs2 = []\n",
        "  test_idxs2 = []\n",
        "\n",
        "  amt_of_distances = len(distances)\n",
        "  total_of_samples = df.shape[0]\n",
        "\n",
        "  amt_of_sample_per_distance = int(total_of_samples/amt_of_distances)\n",
        "  half_of_sample_per_distance = int(amt_of_sample_per_distance/2)\n",
        "\n",
        "  indx_cnt = 0\n",
        "  for dist in distances:\n",
        "\n",
        "    for row_index in range(amt_of_sample_per_distance):\n",
        "      # Select the first 5 samples as train\n",
        "      if row_index == 1 or row_index == 2:\n",
        "        train_idxs2.append(indx_cnt)\n",
        "        indx_cnt += 1\n",
        "      elif row_index >= half_of_sample_per_distance:\n",
        "        test_idxs2.append(indx_cnt)\n",
        "        indx_cnt += 1\n",
        "      else:\n",
        "        indx_cnt += 1\n",
        "\n",
        "  return train_idxs2, test_idxs2\n",
        "\n",
        "def create_data_dict(X_train, X_test, X_train2, X_test2, distances):\n",
        "\n",
        "  data = {}\n",
        "  data_new = {}\n",
        "  data_full = {}\n",
        "  data_new_full = {}\n",
        "\n",
        "  for dist in distances:\n",
        "\n",
        "    X_train_n = X_train[X_train['Distance_km'].isin([int(dist)])]\n",
        "    X_test_n = X_test[X_test['Distance_km'].isin([int(dist)])]\n",
        "\n",
        "    data_full[str(dist)] = {'Train':X_train_n.reset_index(drop = 'True'),'Test':X_test_n.reset_index(drop = 'True')}\n",
        "\n",
        "    X_train_nn = X_train_n.iloc[:, 5:X_train_n.shape[1]]\n",
        "    X_test_nn = X_test_n.iloc[:, 5:X_test_n.shape[1]]\n",
        "\n",
        "    X_train2_n = X_train2[X_train2['Distance_km'].isin([int(dist)])]\n",
        "    X_test2_n = X_test2[X_test2['Distance_km'].isin([int(dist)])]\n",
        "\n",
        "    data_new_full[str(dist)] = {'Train':X_train2_n.reset_index(drop = 'True'),'Test':X_test2_n.reset_index(drop = 'True')}\n",
        "\n",
        "    X_train2_nn = X_train2_n.iloc[:, 5:X_train2_n.shape[1]]\n",
        "    X_test2_nn = X_test2_n.iloc[:, 5:X_test2_n.shape[1]]\n",
        "\n",
        "    data[str(dist)] = {'Train':X_train_nn.reset_index(drop = 'True'),'Test':X_test_nn.reset_index(drop = 'True')}\n",
        "    data_new[str(dist)] = {'Train':X_train2_nn.reset_index(drop = 'True'),'Test':X_test2_nn.reset_index(drop = 'True')}\n",
        "\n",
        "  return data, data_new, data_full, data_new_full"
      ],
      "metadata": {
        "id": "alSxbBmzyr4T"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_test_data(constellation_path):\n",
        "  df = create_df(constellation_path)\n",
        "\n",
        "  # Open df by selected powers\n",
        "  powers = list(df['power_dBm'].unique())\n",
        "  for power in powers:\n",
        "\n",
        "    new_df = df[df['power_dBm'].isin([int(power)])]\n",
        "\n",
        "    distances = list(new_df['Distance_km'].unique())\n",
        "\n",
        "    # Data columns \n",
        "    X1 = new_df.iloc[:, 5:(new_df.shape[1])]\n",
        "    X = X1.applymap(strToTuple)\n",
        "\n",
        "    # Add back extra info columns\n",
        "    info_df = new_df.iloc[:, 0:5]\n",
        "    X = pd.merge(info_df, X, left_index=True, right_index=True)\n",
        "\n",
        "\n",
        "    train_idxs, test_idxs = test_train_indexes_v1(X, distances)\n",
        "    train_idxs2, test_idxs2 = test_train_indexes_v2(X, distances)\n",
        "    \n",
        "    X_train = X.iloc[train_idxs, :].reset_index(drop = \"True\")\n",
        "    X_test = X.iloc[test_idxs, :].reset_index(drop = \"True\")\n",
        "\n",
        "    X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "    X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\")\n",
        "\n",
        "    data, data_new, data_full, data_new_full = create_data_dict(X_train, X_test, X_train2, X_test2, distances)\n",
        "    \n",
        "    return data, data_new, data_full, data_new_full"
      ],
      "metadata": {
        "id": "0lVqPAUrYqmn"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test new data train test"
      ],
      "metadata": {
        "id": "_AgqTAgtYrn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#const_path = path + '/Constellation/QPSK/A.10hops100km/dataSet_Constellation_Samples_QPSK_37GHz_LongHaul_output_10x100.xlsx'\n",
        "const_path = path + '/Constellation/QPSK/A.10hops100km/const_dummy_QPSK.xlsx'\n",
        "\n",
        "# Open df by selected powers\n",
        "\n",
        "df = create_df(const_path)"
      ],
      "metadata": {
        "id": "wnAZgLdpVSqe"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "powers = list(df['power_dBm'].unique())\n",
        "for power in powers:\n",
        "\n",
        "  new_df = df[df['power_dBm'].isin([int(power)])]\n",
        "\n",
        "  distances = list(new_df['Distance_km'].unique())\n",
        "\n",
        "  # Data columns \n",
        "  X1 = new_df.iloc[:, 5:(new_df.shape[1])]\n",
        "  X = X1.applymap(strToTuple)\n",
        "\n",
        "  # Add back extra info columns\n",
        "  info_df = new_df.iloc[:, 0:5]\n",
        "  X = pd.merge(info_df, X, left_index=True, right_index=True)\n",
        "\n",
        "\n",
        "  train_idxs, test_idxs = test_train_indexes_v1(X, distances)\n",
        "  train_idxs2, test_idxs2 = test_train_indexes_v2(X, distances)\n",
        "  \n",
        "  X_train = X.iloc[train_idxs, :].reset_index(drop = \"True\")\n",
        "  X_test = X.iloc[test_idxs, :].reset_index(drop = \"True\")\n",
        "\n",
        "  X_train2 = X.iloc[train_idxs2].reset_index(drop = \"True\")\n",
        "  X_test2 = X.iloc[test_idxs2].reset_index(drop = \"True\")\n",
        "\n",
        "  data_x, data_new_x, data_full, data_new_full = create_data_dict(X_train, X_test, X_train2, X_test2, distances)"
      ],
      "metadata": {
        "id": "zhglUsxoyx2r"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.keys())\n",
        "#print(data['100'])\n",
        "#print(data['100']['Train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf7oDrggWc0Z",
        "outputId": "d7bb0e90-cef3-49bf-a0f2-152b897d584e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['80', '160', '240', '320', '400', '480', '560', '640', '720', '800', '880', '960', '1040', '1120', '1200', '1280', '1360', '1440', '1520', '1600', '1680', '1760', '1840', '1920', '2000'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Get Train Test Data"
      ],
      "metadata": {
        "id": "Nw5l2SldYh0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#const_path = path + '/Constellation/QPSK/A.10hops100km/dataSet_Constellation_Samples_QPSK_37GHz_LongHaul_output_10x100.xlsx'\n",
        "constellation_path = path + '/Constellation/QPSK/A.10hops100km/const_dummy_QPSK.xlsx'\n",
        "\n",
        "data_x, data_new_x, data_full, data_new_full = get_train_test_data(constellation_path)"
      ],
      "metadata": {
        "id": "__Zn6OtVYOQX"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "Ri43qNWXeFcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_b (M,m_og,m_tg,b,beta):\n",
        "  return 2*beta*(M @ m_og + b - m_tg)"
      ],
      "metadata": {
        "id": "edmLVQAxeEbV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_M(M,cov_og,cov_tg,alpha):\n",
        "    error = M @ cov_og @ np.transpose(M) - cov_tg  \n",
        "\n",
        "    m1 = (2*error[0][0] * (2*cov_og[0][0]*M[0][0] + 2*cov_og[0][1]*M[0][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[1][0] + cov_og[0][1]*M[1][1]))\n",
        "    \n",
        "    m2 = (2*error[0][0] * (2*cov_og[1][1]*M[0][1] + 2*cov_og[0][1]*M[0][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[1][0] + cov_og[1][1]*M[1][1]))\n",
        "    \n",
        "    m3 = (2*error[1][1] * (2*cov_og[0][0]*M[1][0] + 2*cov_og[0][1]*M[1][1]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[0][0] + cov_og[0][1]*M[0][1]))\n",
        "\n",
        "    m4 = (2*error[1][1] * (2*cov_og[0][0]*M[1][1] + 2*cov_og[0][1]*M[1][0]) +\n",
        "          2*(error[0][1] + error[1][0]) * (cov_og[0][1]*M[0][0] + cov_og[1][1]*M[0][1]))\n",
        "    \n",
        "    return alpha*np.array([[m1, m2], [m3, m4]])"
      ],
      "metadata": {
        "id": "bDOXvZJoeKW-"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mean_and_cov(data):\n",
        "  aux_x = [] # Reales\n",
        "  aux_y = [] # Imag\n",
        "  for obs in data:\n",
        "    aux_x.append(obs[0])\n",
        "    aux_y.append(obs[1])\n",
        "  return np.array([[np.mean(aux_x)],[np.mean(aux_y)]]), np.cov(aux_x,aux_y)\n",
        "\n",
        "\n",
        "def total_loss(m_mod,m_tg,cov_mod,cov_tg):\n",
        "  return (sum(sum(np.power(cov_mod-cov_tg,2))) + sum(np.power(m_mod - m_tg,2)))[0]\n",
        "\n",
        "\n",
        "def loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b):\n",
        "  first = alpha*sum(sum(np.power(M @ cov_og @ np.transpose(M) - cov_tg, 2)))\n",
        "  second = beta*sum(np.power(M @ m_og + b - m_tg, 2))\n",
        "  a = first+second\n",
        "  return a"
      ],
      "metadata": {
        "id": "cHynfv5FeLI5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(alpha,beta,m_tg,m_og,cov_tg,cov_og,nu,log):\n",
        "  Ms = []\n",
        "  bs = []\n",
        "  M = np.random.rand(2,2)\n",
        "  #M = np.array([[1, 0], [0, 1]])\n",
        "  b = np.random.rand(2,1)\n",
        "  #b = np.array([[0], [0]])\n",
        "  #for i in range(100000):\n",
        "  i = 0\n",
        "  while True:\n",
        "    # print('From:', M @ cov_source @ np.transpose(M))\n",
        "    # print('To:', cov_target)\n",
        "    L = loss(alpha,beta,m_tg,m_og,cov_tg,cov_og,M,b) \n",
        "    if  L < 1e-20:\n",
        "        Ms.append(M)\n",
        "        bs.append(b)\n",
        "        break\n",
        "    b = b - nu*grad_b(M,m_og,m_tg,b,beta)\n",
        "    M = M - nu*grad_M(M,cov_og,cov_tg,alpha)\n",
        "    i+= 1\n",
        "    if (i>= 5000 and i <= 5025) or (i>= 5975 and i <= 6000):\n",
        "      Ms.append(M)\n",
        "      bs.append(b)\n",
        "    if not i%5000 and log: print(L)\n",
        "  if log: print(\"-\"*25)\n",
        "  return Ms,bs"
      ],
      "metadata": {
        "id": "YgA3SBmceOGK"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_comparison_plot(mod_points,ptarget, return_plots=False):\n",
        "  x1 = [x[0] for  x in mod_points]\n",
        "  y1 = [x[1] for  x in mod_points]\n",
        "  x2 = [x[0] for  x in ptarget]\n",
        "  y2 = [x[1] for  x in ptarget]\n",
        "\n",
        "  if return_plots:\n",
        "      return go.Scatter(x = x1, y = y1, mode='markers'), go.Scatter(x = x2, y = y2,mode='markers') \n",
        "\n",
        "  fig = make_subplots(rows=1, cols=2)\n",
        "  fig.add_trace(\n",
        "    go.Scatter(x = x1, y = y1,mode='markers'),\n",
        "    \n",
        "    row=1, col=1\n",
        "  )\n",
        "  fig.add_trace(\n",
        "    go.Scatter(x = x2, y = y2,mode='markers'),\n",
        "    row=1, col=2\n",
        "  )\n",
        "  fig.update_layout(height=500, width=1000, title_text=\"Point comparison\",autosize = False)\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "Pw8-2ZOVeQLR"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_parameters (const,method,source,target,log = False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  q_target = []\n",
        "  for i in range(len(source)):\n",
        "    q_source += [[x.real,x.imag] for x in source.values.tolist()[i] if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "    q_target += [[x.real,x.imag] for x in target.values.tolist()[i]if x.real < limits[0][0] and x.real > limits[0][1] and x.imag < limits[1][0] and x.imag > limits[1][1]]\n",
        "\n",
        "  unbiased = (len(q_source)/(len(q_source)-1) * 125/126)\n",
        "\n",
        "  mean_source,cov_source = compute_mean_and_cov(q_source)\n",
        "  mean_target, cov_target= compute_mean_and_cov(q_target)\n",
        "\n",
        "  cov_source *= unbiased\n",
        "  cov_target *= unbiased\n",
        "\n",
        "  if method == \"GD\":\n",
        "    alpha = 3/4\n",
        "    beta = 1/4\n",
        "    M, b = gradient_descent(alpha,beta,mean_target,mean_source,cov_target,cov_source, 0.5,log)\n",
        "    return M,b\n",
        "\n",
        "  elif method == \"Z\":\n",
        "    return mean_source,cov_source,mean_target,cov_target"
      ],
      "metadata": {
        "id": "BF-MRK9UeSmu"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_GD(const,source,M,b, target = None, return_plots=False):\n",
        "\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "      \n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  for mult in mults:\n",
        "    res = (M @ mult + b).tolist()\n",
        "    new_points.append([res[0][0],res[1][0]])\n",
        "  \n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      return new_points, q_target\n",
        "\n",
        "  return new_points,indexes"
      ],
      "metadata": {
        "id": "0ksqQLt2eTYK"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_const_Z(const,source,mean_source,cov_source,mean_target,cov_target,target = None, return_plots=False):\n",
        "  if const  == 1: limits = [[-2,-4],[4,2]]\n",
        "  elif const == 7: limits = [[2,0],[2,0]]\n",
        "  elif const == 10: limits = [[0,-2],[0,-2]]\n",
        "  elif const == 15: limits = [[2,0],[-2,-4]]\n",
        "\n",
        "  q_source = []\n",
        "  indexes = []\n",
        "\n",
        "  for i in range(len(source)):\n",
        "    row_source = source.values.tolist()[i]\n",
        "    for j in range(len(row_source)):\n",
        "      point_source = row_source[j]\n",
        "      if point_source.real < limits[0][0] and point_source.real > limits[0][1] and point_source.imag < limits[1][0] and point_source.imag > limits[1][1]:\n",
        "        q_source += [[point_source.real,point_source.imag]]\n",
        "        indexes.append([i,j])\n",
        "\n",
        "  if target is not None:\n",
        "    q_target = []\n",
        "\n",
        "    for i in range(len(source)):\n",
        "      row_target = target.values.tolist()[i]\n",
        "      for j in range(len(row_source)):\n",
        "        point_target = row_target[j]\n",
        "        if point_target.real < limits[0][0] and point_target.real > limits[0][1] and point_target.imag < limits[1][0] and point_target.imag > limits[1][1]:\n",
        "          q_target += [[point_target.real,point_target.imag]]\n",
        "\n",
        "  mults = [np.array([[x[0]],[x[1]]]) for x in q_source]\n",
        "  new_points = []\n",
        "\n",
        "  w, v = np.linalg.eig(cov_source)\n",
        "  S1 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "  w, v = np.linalg.eig(cov_target)\n",
        "  S2 = v @ np.diag(np.sqrt(w)) @ np.linalg.inv(v)\n",
        "\n",
        "  for mult in mults:\n",
        "    normalized = np.linalg.inv(S1) @ (mult - mean_source)\n",
        "    denormalized = S2 @ normalized + mean_target\n",
        "\n",
        "    new_points.append([denormalized[0][0], denormalized[1][0]])\n",
        "\n",
        "  if target is not None:\n",
        "    if return_plots:\n",
        "      generate_comparison_plot(new_points,q_target)\n",
        "      \n",
        "\n",
        "  return new_points, indexes"
      ],
      "metadata": {
        "id": "wAAXm-VueWrT"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtain parameters and GD"
      ],
      "metadata": {
        "id": "gzBCccEGecN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances=[i for i in range(1,26)]\n",
        "M,b = compute_parameters(1,\"GD\",data[str(distances[0]*80)]['Train'],data[str(distances[24]*80)]['Train'], log = True)\n",
        "\n",
        "#a,b = modify_const_GD(1,data[str(distances[0]*80)]['Train'],M[-1],b[-1],data[str(distances[24]*80)]['Train'], return_plots=True)"
      ],
      "metadata": {
        "id": "YcbTLGsqehSs",
        "outputId": "0577a27e-7a7b-4b7d-eb37-57a822b374b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00055049]\n",
            "[1.54932795e-08]\n",
            "[2.51436977e-13]\n",
            "[4.07045888e-18]\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M,b = compute_parameters(1,\"GD\",data_x[str(0)]['Train'],data_x[str(200)]['Train'], log = True)"
      ],
      "metadata": {
        "id": "ZCf4dzpZDQBo",
        "outputId": "da67d945-6fb4-4a3d-fb21-17bcd2c5578a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nan]\n",
            "[nan]\n",
            "[nan]\n",
            "[nan]\n",
            "[nan]\n",
            "[nan]\n",
            "[nan]\n",
            "[nan]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-17a1d1d74026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"GD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-cc99d3b90fc9>\u001b[0m in \u001b[0;36mcompute_parameters\u001b[0;34m(const, method, source, target, log)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-51b0d8a7148a>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(alpha, beta, m_tg, m_og, cov_tg, cov_og, nu, log)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_og\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_tg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnu\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_M\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_og\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_tg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0;36m5000\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m5025\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0;36m5975\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m6000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-189ca4b24a22>\u001b[0m in \u001b[0;36mgrad_M\u001b[0;34m(M, cov_og, cov_tg, alpha)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad_M\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_og\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcov_tg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mcov_og\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcov_tg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     m1 = (2*error[0][0] * (2*cov_og[0][0]*M[0][0] + 2*cov_og[0][1]*M[0][1]) +\n\u001b[1;32m      5\u001b[0m           2*(error[0][1] + error[1][0]) * (cov_og[0][0]*M[1][0] + cov_og[0][1]*M[1][1]))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss"
      ],
      "metadata": {
        "id": "clqRuupEezcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "\n",
        "with open('b.pickle', 'wb') as handle:\n",
        "    pickle.dump(b, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "tiFj7MFse1jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "points = []\n",
        "id = [np.identity(2)]\n",
        "zero = [np.zeros((2, 1))]\n",
        "Ms = id + M\n",
        "bs = zero + b\n",
        "\n",
        "for i in range(len(Ms)):\n",
        "  p,_ =  modify_const_GD(1,data[str(distances[0]*80)]['Train'],Ms[i],bs[i])\n",
        "  points.append(p)"
      ],
      "metadata": {
        "id": "yOs8qqgxe3Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = points[-1]\n",
        "x = [a[0] for a in obs]\n",
        "y = [a[1] for a in obs]\n",
        "\n",
        "fig = px.scatter(x=x, y=y, labels=dict(x=\"\", y = \"\"))\n",
        "\n",
        "fig.update_traces(marker=dict(\n",
        "        color='#007bbf', size=10))\n",
        "\n",
        "fig.update_layout(width=550, height = 500)\n",
        "fig.update_yaxes(range = [1.5,4.5])\n",
        "fig.update_xaxes(range = [-4.5,-1.5])\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "zA0Jf7bhe5mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "x1 = [10,8,13,9,11,14,6,4,12,7,5]\n",
        "x2 = x1\n",
        "x3 = x1\n",
        "x4 = [8,8,8,8,8,8,8,19,8,8,8]\n",
        "y1 = [10.0,6.95,7.58,8.81,8.33,9.96,7.24,4.26,10.84,4.82,5.68]\n",
        "y2 = [9.14,8.14,8.74,8.77,9.26,8.10,6.13,3.10,9.13,7.26,4.74]\n",
        "y3 = [7.46,6.77,12.74,7.11,7.81,8.84,6.08,5.39,8.15,6.42,5.73]\n",
        "y4 = [6.58,5.76,7.71,8.84,8.47,7.04,5.25,12.50,5.56,7.91,6.89]\n",
        "\n",
        "reg_x = [0,20]\n",
        "reg_y = [3,13]\n",
        "\n",
        "fig = make_subplots(rows=2, cols=2)\n",
        "\n",
        "\n",
        "fig.add_trace(\n",
        "  go.Scatter(x = reg_x, y = reg_y,mode='lines'),\n",
        "  \n",
        "  row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "  go.Scatter(x = reg_x, y = reg_y,mode='lines'),\n",
        "  \n",
        "  row=1, col=2\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "  go.Scatter(x = reg_x, y = reg_y,mode='lines'),\n",
        "  \n",
        "  row=2, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "  go.Scatter(x = reg_x, y = reg_y,mode='lines'),\n",
        "  \n",
        "  row=2, col=2\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "  go.Scatter(x = x1, y = y1,mode='markers'),\n",
        "  \n",
        "  row=1, col=1\n",
        ")\n",
        "\n",
        "\n",
        "fig.add_trace(\n",
        "  go.Scatter(x = x2, y = y2,mode='markers'),\n",
        "  row=1, col=2\n",
        ")\n",
        "fig.add_trace(\n",
        "go.Scatter(x = x3, y = y3,mode='markers'),\n",
        "row=2, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "go.Scatter(x = x4, y = y4,mode='markers'),\n",
        "row=2, col=2\n",
        ")\n",
        "\n",
        "fig.update_xaxes(range=[0, 20])\n",
        "fig.update_yaxes(range=[0, 15], dtick = 3)\n",
        "fig.update_layout(height=500, width=1000, title_text=\"Point comparison\",autosize = False)\n",
        "fig.update_traces(marker=dict(\n",
        "        color='#007bbf', size=10, line_width=2))\n",
        "\n",
        "fig.update_traces(line_color='black', line_width=2)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "qKbZYT7Pe7do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Doubt 2\n",
        "'''\n",
        "x, y = [], []\n",
        "for x1, y1 in m1:\n",
        "    x.append(x1)\n",
        "    y.append(y1)\n",
        "np.cov(x, y)\n",
        "'''"
      ],
      "metadata": {
        "id": "6Th5EdPLe8YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Doubt 3\n",
        "'''\n",
        "x, y = [], []\n",
        "for x1, y1 in m2:\n",
        "    x.append(x1)\n",
        "    y.append(y1)\n",
        "np.cov(x, y)\n",
        "'''"
      ],
      "metadata": {
        "id": "Uqtf8G9Se_GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1, p = modify_const_Z(7,data[str(distances[15]*80)]['Train'],mean_source,cov_source,mean_target,cov_target,target = data[str(distances[22]*80)]['Train'], return_plots=False)\n",
        "m2, p = modify_const_GD(7,data[str(distances[15]*80)]['Train'],M,b,target = data[str(distances[22]*80)]['Train'], return_plots=False)"
      ],
      "metadata": {
        "id": "TTvh2-0WfBLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  fig = make_subplots(rows=1, cols=3, shared_xaxes = True, shared_yaxes = True\n",
        "                      , subplot_titles=['Z-score', 'Gradient Descent', 'Target distribution'], horizontal_spacing= 0.02)\n",
        "\n",
        "  \n",
        "  fig.add_traces(\n",
        "    [m1, m2, p], rows=[1,1,1], cols=[1,2,3]\n",
        "  )\n",
        "\n",
        "  fig.update_layout(height=420, width=1000, autosize = False)\n",
        "  \n",
        "  fig.update_xaxes(range=[-4.1, -1.9])\n",
        "  fig.update_yaxes(range=[1.9, 4.1]) \n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "MOYrHhdmfC7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L2dist(a,b):\n",
        "    return math.sqrt(math.pow(a[0]-b[0],2)+math.pow(a[1]-b[1],2))"
      ],
      "metadata": {
        "id": "KAVTCcqNfE8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"Z\"\n",
        "\n",
        "quadrants = [1, 7, 10, 15]\n",
        "first = True\n",
        "\n",
        "for i in tqdm(range(25)):\n",
        "    print(\"i = \",i)\n",
        "    for j in range(i+1,25):\n",
        "        print(\" j = \",j)\n",
        "        source = data_new[str(distances[i]*80)]['Train']\n",
        "        target = data_new[str(distances[j]*80)]['Train']\n",
        "        source_test = data_new[str(distances[i]*80)]['Test']\n",
        "\n",
        "        source_test2 = source_test.copy()\n",
        "\n",
        "        for quadrant in quadrants:\n",
        "            print(\"   quadrant = \", quadrant)\n",
        "            if method == \"GD\":\n",
        "              M, b = compute_parameters(quadrant, 'GD', source, target)\n",
        "              new_points, indexes = modify_const_GD(quadrant, source_test, M, b)\n",
        "            elif method == \"Z\":\n",
        "              mean_source,cov_source,mean_target,cov_target = compute_parameters(quadrant, 'Z', source, target)\n",
        "              new_points, indexes = modify_const_Z(quadrant,source_test,mean_source,cov_source,mean_target,cov_target)\n",
        "\n",
        "            '''\n",
        "            new_points2,indexes2 = modify_const_GD(quadrant, source, M, b)\n",
        "            target3,indexes3 = modify_const_GD(quadrant, target, np.array([[1,0],[0,1]]), np.array([[0],[0]]))\n",
        "            print(\"NP1\")\n",
        "            print(compute_mean_and_cov(new_points))\n",
        "            print(\"NP2\")\n",
        "            print(compute_mean_and_cov(new_points2))\n",
        "            print(\"T3\")\n",
        "            print(compute_mean_and_cov(target3))\n",
        "            '''\n",
        "            for k in range(len(indexes)):\n",
        "                source_test2.iloc[indexes[k][0],indexes[k][1]] = complex(new_points[k][0], new_points[k][1])\n",
        "        \n",
        "        F=[]\n",
        "        for k in range(source_test2.shape[0]):\n",
        "            data2=list(source_test2.iloc[k,:])\n",
        "            data2=[[float(d.real), float(d.imag)] for d in data2]\n",
        "            gmm = GaussianMixture(n_components=16, random_state=0, means_init=my_centers).fit(data2)\n",
        "            mus=gmm.means_\n",
        "            sigmas=gmm.covariances_\n",
        "            features=[distances[j]*80]\n",
        "            for z in selCP_pos:\n",
        "                mindist=None\n",
        "                k_inc=None\n",
        "                for w in range(16):\n",
        "                    d=L2dist(mus[w],z)\n",
        "                    if mindist is None or mindist>d:\n",
        "                        mindist=d\n",
        "                        k_inc=w\n",
        "                #print(k_inc)\n",
        "                #print(mus[k_inc])\n",
        "                covmat=np.concatenate(list(sigmas[k_inc])).ravel().tolist()\n",
        "                #features = [*features, *mus[k_inc], *[covmat[0], covmat[3]]]\n",
        "                features = [*features, *mus[k_inc], *covmat]\n",
        "            F.append(features)\n",
        "\n",
        "        header=['dist']\n",
        "        \n",
        "        for j in selCP:\n",
        "            header=[*header,*['mu_r_'+str(j),'mu_i_'+str(j),'sigma_rr_'+str(j),'sigma_ri_'+str(j),'sigma_ir_'+str(j),'sigma_ii_'+str(j)]]\n",
        "            #header=[*header,*['mu_r_'+str(j),'mu_i_'+str(j),'sigma_rr_'+str(j),'sigma_ii_'+str(j)]]\n",
        "        with open(path+'/modifiedData/'+method+'/alpha0.1.csv', 'a', encoding='UTF8', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            # write the header\n",
        "            if first:\n",
        "              writer.writerow(header)\n",
        "              first = False\n",
        "            # write multiple rows\n",
        "            writer.writerows(F)"
      ],
      "metadata": {
        "id": "qr9c5UmtfGlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = data[str(distances[22]*80)]['Train']\n",
        "target = data[str(distances[24]*80)]['Train']\n",
        "source_test = data[str(distances[22]*80)]['Test']\n",
        "target_test = data[str(distances[24]*80)]['Test']"
      ],
      "metadata": {
        "id": "DH6-h5-zfI_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m,b = compute_parameters(7, 'GD', source, target, log = True)"
      ],
      "metadata": {
        "id": "zEDPDzbSfK8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing methods"
      ],
      "metadata": {
        "id": "fhGOffKDfNMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l_gd = []\n",
        "l_z = []\n",
        "const = [1,7,10,15]\n",
        "\n",
        "for i in const:\n",
        "  p_gd,t = modify_const(i,\"GD\",source,target,plot = False)\n",
        "  p_z,_ = modify_const(i,\"Z\",source,target,plot = False)\n",
        "  aux_gd = [[x[0][0],x[1][0]] for x in p_gd]\n",
        "  aux_z = [[x[0][0],x[1][0]] for x in p_z]\n",
        "  m_gd,cov_gd = compute_mean_and_cov(aux_gd)\n",
        "  m_z,cov_z = compute_mean_and_cov(aux_z)\n",
        "  m_t,cov_t = compute_mean_and_cov(t)\n",
        "\n",
        "  l_gd.append(total_loss(m_gd,m_t,cov_gd,cov_t))\n",
        "  l_z.append(total_loss(m_z,m_t,cov_z,cov_t))"
      ],
      "metadata": {
        "id": "5dPJ8ZLUfPgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_comparison = pd.DataFrame({\"Const_P\":[0],\"Loss\":[0],\"Method\":[\"\"]})\n",
        "\n",
        "for i in range(len(l_gd)):\n",
        "  loss_comparison.loc[i] = [const[i],l_gd[i],\"GD\"]\n",
        "\n",
        "for i in range(len(l_z)):\n",
        "  loss_comparison.loc[i+4] = [const[i],l_z[i],\"Z\"]"
      ],
      "metadata": {
        "id": "pCKqdINJfSFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.bar(loss_comparison, x=\"Const_P\", y=\"Loss\", color='Method')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "v05BM4N3fWOB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}